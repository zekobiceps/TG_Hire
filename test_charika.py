#!/usr/bin/env python3
"""
Test standalone pour la fonction get_email_from_charika amÃ©liorÃ©e
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import re

def get_email_from_charika(entreprise):
    """Recherche d'email d'entreprise depuis Charika.ma avec amÃ©lioration ciblÃ©e"""
    try:
        # Rechercher sur Charika.ma
        search_url = f"https://www.charika.ma/search?q={quote(entreprise)}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print(f"ğŸ” Recherche pour '{entreprise}' sur Charika.ma...")
        print(f"URL: {search_url}")
        
        response = requests.get(search_url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Chercher le lien vers la page de l'entreprise - approche amÃ©liorÃ©e
        company_links = soup.find_all('a', href=True)
        company_url = None
        
        print(f"ğŸ“‹ TrouvÃ© {len(company_links)} liens sur la page de recherche")
        
        # Debug: afficher quelques liens pour comprendre la structure
        print("ğŸ” Premiers liens trouvÃ©s:")
        for i, link in enumerate(company_links[:10]):
            href = link.get('href', '')
            text = link.get_text().strip()
            print(f"  {i+1}. href='{href}' | text='{text[:50]}...'")
        
        # Chercher d'abord les liens contenant "entreprise"
        for link in company_links:
            href = link.get('href', '')
            text = link.get_text().strip().lower()
            if 'entreprise' in href and any(word in text for word in entreprise.lower().split()):
                company_url = "https://www.charika.ma" + href if not href.startswith('http') else href
                print(f"âœ… Lien entreprise trouvÃ©: {company_url}")
                break
        
        # Si pas trouvÃ©, chercher dans tous les liens
        if not company_url:
            print("ğŸ” Recherche dans tous les liens...")
            for link in company_links:
                href = link.get('href', '')
                text = link.get_text().strip().lower()
                # Assouplir la recherche
                if href and (entreprise.lower() in text or any(word in text for word in entreprise.lower().split())):
                    if 'entreprise' in href or 'company' in href or '/fiche/' in href:
                        company_url = "https://www.charika.ma" + href if not href.startswith('http') else href
                        print(f"âœ… Lien gÃ©nÃ©ral trouvÃ©: {company_url}")
                        break
        
        if not company_url:
            print("âŒ Aucun lien vers la page de l'entreprise trouvÃ©")
            return None
            
        if company_url:
            print(f"ğŸŒ AccÃ¨s Ã  la page de l'entreprise: {company_url}")
            
            # AccÃ©der Ã  la page de l'entreprise
            company_response = requests.get(company_url, headers=headers, timeout=10)
            company_soup = BeautifulSoup(company_response.content, 'html.parser')
            
            # MÃ©thode 1: Chercher spÃ©cifiquement dans les spans dropdown (structure identifiÃ©e)
            print("ğŸ” MÃ©thode 1: Recherche dans les spans dropdown...")
            dropdown_spans = company_soup.find_all('span', class_='dropdown')
            print(f"ğŸ“‹ TrouvÃ© {len(dropdown_spans)} spans dropdown")
            
            for i, dropdown in enumerate(dropdown_spans):
                dropdown_text = dropdown.get_text()
                print(f"  Dropdown {i+1}: {dropdown_text[:100]}...")
                
                # VÃ©rifier si ce dropdown contient "E-mail"
                if 'E-mail' in dropdown_text or 'Email' in dropdown_text:
                    print(f"  âœ… Dropdown {i+1} contient 'E-mail'")
                    # Chercher les liens mailto dans ce dropdown
                    mailto_links = dropdown.find_all('a', href=lambda x: x and x.startswith('mailto:'))
                    print(f"  ğŸ“§ TrouvÃ© {len(mailto_links)} liens mailto")
                    
                    for link in mailto_links:
                        email = link.get('href').replace('mailto:', '').strip()
                        if '@' in email and '.' in email.split('@')[1]:
                            print(f"  âœ… Email trouvÃ© via dropdown: {email}")
                            return email
            
            # MÃ©thode 2: Chercher tous les liens mailto avec diffÃ©rents sÃ©lecteurs
            print("ğŸ” MÃ©thode 2: Recherche de tous les liens mailto...")
            email_selectors = [
                'a[href^="mailto:"]',
                'span.dropdown a[href^="mailto:"]',
                '.contact-info a[href^="mailto:"]',
                '.email a[href^="mailto:"]',
                '.contact a[href^="mailto:"]'
            ]
            
            for selector in email_selectors:
                email_elements = company_soup.select(selector)
                print(f"  SÃ©lecteur '{selector}': {len(email_elements)} Ã©lÃ©ments")
                
                for element in email_elements:
                    href = element.get('href', '')
                    if href.startswith('mailto:'):
                        email = href.replace('mailto:', '').strip()
                        # VÃ©rifier que c'est un email valide
                        if '@' in email and '.' in email.split('@')[1]:
                            print(f"  âœ… Email trouvÃ© via sÃ©lecteur: {email}")
                            return email
            
            # MÃ©thode 3: Recherche par pattern dans les spans contenant "E-mail"
            print("ğŸ” MÃ©thode 3: Recherche dans spans contenant 'E-mail'...")
            email_spans = company_soup.find_all('span', string=lambda text: text and 'E-mail' in text)
            print(f"ğŸ“‹ TrouvÃ© {len(email_spans)} spans avec 'E-mail'")
            
            for span in email_spans:
                # Chercher dans le parent ou les Ã©lÃ©ments suivants
                parent = span.parent
                if parent:
                    print(f"  Parent HTML: {str(parent)[:200]}...")
                    mailto_links = parent.find_all('a', href=lambda x: x and x.startswith('mailto:'))
                    for link in mailto_links:
                        email = link.get('href').replace('mailto:', '').strip()
                        if '@' in email and '.' in email.split('@')[1]:
                            print(f"  âœ… Email trouvÃ© via span parent: {email}")
                            return email
            
            # MÃ©thode 4: Chercher dans le texte avec regex comme fallback
            print("ğŸ” MÃ©thode 4: Recherche par regex dans tout le texte...")
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
            page_text = company_soup.get_text()
            emails = re.findall(email_pattern, page_text)
            print(f"ğŸ“§ Emails trouvÃ©s par regex: {emails}")
            
            if emails:
                # Filtrer les emails qui semblent pertinents
                for email in emails:
                    if not any(spam in email.lower() for spam in ['noreply', 'no-reply', 'example', 'test']):
                        print(f"  âœ… Email retenu: {email}")
                        return email
        
        print("âŒ Aucun email trouvÃ©")
        return None
        
    except Exception as e:
        print(f"âŒ Erreur lors de la recherche sur Charika: {e}")
        return None

if __name__ == "__main__":
    # Test avec diffÃ©rentes entreprises
    test_companies = ["jetalu", "TGCC", "OCP"]
    
    for company in test_companies:
        print(f"\n{'='*50}")
        print(f"TEST: {company}")
        print(f"{'='*50}")
        
        result = get_email_from_charika(company)
        
        if result:
            print(f"âœ… SUCCÃˆS: Email trouvÃ© pour '{company}': {result}")
        else:
            print(f"âŒ Ã‰CHEC: Aucun email trouvÃ© pour '{company}'")
        
        print("\n" + "-"*50)