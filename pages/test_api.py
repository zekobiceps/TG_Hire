import streamlit as st
import pandas as pd
import io
import requests
import json
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
import re

# --- NOUVEAUT√â : Imports pour les nouvelles m√©thodes ---
from sentence_transformers import SentenceTransformer, util
import spacy

# -------------------- Configuration de la cl√© API DeepSeek --------------------
try:
    API_KEY = st.secrets["DEEPSEEK_API_KEY"]
except KeyError:
    API_KEY = None
    st.error("‚ùå Le secret 'DEEPSEEK_API_KEY' est introuvable. Veuillez le configurer.")

# -------------------- Streamlit Page Config --------------------
st.set_page_config(
    page_title="Analyse CV AI",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------- CSS --------------------
st.markdown("""
<style>
div[data-testid="stTabs"] button p {
    font-size: 18px; 
}
.stTextArea textarea {
    white-space: pre-wrap !important;
}
</style>
""", unsafe_allow_html=True)

# -------------------- Chargement des mod√®les ML (mis en cache) --------------------

# --- NOUVEAUT√â : Mise en cache des mod√®les pour la performance ---
@st.cache_resource
def load_spacy_model():
    """Charge le mod√®le spaCy une seule fois."""
    return spacy.load("fr_core_news_sm")

@st.cache_resource
def load_embedding_model():
    """Charge le mod√®le SentenceTransformer une seule fois."""
    return SentenceTransformer('all-MiniLM-L6-v2')

# Charger les mod√®les au d√©marrage
nlp = load_spacy_model()
embedding_model = load_embedding_model()


# -------------------- Fonctions de traitement des CV --------------------
def extract_text_from_pdf(file):
    """Extrait le texte d'un fichier PDF."""
    try:
        pdf = PdfReader(file)
        text = ""
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
        return text.strip() if text else "Aucun texte lisible trouv√©."
    except Exception as e:
        return f"Erreur d'extraction du texte: {str(e)}"

# --- M√âTHODE 1 : SIMILARIT√â COSINUS (EXISTANTE) ---
def rank_resumes_with_cosine(job_description, resumes):
    """Classe les CVs en utilisant la similarit√© cosinus (TF-IDF)."""
    try:
        documents = [job_description] + resumes
        vectorizer = TfidfVectorizer().fit_transform(documents)
        vectors = vectorizer.toarray()
        cosine_similarities = cosine_similarity([vectors[0]], vectors[1:]).flatten()
        return cosine_similarities
    except Exception as e:
        st.error(f"‚ùå Erreur Cosinus: {e}")
        return []

# --- NOUVEAUT√â : M√âTHODE 2 : WORD EMBEDDINGS ---
def rank_resumes_with_embeddings(job_description, resumes):
    """Classe les CVs en utilisant la similarit√© s√©mantique (Sentence-BERT)."""
    try:
        # Encodage des textes en vecteurs s√©mantiques
        jd_embedding = embedding_model.encode(job_description, convert_to_tensor=True)
        resume_embeddings = embedding_model.encode(resumes, convert_to_tensor=True)
        
        # Calcul de la similarit√© cosinus sur les vecteurs s√©mantiques
        cosine_scores = util.pytorch_cos_sim(jd_embedding, resume_embeddings)
        return cosine_scores.flatten().cpu().numpy()
    except Exception as e:
        st.error(f"‚ùå Erreur Embeddings: {e}")
        return []

# --- NOUVEAUT√â : M√âTHODE 3 : SCORING PAR R√àGLES (NER) ---
def rank_resumes_with_ner(job_description, resumes):
    """Classe les CVs en utilisant un scoring bas√© sur des r√®gles et la NER."""
    
    # --- PERSONNALISEZ VOS R√àGLES ICI ---
    # D√©finissez les comp√©tences cl√©s que vous recherchez
    SKILLS_TECH = ["python", "sql", "pandas", "streamlit", "docker", "git"]
    SKILLS_SOFT = ["gestion de projet", "communication", "leadership", "agile"]
    
    scores = []
    for resume_text in resumes:
        doc = nlp(resume_text.lower())
        
        current_score = 0
        
        # R√®gle 1 : Points pour les comp√©tences techniques
        found_tech_skills = [skill for skill in SKILLS_TECH if skill in doc.text]
        current_score += len(found_tech_skills) * 10 # 10 points par comp√©tence technique
        
        # R√®gle 2 : Points pour les soft skills
        found_soft_skills = [skill for skill in SKILLS_SOFT if skill in doc.text]
        current_score += len(found_soft_skills) * 5 # 5 points par soft skill
        
        # R√®gle 3 : Points pour l'exp√©rience (exemple simple)
        if re.search(r"(\d+)\s*(ans|ann√©es)\s*d'exp√©rience", doc.text):
            current_score += 15 # Bonus si le nombre d'ann√©es est mentionn√©
            
        scores.append(current_score)

    # Normaliser les scores entre 0 et 1 pour la coh√©rence
    max_score = sum([10 for _ in SKILLS_TECH]) + sum([5 for _ in SKILLS_SOFT]) + 15
    if max_score > 0:
        normalized_scores = [s / max_score for s in scores]
    else:
        normalized_scores = [0.0 for _ in scores]
        
    return normalized_scores

# --- M√âTHODE 4 : ANALYSE PAR IA (EXISTANTE) ---
def get_detailed_score_with_ai(job_description, resume_text):
    """√âvalue la pertinence d'un CV en utilisant l'IA."""
    # ... (Le reste de votre fonction get_detailed_score_with_ai reste identique) ...
    if not API_KEY:
        return {"score": 0.0, "explanation": "‚ùå Analyse IA impossible. Cl√© API non configur√©e."}
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    prompt = f"""
    En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
    Fournis ta r√©ponse en deux parties :
    1. Un score de correspondance en pourcentage (ex: "Score: 85%").
    2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.

    ---
    Description du poste:
    {job_description}
    ---
    Texte du CV:
    {resume_text}
    ---
    """
    payload = {"model": "deepseek-chat", "messages": [{"role": "system", "content": "You are a professional recruiter assistant."}, {"role": "user", "content": prompt}], "stream": False, "temperature": 0.0}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        full_response_text = response.json()["choices"][0]["message"]["content"].strip()
        score_match = re.search(r"Score:\s*(\d+)%", full_response_text)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        return {"score": score, "explanation": full_response_text}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erreur IA: {e}")
        return {"score": 0.0, "explanation": "‚ùå Analyse IA √©chou√©e."}

def rank_resumes_with_ai(job_description, resumes, file_names):
    """Classe les CVs en utilisant l'IA."""
    # ... (Votre fonction rank_resumes_with_ai reste identique) ...
    scores_data = []
    for i, resume_text in enumerate(resumes):
        detailed_response = get_detailed_score_with_ai(job_description, resume_text)
        scores_data.append({"file_name": file_names[i], "score": detailed_response["score"], "explanation": detailed_response["explanation"]})
    return scores_data

# ... (Votre fonction get_deepseek_analysis pour l'onglet 2 reste identique) ...
def get_deepseek_analysis(text):
    #...
    return "Analyse..."


# -------------------- INTERFACE UTILISATEUR --------------------
st.title("üìÑ Analyseur de CVs Intelligent")

tab1, tab2 = st.tabs(["üìä Classement de CVs", "üéØ Analyse de Profil"])

# -------------------- ONGLET 1 : CLASSEMENT --------------------
with tab1:
    st.markdown("### üìÑ Informations du Poste")
    job_description = st.text_area("Description du poste", placeholder="Coller la description compl√®te du poste ici...", height=250)
    
    st.markdown("### üì§ Importer des CVs")
    uploaded_files_ranking = st.file_uploader(
        "S√©lectionnez les CVs (PDF)",
        type=["pdf"],
        accept_multiple_files=True,
        key="ranking_uploader"
    )
    
    st.markdown("---")
    
    # --- NOUVEAUT√â : S√©lecteur avec les 4 m√©thodes ---
    analysis_method = st.radio(
        "‚ú® Choisissez votre m√©thode d'analyse",
        [
            "Similarit√© Cosinus (Mots-cl√©s)", 
            "Similarit√© S√©mantique (Embeddings)", 
            "Scoring par R√®gles (NER)", 
            "Analyse par IA (DeepSeek)"
        ],
        index=0,
        help="""
        - **Cosinus**: Rapide, bas√© sur la fr√©quence des mots-cl√©s.
        - **S√©mantique**: Plus intelligent, comprend le sens des phrases.
        - **R√®gles (NER)**: Transparent, bas√© sur des crit√®res que vous pouvez d√©finir dans le code.
        - **IA DeepSeek**: Le plus puissant, analyse contextuelle compl√®te (utilise votre cl√© API).
        """
    )
    
    if st.button("üîç Analyser et Classer les CVs", type="primary", use_container_width=True, disabled=not (uploaded_files_ranking and job_description)):
        with st.spinner("üîç Analyse en cours... Cette op√©ration peut prendre quelques instants."):
            resumes, file_names = [], []
            for file in uploaded_files_ranking:
                text = extract_text_from_pdf(file)
                if not "Erreur" in text:
                    resumes.append(text)
                    file_names.append(file.name)
            
            scores = []
            explanations = None
            
            if analysis_method == "Similarit√© Cosinus (Mots-cl√©s)":
                scores = rank_resumes_with_cosine(job_description, resumes)
            elif analysis_method == "Similarit√© S√©mantique (Embeddings)":
                scores = rank_resumes_with_embeddings(job_description, resumes)
            elif analysis_method == "Scoring par R√®gles (NER)":
                scores = rank_resumes_with_ner(job_description, resumes)
            elif analysis_method == "Analyse par IA (DeepSeek)":
                ai_results = rank_resumes_with_ai(job_description, resumes, file_names)
                scores = [res["score"] for res in ai_results]
                explanations = {res["file_name"]: res["explanation"] for res in ai_results}

            if len(scores) > 0:
                ranked_resumes = sorted(zip(file_names, scores), key=lambda x: x[1], reverse=True)
                
                results_df = pd.DataFrame({
                    "Rang": range(1, len(ranked_resumes) + 1),
                    "Nom du CV": [name for name, _ in ranked_resumes],
                    "Score": [f"{score * 100:.1f}%" for _, score in ranked_resumes],
                })
                
                st.markdown("### üèÜ R√©sultats du Classement")
                st.dataframe(results_df, use_container_width=True, hide_index=True)

                if explanations:
                    st.markdown("### üìù Analyse d√©taill√©e par l'IA")
                    for file_name, score in ranked_resumes:
                        with st.expander(f"**{file_name}** (Score: {score * 100:.1f}%)"):
                            st.markdown(explanations[file_name])
            else:
                st.error("‚ùå Aucun CV n'a pu √™tre analys√©.")

# -------------------- ONGLET 2 : ANALYSE DE PROFIL --------------------
with tab2:
    st.markdown("### üìÇ Importer un CV pour une analyse d√©taill√©e")
    uploaded_file_analysis = st.file_uploader(
        "S√©lectionnez un CV (PDF)",
        type=["pdf"],
        accept_multiple_files=False, # Un seul fichier pour l'analyse d√©taill√©e
        key="analysis_uploader"
    )
    
    if uploaded_file_analysis:
        if st.button("üöÄ Lancer l'analyse du profil", type="primary", use_container_width=True):
            with st.spinner("‚è≥ L'IA analyse le profil..."):
                text = extract_text_from_pdf(uploaded_file_analysis)
                if "Erreur" in text:
                    st.error(f"‚ùå Erreur d'extraction: {text}")
                else:
                    analysis_result = get_deepseek_analysis(text) # Assurez-vous que cette fonction est compl√®te
                    st.markdown("### üìã Analyse du Profil")
                    st.markdown(analysis_result)