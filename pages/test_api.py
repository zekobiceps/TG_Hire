import streamlit as st
import pandas as pd
import io
import requests
import json
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
import re

# Imports pour la m√©thode s√©mantique
from sentence_transformers import SentenceTransformer, util
import torch

# -------------------- Configuration de la cl√© API DeepSeek --------------------
try:
    API_KEY = st.secrets["DEEPSEEK_API_KEY"]
except KeyError:
    API_KEY = None
    st.error("‚ùå Le secret 'DEEPSEEK_API_KEY' est introuvable. Veuillez le configurer.")

# -------------------- Streamlit Page Config --------------------
st.set_page_config(
    page_title="Analyse CV AI",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------- CSS --------------------
st.markdown("""
<style>
div[data-testid="stTabs"] button p {
    font-size: 18px; 
}
.stTextArea textarea {
    white-space: pre-wrap !important;
}
</style>
""", unsafe_allow_html=True)

# -------------------- Chargement des mod√®les ML (mis en cache) --------------------
@st.cache_resource
def load_embedding_model():
    """Charge le mod√®le SentenceTransformer une seule fois."""
    return SentenceTransformer('all-MiniLM-L6-v2')

embedding_model = load_embedding_model()

# -------------------- Fonctions de traitement --------------------
def extract_text_from_pdf(file):
    try:
        pdf = PdfReader(file)
        text = "".join(page.extract_text() for page in pdf.pages if page.extract_text())
        return text.strip() if text else "Aucun texte lisible trouv√©."
    except Exception as e:
        return f"Erreur d'extraction du texte: {str(e)}"

# --- M√âTHODE 1 : SIMILARIT√â COSINUS ---
def rank_resumes_with_cosine(job_description, resumes):
    try:
        documents = [job_description] + resumes
        vectorizer = TfidfVectorizer().fit_transform(documents)
        vectors = vectorizer.toarray()
        cosine_similarities = cosine_similarity([vectors[0]], vectors[1:]).flatten()
        return {"scores": cosine_similarities}
    except Exception as e:
        st.error(f"‚ùå Erreur Cosinus: {e}")
        return {"scores": []}

# --- M√âTHODE 2 : WORD EMBEDDINGS ---
def rank_resumes_with_embeddings(job_description, resumes):
    try:
        jd_embedding = embedding_model.encode(job_description, convert_to_tensor=True)
        resume_embeddings = embedding_model.encode(resumes, convert_to_tensor=True)
        cosine_scores = util.pytorch_cos_sim(jd_embedding, resume_embeddings)
        return {"scores": cosine_scores.flatten().cpu().numpy()}
    except Exception as e:
        st.error(f"‚ùå Erreur S√©mantique : {e}")
        return {"scores": []}

# --- ANALYSE PAR REGEX ---
def regex_analysis(text):
    text_lower = text.lower()
    SKILLS_TECH = ["ged", "edms", "archivage", "d√©mat√©rialisation", "num√©risation", "sap", "aconex", "oracle", "jira"]
    SKILLS_SOFT = ["gestion de projet", "communication", "leadership", "rigueur", "analyse", "collaboration", "animation d'√©quipe"]
    found_tech = {skill for skill in SKILLS_TECH if re.search(r'\b' + re.escape(skill) + r'\b', text_lower)}
    found_soft = {skill for skill in SKILLS_SOFT if re.search(r'\b' + re.escape(skill) + r'\b', text_lower)}
    experience_match = re.search(r"(\d+)\s*(ans|ann√©es)\s*d'exp√©rience", text_lower)
    experience = int(experience_match.group(1)) if experience_match else 0
    return {
        "Comp√©tences Techniques": list(found_tech),
        "Comp√©tences Comportementales": list(found_soft),
        "Ann√©es d'exp√©rience d√©tect√©es": experience
    }

# --- NOUVEAUT√â : SCORING PAR R√àGLES RENVOYANT LA LOGIQUE ---
def rank_resumes_with_rules(job_description, resumes, file_names):
    jd_entities = regex_analysis(job_description)
    results = []
    
    TECH_SKILL_WEIGHT = 10
    EXPERIENCE_WEIGHT = 20
    
    for i, resume_text in enumerate(resumes):
        resume_entities = regex_analysis(resume_text)
        current_score = 0
        
        logic = {}
        
        common_tech_skills = set(jd_entities["Comp√©tences Techniques"]) & set(resume_entities["Comp√©tences Techniques"])
        score_from_tech = len(common_tech_skills) * TECH_SKILL_WEIGHT
        current_score += score_from_tech
        logic['Comp√©tences Techniques trouv√©es'] = f"{list(common_tech_skills)} (+{score_from_tech} pts)"

        required_exp = jd_entities.get("Ann√©es d'exp√©rience d√©tect√©es", 0)
        candidate_exp = resume_entities.get("Ann√©es d'exp√©rience d√©tect√©es", 0)
        score_from_exp = 0
        if required_exp > 0 and candidate_exp >= required_exp:
            score_from_exp = EXPERIENCE_WEIGHT
            current_score += score_from_exp
        logic['Exp√©rience'] = f"{candidate_exp} ans d√©tect√©s vs {required_exp} requis (+{score_from_exp} pts)"

        results.append({
            "file_name": file_names[i],
            "score": current_score,
            "logic": logic
        })

    max_possible_score = len(jd_entities["Comp√©tences Techniques"]) * TECH_SKILL_WEIGHT
    if jd_entities.get("Ann√©es d'exp√©rience d√©tect√©es", 0) > 0:
        max_possible_score += EXPERIENCE_WEIGHT

    if max_possible_score > 0:
        for res in results:
            res["score"] /= max_possible_score
            
    return results

# --- M√âTHODE 4 : ANALYSE PAR IA ---
def get_detailed_score_with_ai(job_description, resume_text):
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Analyse IA impossible. Cl√© API non configur√©e."}
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    prompt = f"""
    En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
    Fournis ta r√©ponse en deux parties :
    1. Un score de correspondance en pourcentage (ex: "Score: 85%").
    2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
    ---
    Description du poste: {job_description}
    ---
    Texte du CV: {resume_text}
    """
    payload = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.0}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        full_response_text = response.json()["choices"][0]["message"]["content"]
        score_match = re.search(r"Score:\s*(\d+)%", full_response_text)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        return {"score": score, "explanation": full_response_text}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erreur IA : {e}")
        return {"score": 0.0, "explanation": "Erreur"}

def rank_resumes_with_ai(job_description, resumes, file_names):
    scores_data = []
    for i, resume_text in enumerate(resumes):
        detailed_response = get_detailed_score_with_ai(job_description, resume_text)
        scores_data.append({
            "file_name": file_names[i],
            "score": detailed_response["score"],
            "explanation": detailed_response["explanation"]
        })
    return {"scores": [d["score"] for d in scores_data], "explanations": {d["file_name"]: d["explanation"] for d in scores_data}}

def get_deepseek_analysis(text):
    if not API_KEY: return "Analyse impossible."
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    prompt = f"""
    En tant qu'expert en recrutement, analyse le CV suivant.
    Identifie les points forts et les points faibles de ce candidat sous des titres d√©di√©s.
    Voici le texte du CV : {text}
    """
    payload = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}]}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Erreur IA : {e}"

# -------------------- Interface Utilisateur --------------------
st.title("üìÑ Analyseur de CVs Intelligent")

tab1, tab2, tab3 = st.tabs(["üìä Classement de CVs", "üéØ Analyse de Profil", "üìñ Guide des M√©thodes"])

# --- ONGLET CLASSEMENT ---
with tab1:
    st.markdown("### üìÑ Informations du Poste")
    # --- NOUVEAUT√â : Retour de la disposition en colonnes ---
    col1, col2 = st.columns([2, 1])
    with col1:
        job_title = st.text_input("Intitul√© du poste", placeholder="Ex: Chef de projet GED")
        job_description = st.text_area("Description du poste", height=200, key="jd_ranking", placeholder="Collez la description compl√®te du poste ici...")
    with col2:
        st.markdown("#### üì§ Importer des CVs")
        uploaded_files_ranking = st.file_uploader("Importer des CVs", type=["pdf"], accept_multiple_files=True, key="ranking_uploader")
    
    st.markdown("---")
    
    analysis_method = st.radio(
        "‚ú® Choisissez votre m√©thode de classement",
        ["Similarit√© Cosinus (Mots-cl√©s)", "Similarit√© S√©mantique (Embeddings)", "Scoring par R√®gles (Regex)", "Analyse par IA (DeepSeek)"],
        index=0, help="Consultez l'onglet 'Guide des M√©thodes'."
    )

    if st.button("üîç Analyser et Classer", type="primary", use_container_width=True, disabled=not (uploaded_files_ranking and job_description)):
        resumes, file_names = [], []
        with st.spinner("Lecture des fichiers PDF..."):
            for file in uploaded_files_ranking:
                text = extract_text_from_pdf(file)
                if not "Erreur" in text:
                    resumes.append(text)
                    file_names.append(file.name)
        
        with st.spinner("Analyse des CVs en cours..."):
            results, explanations, logic = None, None, None
            if analysis_method == "Analyse par IA (DeepSeek)":
                results = rank_resumes_with_ai(job_description, resumes, file_names)
                explanations = results.get("explanations")
            elif analysis_method == "Scoring par R√®gles (Regex)":
                rule_results = rank_resumes_with_rules(job_description, resumes, file_names)
                results = {"scores": [r["score"] for r in rule_results]}
                logic = {r["file_name"]: r["logic"] for r in rule_results}
            elif analysis_method == "Similarit√© S√©mantique (Embeddings)":
                results = rank_resumes_with_embeddings(job_description, resumes)
            else: # Cosinus par d√©faut
                results = rank_resumes_with_cosine(job_description, resumes)

            scores = results.get("scores", [])
            if scores:
                ranked_resumes = sorted(zip(file_names, scores), key=lambda x: x[1], reverse=True)
                results_df = pd.DataFrame(ranked_resumes, columns=["Nom du CV", "Score brut"])
                results_df["Rang"] = range(1, len(results_df) + 1)
                results_df["Score"] = results_df["Score brut"].apply(lambda x: f"{x*100:.1f}%")
                
                st.markdown("### üèÜ R√©sultats du Classement")
                st.dataframe(results_df[["Rang", "Nom du CV", "Score"]], use_container_width=True, hide_index=True)
                
                # --- NOUVEAUT√â : Affichage de la logique de scoring pour Regex ---
                if logic:
                    st.markdown("### üß† Logique de Scoring (R√®gles)")
                    for _, row in results_df.iterrows():
                        file_name = row["Nom du CV"]
                        with st.expander(f"D√©tail du score pour : **{file_name}**"):
                            st.json(logic.get(file_name, "Aucun d√©tail disponible."))

                if explanations:
                    st.markdown("### üìù Analyse d√©taill√©e par l'IA")
                    for _, row in results_df.iterrows():
                        file_name = row["Nom du CV"]
                        score = row["Score brut"]
                        with st.expander(f"Analyse pour : **{file_name}** (Score: {score*100:.1f}%)"):
                            st.markdown(explanations.get(file_name, "Aucune explication disponible."))

# --- ONGLET ANALYSE DE PROFIL ---
with tab2:
    st.markdown("### üìÇ Importer un ou plusieurs CVs pour une analyse individuelle")
    # --- NOUVEAUT√â : Correction du bug, on peut uploader plusieurs fichiers ---
    uploaded_files_analysis = st.file_uploader("Importer des CVs", type=["pdf"], key="analysis_uploader", accept_multiple_files=True)
    
    # --- NOUVEAUT√â : Les 4 m√©thodes sont disponibles ---
    analysis_type_single = st.selectbox(
        "Type d'analyse souhait√©",
        ("Analyse par IA (DeepSeek)", "Analyse par Regex (Extraction d'entit√©s)", "Score S√©mantique", "Score Cosinus")
    )
    # --- NOUVEAUT√â : Explications sous le menu d√©roulant ---
    captions = {
        "Analyse par IA (DeepSeek)": "Analyse qualitative (points forts/faibles) par un LLM. Consomme vos tokens !",
        "Analyse par Regex (Extraction d'entit√©s)": "Extrait des informations structur√©es (comp√©tences, etc.) sur la base de mots-cl√©s.",
        "Score S√©mantique": "Calcule un score de pertinence bas√© sur le sens des phrases (n√©cessite une description de poste).",
        "Score Cosinus": "Calcule un score de pertinence bas√© sur les mots-cl√©s (n√©cessite une description de poste)."
    }
    st.caption(captions.get(analysis_type_single))

    # --- NOUVEAUT√â : On demande la description de poste si n√©cessaire ---
    job_desc_single = ""
    if "Score" in analysis_type_single:
        job_desc_single = st.text_area("Description du poste pour le calcul du score", height=150, key="jd_single")

    if uploaded_files_analysis and st.button("üöÄ Lancer l'analyse", type="primary", use_container_width=True):
        # --- NOUVEAUT√â : Boucle pour analyser tous les fichiers ---
        for uploaded_file in uploaded_files_analysis:
            with st.expander(f"R√©sultat pour : **{uploaded_file.name}**", expanded=True):
                with st.spinner("Analyse en cours..."):
                    text = extract_text_from_pdf(uploaded_file)
                    if "Erreur" in text:
                        st.error(f"‚ùå {text}")
                    else:
                        if analysis_type_single == "Analyse par Regex (Extraction d'entit√©s)":
                            entities = regex_analysis(text)
                            st.info("**Entit√©s extraites par la m√©thode Regex**")
                            st.json(entities)
                        elif "Score S√©mantique" in analysis_type_single:
                            if not job_desc_single: st.warning("Veuillez fournir une description de poste.")
                            else:
                                score = rank_resumes_with_embeddings(job_desc_single, [text])["scores"][0]
                                st.metric("Score de Pertinence S√©mantique", f"{score*100:.1f}%")
                        elif "Score Cosinus" in analysis_type_single:
                            if not job_desc_single: st.warning("Veuillez fournir une description de poste.")
                            else:
                                score = rank_resumes_with_cosine(job_desc_single, [text])["scores"][0]
                                st.metric("Score de Pertinence Cosinus", f"{score*100:.1f}%")
                        else: # Analyse IA par d√©faut
                            analysis_result = get_deepseek_analysis(text)
                            st.markdown(analysis_result)

# --- ONGLET GUIDE DES M√âTHODES ---
with tab3:
    st.header("üìñ Comprendre les M√©thodes d'Analyse")
    st.markdown("Chaque m√©thode a ses propres forces et faiblesses. Voici un guide pour vous aider √† choisir la plus adapt√©e √† votre besoin.")
    
    # --- NOUVEAUT√â : Explications beaucoup plus d√©taill√©es ---
    st.subheader("1. Similarit√© Cosinus (Bas√©e sur les Mots-cl√©s)")
    st.markdown("""
    - **Principe** : Cette m√©thode transforme le CV et l'annonce en listes de mots-cl√©s, puis compte combien de mots importants sont communs aux deux documents.
    - **Comment √ßa marche ?** Elle utilise un mod√®le math√©matique (TF-IDF) pour donner plus de poids aux mots rares et importants (comme "archivage") qu'aux mots tr√®s courants (comme "le", "de"). Le score repr√©sente la similarit√© de ces "sacs de mots-cl√©s".
    - **Id√©al pour** : Un premier tri tr√®s rapide et grossier.
    - **Avantages** : ‚úÖ Extr√™mement rapide, ne n√©cessite aucune IA externe.
    - **Limites** : ‚ùå Ne comprend absolument pas le contexte ou les synonymes. Pour lui, "GED" (Gestion √âlectronique de Documents) et "EDMS" (Electronic Document Management System) sont deux termes compl√®tement diff√©rents.
    """)
    
    st.subheader("2. Similarit√© S√©mantique (Bas√©e sur les Embeddings)")
    st.markdown("""
    - **Principe** : Utilise un mod√®le de langage pr√©-entra√Æn√© (ici, `Sentence-BERT`) pour convertir les phrases en vecteurs num√©riques qui repr√©sentent leur signification.
    - **Comment √ßa marche ?** Au lieu de comparer des mots, on compare la "direction" de ces vecteurs dans un espace √† plusieurs dimensions. Deux vecteurs qui pointent dans la m√™me direction repr√©sentent des id√©es s√©mantiquement similaires.
    - **Id√©al pour** : Obtenir un score de pertinence plus intelligent qui comprend les nuances du langage.
    - **Avantages** : ‚úÖ Comprend le contexte, les synonymes et les concepts similaires. C'est un excellent √©quilibre entre vitesse et intelligence.
    - **Limites** : ‚ùå Un peu plus lente que la m√©thode cosinus car elle fait appel √† un mod√®le de deep learning.
    """)

    st.subheader("3. Scoring par R√®gles (Bas√© sur Regex)")
    st.markdown("""
    - **Principe** : Imite la fa√ßon dont un recruteur humain lit un CV en cherchant des informations sp√©cifiques. On d√©finit des r√®gles claires (ex: "trouver ces comp√©tences", "v√©rifier les ann√©es d'exp√©rience") et on attribue des points.
    - **Comment √ßa marche ?** Le code utilise des expressions r√©guli√®res (Regex) pour rechercher des mots-cl√©s pr√©cis et des sch√©mas de texte (comme "X ans d'exp√©rience") dans le CV. Un score est ensuite calcul√© en fonction de ce qui a √©t√© trouv√©.
    - **Id√©al pour** : Des postes o√π les crit√®res sont tr√®s clairs et objectifs (ex: "doit avoir la comp√©tence X et plus de 5 ans d'exp√©rience").
    - **Avantages** : ‚úÖ Totalement transparent (le d√©tail du score peut √™tre affich√©), 100% personnalisable et sans d√©pendances complexes.
    - **Limites** : ‚ùå Tr√®s rigide. Si une comp√©tence est formul√©e diff√©remment de ce qui est pr√©vu dans les r√®gles, elle ne sera pas d√©tect√©e.
    """)
    
    st.subheader("4. Analyse par IA (Bas√©e sur un LLM)")
    st.markdown("""
    - **Principe** : C'est la m√©thode la plus avanc√©e. On envoie le CV et l'annonce √† un grand mod√®le de langage (ici, DeepSeek), en lui demandant d'agir comme un expert en recrutement et de donner son avis.
    - **Comment √ßa marche ?** L'IA lit et comprend les deux textes dans leur int√©gralit√©, puis utilise sa vaste connaissance pour √©valuer la pertinence, identifier les forces et les faiblesses, et formuler une explication d√©taill√©e.
    - **Id√©al pour** : Obtenir une analyse fine et contextuelle, similaire √† celle d'un premier entretien.
    - **Avantages** : ‚úÖ La plus pr√©cise et la plus "humaine". Comprend les nuances, l'exp√©rience implicite et peut fournir des explications de haute qualit√©.
    - **Limites** : ‚ùå La plus lente, et chaque analyse **consomme vos tokens !**
    """)

# --- SIDEBAR ---
with st.sidebar:
    st.markdown("### üîß Configuration")
    if st.button("Test Connexion API DeepSeek"):
        if API_KEY:
            try:
                response = requests.get("https://api.deepseek.com/v1/models", headers={"Authorization": f"Bearer {API_KEY}"})
                st.success("‚úÖ Connexion API r√©ussie") if response.status_code == 200 else st.error(f"‚ùå Erreur de connexion ({response.status_code})")
            except Exception as e:
                st.error(f"‚ùå Erreur: {e}")
        else:
            st.error("‚ùå Cl√© API non configur√©e")