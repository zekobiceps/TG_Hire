import streamlit as st
import pandas as pd
import io
import requests
import google.generativeai as genai
import anthropic
import groq
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
import re
import os
from datetime import datetime
from typing import cast
import plotly.graph_objects as go
import plotly.express as px
from utils import display_commit_info

# Imports optionnels pour la manipulation des PDF (s'il manque, le code utilisera des fallbacks)
try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None

try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None

try:
    import pdfplumber
except Exception:
    pdfplumber = None

try:
    import PyPDF2
except Exception:
    PyPDF2 = None

try:
    from pypdf import PdfReader as PypdfReader
except Exception:
    PypdfReader = None

# Imports pour OCR (Cas des CV scann√©s)
try:
    import pytesseract
    from pdf2image import convert_from_path, convert_from_bytes
except Exception:
    pytesseract = None
    convert_from_path = None

# Imports pour la m√©thode s√©mantique
from sentence_transformers import SentenceTransformer, util
import torch

# Import des fonctions avanc√©es d'analyse
from utils import (rank_resumes_with_ensemble, batch_process_resumes, 
                 save_feedback, get_average_feedback_score, get_feedback_summary)

# -------------------- Configuration de la cl√© API DeepSeek --------------------
# --- CORRECTION : D√©plac√© √† l'int√©rieur des fonctions pour √©viter l'erreur au d√©marrage ---

# -------------------- Streamlit Page Config --------------------
st.set_page_config(
    page_title="Analyse CV AI",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# V√©rification de la connexion
if not st.session_state.get("logged_in", False):
    st.stop()

# --- V√©rification unique de la cl√© API DeepSeek au d√©marrage ---
# Cette v√©rification est silencieuse ici pour √©viter de bloquer ou d'afficher des erreurs avant le chargement complet
_deepseek_api_available = False
try:
    if "DEEPSEEK_API_KEY" in st.secrets:
        _deepseek_api_available = True
except Exception:
    pass


# Initialisation des variables de session
if "cv_analysis_feedback" not in st.session_state:
    st.session_state.cv_analysis_feedback = False
if "last_analysis_method" not in st.session_state:
    st.session_state.last_analysis_method = None
if "last_analysis_result" not in st.session_state:
    st.session_state.last_analysis_result = None
if "last_job_title" not in st.session_state:
    st.session_state.last_job_title = ""
if "last_job_description" not in st.session_state:
    st.session_state.last_job_description = ""
if "last_cv_count" not in st.session_state:
    st.session_state.last_cv_count = 0
    
# Variables pour le syst√®me de feedback persistent
if "show_feedback_form" not in st.session_state:
    st.session_state.show_feedback_form = False
if "feedback_submitted" not in st.session_state:
    st.session_state.feedback_submitted = False
if "global_feedback_score" not in st.session_state:
    st.session_state.global_feedback_score = 3
    
# Variables pour conserver les r√©sultats de l'analyse m√™me apr√®s feedback
if "ranked_resumes" not in st.session_state:
    st.session_state.ranked_resumes = []
if "file_names" not in st.session_state:
    st.session_state.file_names = []
if "scores" not in st.session_state:
    st.session_state.scores = []

# -------------------- CSS --------------------
st.markdown("""
<style>
div[data-testid="stTabs"] button p {
    font-size: 18px; 
}
.stTextArea textarea {
    white-space: pre-wrap !important;
}
.feedback-box {
    padding: 1rem;
    border-radius: 0.5rem;
    background-color: #f0f8ff;
    margin-bottom: 1rem;
}
.feedback-title {
    font-size: 1.2rem;
    font-weight: bold;
    margin-bottom: 0.5rem;
}
.method-stats {
    padding: 0.5rem;
    border-radius: 0.3rem;
    background-color: #f5f5f5;
    margin: 0.2rem 0;
}
.progress-bar-container {
    width: 100%;
    height: 10px;
    background-color: #f0f0f0;
    border-radius: 5px;
    margin: 10px 0;
    overflow: hidden;
}
.progress-bar {
    height: 100%;
    background-color: #4CAF50;
    border-radius: 5px;
}
/* R√©duire la taille du texte des m√©triques */
[data-testid="metric-container"] {
    font-size: 0.8em !important;
}
[data-testid="metric-container"] > div:first-child {
    font-size: 0.75em !important;
}
[data-testid="metric-container"] > div:last-child {
    font-size: 0.7em !important;
}
</style>
""", unsafe_allow_html=True)

# -------------------- Chargement des mod√®les ML (mis en cache) --------------------
@st.cache_resource
def load_embedding_model():
    """Charge le mod√®le SentenceTransformer une seule fois de mani√®re s√©curis√©e."""
    try:
        # If the user provided a Hugging Face token in Streamlit secrets or env, expose it
        hf_token = None
        try:
            hf_token = st.secrets.get("HUGGINGFACEHUB_API_TOKEN") or st.secrets.get("HF_TOKEN")
        except Exception:
            hf_token = None

        # Also accept common env var names
        if not hf_token:
            hf_token = os.environ.get("HUGGINGFACEHUB_API_TOKEN") or os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACE_TOKEN") or os.environ.get("HF_HUB_TOKEN")

        if hf_token:
            # Ensure huggingface hub sees the token
            os.environ.setdefault("HUGGINGFACEHUB_API_TOKEN", hf_token)
            os.environ.setdefault("HF_TOKEN", hf_token)

        # Try the full HF repo path first, then the short name for backwards compatibility
        try:
            return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        except Exception:
            try:
                return SentenceTransformer('all-MiniLM-L6-v2')
            except Exception as e2:
                # If we hit rate limiting, give a clearer message
                msg = str(e2)
                hint = (
                    "V√©rifiez que le package 'sentence-transformers' est install√© et que vous avez acc√®s au mod√®le. "
                    "Si Hugging Face rate-limite votre IP, cr√©ez un token HF et mettez-le dans Streamlit secrets sous 'HUGGINGFACEHUB_API_TOKEN' ou en variable d'environnement 'HUGGINGFACEHUB_API_TOKEN'."
                )
                st.warning(f"‚ö†Ô∏è Impossible de charger le mod√®le s√©mantique (embedding). La m√©thode 'S√©mantique' sera indisponible. Erreur: {msg} {hint}")
                return None
    except Exception as e:
        msg = str(e)
        hint = (
            "V√©rifiez que le package 'sentence-transformers' est install√© et que vous avez acc√®s au mod√®le. "
            "Si vous chargez depuis Hugging Face, assurez-vous que le chemin est 'sentence-transformers/all-MiniLM-L6-v2' "
        )
        st.warning(f"‚ö†Ô∏è Impossible de charger le mod√®le s√©mantique (embedding). La m√©thode 'S√©mantique' sera indisponible. Erreur: {msg} {hint}")
        return None

embedding_model = load_embedding_model()

# -------------------- Fonctions de traitement --------------------
def get_api_key():
    """R√©cup√®re la cl√© API avec persistance en session state pour √©viter les pertes lors du rechargement."""
    # 1. V√©rifier si d√©j√† en session
    if "DEEPSEEK_API_KEY" in st.session_state:
        return st.session_state.DEEPSEEK_API_KEY
        
    api_key = None
    try:
        # 2. V√©rifier st.secrets
        if "DEEPSEEK_API_KEY" in st.secrets:
             api_key = st.secrets["DEEPSEEK_API_KEY"]
        # 3. V√©rifier variables d'environnement (fallback)
        if not api_key:
             api_key = os.environ.get("DEEPSEEK_API_KEY")
             
        if api_key:
            st.session_state.DEEPSEEK_API_KEY = api_key
            return api_key
    except Exception:
        pass
    return None

def extract_text_from_pdf(file):
    try:
        # Utiliser un buffer m√©moire pour plus de compatibilit√©
        import io
        try:
            file.seek(0)
            data = file.read()
            bio = io.BytesIO(data)
        except Exception:
            bio = file

        # 0) PyMuPDF (fitz) - PRIORIT√â ABSOLUE pour l'ordre de lecture
        # sort=True remet le texte dans l'ordre de lecture visuel (haut-gauche -> bas-droite)
        # C'est CRUCIAL pour les CVs o√π le nom est dans un en-t√™te graphique.
        if fitz:
            try:
                bio.seek(0)
                doc = fitz.open(stream=bio, filetype="pdf")
                text_parts = []
                for page in doc:
                    # sort=True est la cl√© ici pour √©viter que le nom ne finisse √† la fin du fichier
                    text_parts.append(page.get_text("text", sort=True))
                text = "\n".join(text_parts).strip()
                if len(text) > 50:  # Validation minimale
                    return text
            except Exception as e:
                print(f"fitz sorting error: {e}")

        # 1) pdfplumber (meilleur pour extraction de texte mise en page)
        try:
            import pdfplumber
            bio.seek(0)
            with pdfplumber.open(bio) as pdf:
                parts = []
                for page in pdf.pages:
                    pt = page.extract_text()
                    if pt:
                        parts.append(pt)
                text = "\n".join(parts).strip()
                if text:
                    return text
        except Exception as e:
            # Ignorer et essayer d'autres m√©thodes
            print(f"pdfplumber error: {e}")

        # 2) PyPDF2
        try:
            import PyPDF2
            bio.seek(0)
            reader = PyPDF2.PdfReader(bio)
            parts = []
            for page in reader.pages:
                try:
                    pt = page.extract_text()
                except Exception:
                    pt = None
                if pt:
                    parts.append(pt)
            text = "\n".join(parts).strip()
            if text:
                return text
        except Exception as e:
            print(f"PyPDF2 error: {e}")

        # 3) pypdf
        try:
            from pypdf import PdfReader as PypdfReader
            bio.seek(0)
            reader = PypdfReader(bio)
            parts = []
            for page in reader.pages:
                try:
                    pt = page.extract_text()
                except Exception:
                    pt = None
                if pt:
                    parts.append(pt)
            text = "\n".join(parts).strip()
            if text:
                return text
        except Exception as e:
            print(f"pypdf error: {e}")

        # Aucun texte extrait -> PDF probablement scann√© (images) ou prot√©g√©
        # Tentative OCR si disponible
        if pytesseract and convert_from_bytes:
            try:
                bio.seek(0)
                # On convertit le contenu du BytesIO en bytes
                pdf_bytes = bio.read()
                # On convertit la premi√®re page en image
                images = convert_from_bytes(pdf_bytes, first_page=1, last_page=1)
                if images:
                    ocr_text = pytesseract.image_to_string(images[0], lang='fra+eng')
                    if len(ocr_text.strip()) > 10:
                        return ocr_text
            except Exception as e:
                print(f"OCR failed: {e}")

        return "Aucun texte lisible trouv√©. Le PDF est peut-√™tre un scan (images) ou prot√©g√© par mot de passe."
    except Exception as e:
        return f"Erreur d'extraction du texte: {str(e)}"

# --- M√âTHODE 1 : SIMILARIT√â COSINUS (AVEC LOGIQUE) ---
def rank_resumes_with_cosine(job_description, resumes, file_names):
    try:
        documents = [job_description] + resumes
        vectorizer = TfidfVectorizer(stop_words='english').fit(documents)
        vectors = vectorizer.transform(documents).toarray()
        
        cosine_similarities = cosine_similarity([vectors[0]], vectors[1:]).flatten()
        
        logic = {}
        feature_names = vectorizer.get_feature_names_out()
        for i, resume_text in enumerate(resumes):
            jd_vector = vectors[0]
            resume_vector = vectors[i+1]
            common_keywords_indices = (jd_vector > 0) & (resume_vector > 0)
            common_keywords = feature_names[common_keywords_indices]
            logic[file_names[i]] = {"Mots-cl√©s communs importants": list(common_keywords[:10])}

        return {"scores": cosine_similarities, "logic": logic}
    except Exception as e:
        st.error(f"‚ùå Erreur Cosinus: {e}")
        return {"scores": [], "logic": {}}

# --- M√âTHODE 2 : WORD EMBEDDINGS (AVEC LOGIQUE) ---
def rank_resumes_with_embeddings(job_description, resumes, file_names):
    if embedding_model is None:
        st.error("‚ùå Le mod√®le s√©mantique n'est pas charg√©. Impossible d'utiliser cette m√©thode.")
        return {"scores": [0] * len(resumes), "logic": {}}
        
    try:
        jd_embedding = embedding_model.encode(job_description, convert_to_tensor=True)
        resume_embeddings = embedding_model.encode(resumes, convert_to_tensor=True)
        cosine_scores = util.pytorch_cos_sim(jd_embedding, resume_embeddings)
        scores = cosine_scores.flatten().cpu().numpy()

        logic = {}
        jd_sentences = [s.strip() for s in job_description.split('.') if len(s.strip()) > 10]
        if not jd_sentences: jd_sentences = [job_description]
        jd_sent_embeddings = embedding_model.encode(jd_sentences, convert_to_tensor=True)

        for i, resume_text in enumerate(resumes):
            resume_sentences = [s.strip() for s in resume_text.split('\n') if len(s.strip()) > 10]
            if not resume_sentences: continue
            resume_sent_embeddings = embedding_model.encode(resume_sentences, convert_to_tensor=True)
            
            similarity_matrix = util.pytorch_cos_sim(resume_sent_embeddings, jd_sent_embeddings)
            best_matches = {}
            for jd_idx, jd_sent in enumerate(jd_sentences):
                best_match_score, best_match_idx = torch.max(similarity_matrix[:, jd_idx], dim=0)
                if best_match_score > 0.5: # Seuil de pertinence
                     best_matches[jd_sent] = resume_sentences[best_match_idx.item()]
            logic[file_names[i]] = {"Phrases les plus pertinentes (Annonce -> CV)": best_matches}

        return {"scores": scores, "logic": logic}
    except Exception as e:
        st.error(f"‚ùå Erreur S√©mantique : {e}")
        return {"scores": [], "logic": {}}

# --- ANALYSE PAR REGEX AM√âLIOR√âE (AVEC CALCUL D'EXP√âRIENCE) ---
def regex_analysis(text):
    text_lower = text.lower()
    
    # --- CALCUL D'EXP√âRIENCE BAS√â SUR LES DATES ---
    total_experience_months = 0
    
    # Patterns pour diff√©rents formats de dates
    # 1. Format MM/YYYY - MM/YYYY
    # 2. Format Mois YYYY - Mois YYYY
    # 3. Format YYYY - YYYY
    # 4. Format p√©riode (X ans et Y mois)
    date_patterns = [
        # Format MM/YYYY - MM/YYYY ou Mois YYYY - Mois YYYY
        re.findall(r'(\d{1,2}/\d{4})\s*-\s*(\d{1,2}/\d{4}|aujourd\'hui|pr√©sent|jour|current)|([a-z√©√®√™√´√†√¢√§√¥√∂√π√ª√º√Ø√Æ√ß]+\.?\s+\d{4})\s*-\s*([a-z√©√®√™√´√†√¢√§√¥√∂√π√ª√º√Ø√Æ√ß]+\.?\s+\d{4}|aujourd\'hui|pr√©sent|jour|current)', text, re.IGNORECASE),
        # Format YYYY - YYYY
        re.findall(r'(?<!\d)(\d{4})\s*-\s*(\d{4}|aujourd\'hui|pr√©sent|jour|current)(?!\d)', text, re.IGNORECASE),
        # Format "X ans et Y mois" ou "X ann√©es d'exp√©rience"
        re.findall(r'(\d+)\s+ans?\s+(?:et\s+(\d+)\s+mois)?|(\d+)\s+ann√©es?\s+d[e\']exp√©rience', text, re.IGNORECASE)
    ]
    
    month_map = {
        # Fran√ßais
        "janvier": 1, "f√©vrier": 2, "mars": 3, "avril": 4, "mai": 5, "juin": 6, 
        "juillet": 7, "ao√ªt": 8, "septembre": 9, "octobre": 10, "novembre": 11, "d√©cembre": 12,
        "jan": 1, "f√©v": 2, "mar": 3, "avr": 4, "mai": 5, "juin": 6, 
        "juil": 7, "ao√ªt": 8, "sept": 9, "oct": 10, "nov": 11, "d√©c": 12,
        # Anglais
        "january": 1, "february": 2, "march": 3, "april": 4, "may": 5, "june": 6,
        "july": 7, "august": 8, "september": 9, "october": 10, "november": 11, "december": 12,
        "jan": 1, "feb": 2, "mar": 3, "apr": 4, "may": 5, "jun": 6,
        "jul": 7, "aug": 8, "sep": 9, "oct": 10, "nov": 11, "dec": 12
    }
    
    def parse_date(date_str):
        if not date_str:
            return None
            
        date_str = date_str.lower().strip().replace('.','').replace('√ª','u')
        
        # Traitement des mentions "aujourd'hui", "pr√©sent", etc.
        if any(current_term in date_str for current_term in ["aujourd'hui", "pr√©sent", "current", "jour"]):
            return datetime.now()
            
        # Pour le format ann√©e seule (YYYY)
        if re.match(r'^\d{4}$', date_str):
            return datetime(int(date_str), 1, 1)
            
        # Pour les formats avec mois en lettres
        for month_name, month_num in month_map.items():
            if month_name in date_str:
                year_match = re.search(r'\d{4}', date_str)
                if year_match:
                    year = int(year_match.group())
                    return datetime(year, month_num, 1)
                    
        # Format MM/YYYY par d√©faut
        try:
            return datetime.strptime(date_str, '%m/%Y')
        except ValueError:
            # En cas d'√©chec, on essaie de nettoyer davantage
            cleaned = re.sub(r'[^\d/]', '', date_str).strip()
            if re.match(r'^\d{1,2}/\d{4}$', cleaned):
                return datetime.strptime(cleaned, '%m/%Y')
                
        return None

    # Traitement du format MM/YYYY - MM/YYYY ou Mois YYYY - Mois YYYY
    for match in date_patterns[0]:
        try:
            start_str, end_str = match[0] or match[2], match[1] or match[3]
            
            start_date = parse_date(start_str)
            end_date = datetime.now() if any(current_term in end_str.lower() for current_term in ["aujourd'hui", "pr√©sent", "current", "jour"]) else parse_date(end_str)
            
            if start_date and end_date:
                duration = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)
                total_experience_months += max(0, duration)
        except Exception:
            continue
    
    # Traitement du format YYYY - YYYY
    for match in date_patterns[1]:
        try:
            start_year, end_year = match
            
            if any(current_term in end_year.lower() for current_term in ["aujourd'hui", "pr√©sent", "current", "jour"]):
                end_date = datetime.now()
                start_date = datetime(int(start_year), 1, 1)
            else:
                start_date = datetime(int(start_year), 1, 1)
                end_date = datetime(int(end_year), 12, 31)
                
            duration = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)
            total_experience_months += max(0, duration)
        except Exception:
            continue
    
    # Traitement des mentions explicites d'ann√©es d'exp√©rience
    for match in date_patterns[2]:
        try:
            years = int(match[0] or match[2] or 0)  # Ann√©es
            months = int(match[1] or 0)             # Mois (optionnel)
            
            total_experience_months += years * 12 + months
        except Exception:
            continue
    
    # Si aucune exp√©rience d√©tect√©e mais "X ans d'exp√©rience" est mentionn√© directement
    if total_experience_months == 0:
        # Recherche de mentions d'exp√©rience directes en fran√ßais et en anglais
        direct_exp_patterns = [
            r'(\d+)\s*(?:an(?:s|n√©(?:e|es))?)\s+d[\'e]\s*(?:exp√©rience|exp\.)',  # X ans d'exp√©rience
            r'exp√©rience\s+(?:de|d[\'e])\s+(\d+)\s*(?:an(?:s|n√©(?:e|es))?)',      # exp√©rience de X ans
            r'(\d+)\s*(?:year(?:s)?)\s+(?:of)?\s*experience',                    # X years experience (EN)
            r'experience\s+(?:of)?\s+(\d+)\s*(?:year(?:s)?)',                    # experience of X years (EN)
        ]
        
        for pattern in direct_exp_patterns:
            direct_exp_match = re.search(pattern, text_lower)
            if direct_exp_match:
                try:
                    years = int(direct_exp_match.group(1))
                    total_experience_months = years * 12
                    break
                except:
                    continue
    
    # Arrondi √† l'ann√©e la plus proche
    total_experience_years = round(total_experience_months / 12)

    education_level = 0
    # Patterns d'√©ducation am√©lior√©s avec √©quivalents internationaux
    edu_patterns = {
        8: r'doctorat|phd|ph\.d|docteur|doctorate',
        5: r'bac\s*\+\s*5|master|m\.?sc\.?|ing√©nieur|mba|dipl√¥me\s+d[\'e]ing√©nieur',
        3: r'bac\s*\+\s*3|licence|bachelor|b\.?sc\.?|dipl√¥me\s+universitaire\s+de\s+technologie|d\.?u\.?t',
        2: r'bac\s*\+\s*2|bts|dut|deug',
        0: r'baccalaur√©at|bac|high\s+school|secondary\s+education'
    }
    
    # On commence par rechercher le dipl√¥me le plus √©lev√©
    levels = sorted(edu_patterns.keys(), reverse=True)
    for level in levels:
        pattern = edu_patterns[level]
        if re.search(pattern, text_lower):
            education_level = level
            break
            
    skills = []
    
    # Recherche de sections sp√©cifiques o√π les comp√©tences peuvent se trouver
    skill_sections = [
        r"(?:comp√©tences|skills|competences)\s*(?:techniques|technical)?\s*[:;](.*?)(?:\n\n|\Z)",
        r"(?:profil|profile)\s+(?:recherch√©|sought|technique|technical)\s*[:;](.*?)(?:\n\n|\Z)",
        r"(?:technologies|outils|tools|langages|languages)\s*[:;](.*?)(?:\n\n|\Z)",
        r"(?:expertise|savoir-faire)\s*[:;](.*?)(?:\n\n|\Z)"
    ]
    
    # Stop words plus complets (FR/EN)
    stop_words = [
        # Fran√ßais
        "profil", "recherch√©", "ma√Ætrise", "bonne", "exp√©rience", "esprit", "bas√©", "casablanca", 
        "missions", "principales", "confirm√©e", "id√©alement", "selon", "avoir", "√™tre", "connaissance",
        "capable", "capacit√©", "aptitude", "comp√©tence", "technique", "solide", "avanc√©e",
        # Anglais
        "profile", "required", "mastery", "good", "experience", "spirit", "based", "mission", "main",
        "confirmed", "ideally", "according", "have", "being", "knowledge", "able", "ability", "skill",
        "technical", "solid", "advanced"
    ]
    
    # Recherche dans les diff√©rentes sections
    for pattern in skill_sections:
        section_match = re.search(pattern, text_lower, re.DOTALL | re.IGNORECASE)
        if section_match:
            section_text = section_match.group(1)
            # Extraction des mots pertinents (mots de 4 lettres minimum, incluant caract√®res sp√©ciaux techniques)
            words = re.findall(r'\b[a-zA-Z√Ä-√ø\+\#\.]{4,}\b', section_text)
            skills.extend([word for word in words if word.lower() not in stop_words])
    
    # Si aucune section trouv√©e, chercher dans tout le texte
    if not skills:
        # Recherche de termes techniques communs
        tech_patterns = [
            r'\b(?:python|java(?:script)?|typescript|c\+\+|ruby|php|html5?|css3?|sql|nosql|mongodb|mysql|postgresql|oracle|azure|aws|gcp|react(?:js)?|angular(?:js)?|vue(?:js)?|node(?:js)?|express(?:js)?|django|flask|spring|hibernate|docker|kubernetes|jenkins|git|jira|confluence|agile|scrum|kanban)\b',
            r'\b(?:excel|word|powerpoint|outlook|office|sharepoint|teams|visio|project|access|onedrive|dynamics|power\s*bi|tableau|qlik(?:view)?|looker|microstrategy)\b',
            r'\b(?:sap|oracle|salesforce|workday|netsuite|peoplesoft|microsoft\s*dynamics|jd\s*edwards|sage|quickbooks)\b'
        ]
        
        for pattern in tech_patterns:
            tech_matches = re.findall(pattern, text_lower, re.IGNORECASE)
            skills.extend(tech_matches)

    return {
        "Niveau d'√©tudes": education_level,
        "Ann√©es d'exp√©rience": total_experience_years,
        "Comp√©tences cl√©s extraites": list(set(skills))
    }

# --- SCORING PAR R√àGLES AVEC REGEX AM√âLIOR√â ---
def rank_resumes_with_rules(job_description, resumes, file_names, job_title: str | None = None):
    """Scoring par r√®gles (regex) avec priorit√© sur l'intitul√© du poste.

    On ajoute un poids √©lev√© pour la pr√©sence explicite de l'intitul√© du poste
    (ou sa variation) dans le CV. Si `job_title` n'est pas fourni, on utilise
    `st.session_state.last_job_title` comme fallback.
    """
    jd_entities = regex_analysis(job_description)
    results = []

    # Poids configurables
    JOB_TITLE_WEIGHT = 50  # Poids fort pour l'intitul√© du poste
    SKILL_WEIGHT = 5
    EDUCATION_WEIGHT = 30
    EXPERIENCE_WEIGHT = 20

    # Normalisation / fallback du titre recherch√©
    job_title_param = (job_title or st.session_state.get('last_job_title', '') or '').strip()
    job_title_norm = job_title_param.lower()

    for i, resume_text in enumerate(resumes):
        resume_entities = regex_analysis(resume_text)
        current_score = 0
        logic = {}

        # 1) V√©rifier l'intitul√© du poste (fort signal)
        title_score = 0
        resume_lower = resume_text.lower()
        if job_title_norm:
            # Correspondance exacte simple
            if re.search(re.escape(job_title_norm), resume_lower):
                title_score = JOB_TITLE_WEIGHT
            else:
                # Tentative plus flexible: v√©rifier la s√©quence de tokens
                tokens = [t for t in re.findall(r"\w+", job_title_norm) if len(t) > 1]
                if tokens:
                    seq_pattern = r"\b" + r"\s+".join(map(re.escape, tokens)) + r"\b"
                    if re.search(seq_pattern, resume_lower):
                        title_score = int(JOB_TITLE_WEIGHT * 0.9)
        current_score += title_score
        logic['Intitul√© poste'] = f"Recherche '{job_title_param}' -> {'trouv√©' if title_score>0 else 'non trouv√©'} (+{title_score} pts)"

        # 2) Comp√©tences
        jd_skills = jd_entities["Comp√©tences cl√©s extraites"]
        common_skills = [skill for skill in jd_skills if re.search(r'\b' + re.escape(skill) + r'\b', resume_lower)]
        score_from_skills = len(common_skills) * SKILL_WEIGHT
        current_score += score_from_skills
        logic['Comp√©tences correspondantes'] = f"{common_skills} (+{score_from_skills} pts)"

        # 3) √âducation
        score_from_edu = 0
        if resume_entities["Niveau d'√©tudes"] >= jd_entities["Niveau d'√©tudes"]:
            score_from_edu = EDUCATION_WEIGHT
            current_score += score_from_edu
        logic['Niveau d\'√©tudes'] = "Candidat: Bac+{} vs Requis: Bac+{} (+{} pts)".format(resume_entities["Niveau d'√©tudes"], jd_entities["Niveau d'√©tudes"], score_from_edu)

        # 4) Exp√©rience
        score_from_exp = 0
        if resume_entities["Ann√©es d'exp√©rience"] >= jd_entities["Ann√©es d'exp√©rience"]:
            score_from_exp = EXPERIENCE_WEIGHT
            current_score += score_from_exp
        logic['Exp√©rience'] = "Candidat: {} ans vs Requis: {} ans (+{} pts)".format(resume_entities["Ann√©es d'exp√©rience"], jd_entities["Ann√©es d'exp√©rience"], score_from_exp)

        results.append({"file_name": file_names[i], "score": current_score, "logic": logic})

    # Calcul du score maximal possible (inclut le poids du titre)
    max_score = JOB_TITLE_WEIGHT + (len(jd_entities["Comp√©tences cl√©s extraites"]) * SKILL_WEIGHT) + EDUCATION_WEIGHT + EXPERIENCE_WEIGHT

    if max_score > 0:
        for res in results:
            res["score"] = min(res["score"] / max_score, 1.0)

    return results

# --- M√âTHODE 4 : ANALYSE PAR IA (PARSING CORRIG√â) ---
def get_detailed_score_with_ai(job_description, resume_text):
    API_KEY = get_api_key()
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Analyse IA impossible."}
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    prompt = f"""
    En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
    Fournis ta r√©ponse en deux parties :
    1. Un score de correspondance en pourcentage (ex: "Score: 85%").
    2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
    ---
    Description du poste: {job_description}
    ---
    Texte du CV: {resume_text}
    """
    payload = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.0}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        full_response_text = response.json()["choices"][0]["message"]["content"]
        score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", full_response_text, re.IGNORECASE)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        return {"score": score, "explanation": full_response_text}
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erreur IA : {e}")
        return {"score": 0.0, "explanation": "Erreur"}

def rank_resumes_with_ai(job_description, resumes, file_names):
    scores_data = []
    for resume_text in resumes:
        scores_data.append(get_detailed_score_with_ai(job_description, resume_text))
    return {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}



# --- FONCTIONS GROQ ---
def get_groq_api_key():
    """R√©cup√®re la cl√© Groq avec persistance en session state."""
    if "Groq_API_KEY" in st.session_state:
        return st.session_state.Groq_API_KEY
    
    api_key = None
    try:
        keys_to_check = ["Groq_API_KEY", "GROQ_API_KEY"]
        for k in keys_to_check:
            if k in st.secrets:
                api_key = st.secrets[k]
                break
        
        if not api_key:
            for k in keys_to_check:
                val = os.environ.get(k)
                if val:
                    api_key = val
                    break
                    
        if api_key:
            st.session_state.Groq_API_KEY = api_key
            return api_key
    except Exception:
        pass
    return None

def get_detailed_score_with_groq(job_description, resume_text):
    API_KEY = get_groq_api_key()
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Cl√© Groq manquante."}
    
    try:
        client = groq.Groq(api_key=API_KEY)
        prompt = f"""
        En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
        Fournis ta r√©ponse en deux parties :
        1. Un score de correspondance en pourcentage (ex: "Score: 85%").
        2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
        ---
        Description du poste: {job_description}
        ---
        Texte du CV: {resume_text}
        """
        
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile",
            max_tokens=4000,
        )
        text_resp = chat_completion.choices[0].message.content
        
        score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", text_resp, re.IGNORECASE)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        
        return {"score": score, "explanation": text_resp}
    except Exception as e:
        return {"score": 0.0, "explanation": f"Erreur Groq: {e}"}

def rank_resumes_with_groq(job_description, resumes, file_names):
    scores_data = []
    progress_bar = st.progress(0)
    for i, resume_text in enumerate(resumes):
        scores_data.append(get_detailed_score_with_groq(job_description, resume_text))
        progress_bar.progress((i + 1) / len(resumes))
    progress_bar.empty()
    return {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}

def get_groq_profile_analysis(text: str, candidate_name: str | None = None) -> str:
    API_KEY = get_groq_api_key()
    if not API_KEY: return "‚ùå Analyse Groq impossible (cl√© manquante)."

    safe_name = (candidate_name or "Candidat").strip()

    try:
        client = groq.Groq(api_key=API_KEY)
        prompt = f"""Tu es un expert en recrutement. Analyse le CV suivant et g√©n√®re un r√©sum√© structur√© et concis EN FRAN√áAIS.

R√®gles NOM :
- Nom identifi√© : "{safe_name}".
- Si "{safe_name}" est inappropri√© (Candidat, Permis B...), Trouve le vrai nom dans le texte.
- Sinon garde "{safe_name}".

**Format de sortie OBLIGATOIRE** :

**üë§ [Nom du Candidat]**

**üìä Synth√®se**
[2-3 phrases]

**üéì Formation**
[Dipl√¥me le plus √©lev√©]

**üíº Exp√©rience**
[Dernier poste]

**üõ†Ô∏è Comp√©tences cl√©s**
[4-5 comp√©tences]

**üí° Points forts**
[2-3 points]

**‚ö†Ô∏è Points d'attention**
[1-2 points]

Texte du CV :
{text[:4000]}
"""
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile",
            max_tokens=2000,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"‚ùå Erreur Groq : {e}"

# --- FONCTIONS OPENROUTER ---
def get_openrouter_api_key():
    """R√©cup√®re la cl√© OpenRouter avec persistance en session state."""
    if "OpenRouter_API_KEY" in st.session_state:
        return st.session_state.OpenRouter_API_KEY

    api_key = None
    try:
        # Try multiple possible secret keys and nested structures
        # 1) Direct keys in st.secrets
        try:
            # st.secrets behaves like a dict-like object
            secret_keys = [
                "OpenRouter_API_KEY", "OPENROUTER_API_KEY", "openrouter_api_key",
                "openrouter", "OPENROUTER"
            ]
            for k in secret_keys:
                if k in st.secrets:
                    candidate = st.secrets[k]
                    if isinstance(candidate, dict):
                        # common nested fields
                        for nk in ["api_key", "OpenRouter_API_KEY", "openrouter_api_key", "key"]:
                            if nk in candidate and candidate[nk]:
                                api_key = candidate[nk]
                                break
                        if api_key:
                            break
                    elif candidate:
                        api_key = candidate
                        break
        except Exception:
            # If st.secrets access fails, continue to env fallback
            pass

        # 2) Environment variables fallback
        if not api_key:
            for k in ["OPENROUTER_API_KEY", "OpenRouter_API_KEY", "openrouter_api_key"]:
                val = os.environ.get(k)
                if val:
                    api_key = val
                    break

        # Final normalization and caching in session_state
        if api_key:
            api_key = str(api_key).strip()
            if api_key:
                st.session_state.OpenRouter_API_KEY = api_key
                return api_key
    except Exception as e:
        print(f"Erreur get_openrouter_api_key: {e}")

    return None

def get_detailed_score_with_openrouter(job_description, resume_text):
    API_KEY = get_openrouter_api_key()
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Cl√© OpenRouter manquante."}

    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://tg-hire.streamlit.app/", # Optionnel
                "X-Title": "TG Hire" # Optionnel
            },
            data=json.dumps({
                "model": "openai/gpt-3.5-turbo", # Mod√®le par d√©faut √©conomique
                "messages": [
                    {
                        "role": "user",
                        "content": f"""
                        En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
                        Fournis ta r√©ponse en deux parties :
                        1. Un score de correspondance en pourcentage (ex: "Score: 85%").
                        2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
                        ---
                        Description du poste: {job_description}
                        ---
                        Texte du CV: {resume_text}
                        """
                    }
                ]
            })
        )
        response.raise_for_status()
        data = response.json()
        text_resp = data['choices'][0]['message']['content']
        
        score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", text_resp, re.IGNORECASE)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        
        return {"score": score, "explanation": text_resp}
    except Exception as e:
        return {"score": 0.0, "explanation": f"Erreur OpenRouter: {e}"}

def rank_resumes_with_openrouter(job_description, resumes, file_names):
    scores_data = []
    progress_bar = st.progress(0)
    for i, resume_text in enumerate(resumes):
        scores_data.append(get_detailed_score_with_openrouter(job_description, resume_text))
        progress_bar.progress((i + 1) / len(resumes))
    progress_bar.empty()
    return {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}

def get_openrouter_profile_analysis(text: str, candidate_name: str | None = None) -> str:
    API_KEY = get_openrouter_api_key()
    if not API_KEY: return "‚ùå Analyse OpenRouter impossible (cl√© manquante)."

    safe_name = (candidate_name or "Candidat").strip()

    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json",
            },
            data=json.dumps({
                "model": "openai/gpt-3.5-turbo",
                "messages": [
                    {
                        "role": "user",
                        "content": f"""Tu es un expert en recrutement. Analyse le CV suivant et g√©n√®re un r√©sum√© structur√© et concis EN FRAN√áAIS.

R√®gles NOM :
- Nom identifi√© : "{safe_name}".
- Si "{safe_name}" est inappropri√© (Candidat, Permis B...), Trouve le vrai nom dans le texte.
- Sinon garde "{safe_name}".

**Format de sortie OBLIGATOIRE** :

**üë§ [Nom du Candidat]**

**üìä Synth√®se**
[2-3 phrases]

**üéì Formation**
[Dipl√¥me le plus √©lev√©]

**üíº Exp√©rience**
[Dernier poste]

**üõ†Ô∏è Comp√©tences cl√©s**
[4-5 comp√©tences]

**üí° Points forts**
[2-3 points]

**‚ö†Ô∏è Points d'attention**
[1-2 points]

Texte du CV :
{text[:4000]}
"""
                    }
                ]
            })
        )
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"‚ùå Erreur OpenRouter : {e}"
        
# DELETED DUPLICATE FUNCTION: get_openrouter_auto_classification

# --- FONCTIONS CLAUDE ---
def get_claude_api_key():
    """R√©cup√®re la cl√© Claude avec persistance en session state."""
    if "Claude_API_KEY" in st.session_state:
        return st.session_state.Claude_API_KEY
    
    api_key = None
    try:
        keys_to_check = ["Claude_API_KEY", "CLAUDE_API_KEY", "anthropic_api_key", "ANTHROPIC_API_KEY"]
        for k in keys_to_check:
            if k in st.secrets:
                api_key = st.secrets[k]
                break
        
        if not api_key:
            for k in keys_to_check:
                val = os.environ.get(k)
                if val:
                    api_key = val
                    break
                    
        if api_key:
            st.session_state.Claude_API_KEY = api_key
            return api_key
    except Exception:
        pass
    return None

def get_detailed_score_with_claude(job_description, resume_text):
    API_KEY = get_claude_api_key()
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Cl√© Claude manquante."}
    
    try:
        client = anthropic.Anthropic(api_key=API_KEY)
        prompt = f"""
        En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
        Fournis ta r√©ponse en deux parties :
        1. Un score de correspondance en pourcentage (ex: "Score: 85%").
        2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
        ---
        Description du poste: {job_description}
        ---
        Texte du CV: {resume_text}
        """
        
        message = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=4000,
            messages=[{"role": "user", "content": prompt}]
        )
        # Safely extract text from blocks
        text_resp = ""
        for block in message.content:
            if block.type == "text":
                text_resp += block.text
        
        score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", text_resp, re.IGNORECASE)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        
        return {"score": score, "explanation": text_resp}
    except Exception as e:
        return {"score": 0.0, "explanation": f"Erreur Claude: {e}"}

def get_claude_profile_analysis(text: str, candidate_name: str | None = None) -> str:
    API_KEY = get_claude_api_key()
    if not API_KEY: return "‚ùå Analyse Claude impossible (cl√© manquante)."

    safe_name = (candidate_name or "Candidat").strip()

    try:
        client = anthropic.Anthropic(api_key=API_KEY)
        prompt = f"""Tu es un expert en recrutement. Analyse le CV suivant et g√©n√®re un r√©sum√© structur√© et concis EN FRAN√áAIS.

R√®gles NOM :
- Nom identifi√© : "{safe_name}".
- Si "{safe_name}" est inappropri√© (Candidat, Permis B...), Trouve le vrai nom dans le texte.
- Sinon garde "{safe_name}".

**Format de sortie OBLIGATOIRE** :

**üë§ [Nom du Candidat]**

**üìä Synth√®se**
[2-3 phrases]

**üéì Formation**
[Dipl√¥me le plus √©lev√©]

**üíº Exp√©rience**
[Dernier poste]

**üõ†Ô∏è Comp√©tences cl√©s**
[4-5 comp√©tences]

**üí° Points forts**
[2-3 points]

**‚ö†Ô∏è Points d'attention**
[1-2 points]

Texte du CV :
{text[:4000]}
"""
        message = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        # Safely extract text from blocks
        text_resp = ""
        for block in message.content:
            if block.type == "text":
                text_resp += block.text
        return text_resp
    except Exception as e:
        return f"‚ùå Erreur Claude : {e}"

# --- FONCTIONS GEMINI ---

def get_gemini_api_key():
    """R√©cup√®re la cl√© Gemini avec persistance en session state."""
    # 1. V√©rifier si d√©j√† en session
    if "Gemini_API_KEY" in st.session_state:
        return st.session_state.Gemini_API_KEY
    
    api_key = None
    try:
        # 2. V√©rifier st.secrets (attention aux majuscules/minuscules)
        # On essaie plusieurs variantes courantes
        keys_to_check = ["Gemini_API_KEY", "GEMINI_API_KEY", "google_api_key", "GOOGLE_API_KEY"]
        for k in keys_to_check:
            if k in st.secrets:
                api_key = st.secrets[k]
                break
        
        # 3. V√©rifier variables d'environnement
        if not api_key:
            for k in keys_to_check:
                val = os.environ.get(k)
                if val:
                    api_key = val
                    break
        
        if api_key:
            st.session_state.Gemini_API_KEY = api_key
            return api_key
    except Exception:
        pass
    return None

def get_detailed_score_with_gemini(job_description, resume_text):
    API_KEY = get_gemini_api_key()
    if not API_KEY: return {"score": 0.0, "explanation": "‚ùå Cl√© Gemini manquante."}
    
    genai.configure(api_key=API_KEY)
    
    # Selection du mod√®le bas√© sur la disponibilit√©
    try:
        model = genai.GenerativeModel('gemini-2.5-flash-lite')
    except:
        model = genai.GenerativeModel('gemini-2.0-flash')
    
    prompt = f"""
    En tant qu'expert en recrutement, √©value la pertinence du CV suivant pour la description de poste donn√©e.
    Fournis ta r√©ponse en deux parties :
    1. Un score de correspondance en pourcentage (ex: "Score: 85%").
    2. Une analyse d√©taill√©e expliquant les points forts et les points √† am√©liorer.
    ---
    Description du poste: {job_description}
    ---
    Texte du CV: {resume_text}
    """
    
    try:
        response = model.generate_content(prompt)
        text_resp = response.text
        
        # Extraction du score
        score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", text_resp, re.IGNORECASE)
        score = int(score_match.group(1)) / 100 if score_match else 0.0
        
        return {"score": score, "explanation": text_resp}
    except Exception as e:
        # Fallback intelligent en cas d'erreur 404
        if "not found" in str(e).lower() or "404" in str(e):
            try:
                # Tentative ultime sur le mod√®le 'gemini-flash-latest' qui est souvent un alias stable
                model = genai.GenerativeModel('gemini-flash-latest')
                response = model.generate_content(prompt)
                text_resp = response.text
                score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", text_resp, re.IGNORECASE)
                score = int(score_match.group(1)) / 100 if score_match else 0.0
                return {"score": score, "explanation": text_resp}
            except Exception as e2:
                 return {"score": 0.0, "explanation": f"Erreur Gemini (Fallback): {e2}"}
        return {"score": 0.0, "explanation": f"Erreur Gemini: {e}"}

def rank_resumes_with_gemini(job_description, resumes, file_names):
    scores_data = []
    # Placeholder pour barre de progression si int√©gr√©e, sinon boucle simple
    progress_bar = st.progress(0)
    for i, resume_text in enumerate(resumes):
        scores_data.append(get_detailed_score_with_gemini(job_description, resume_text))
        progress_bar.progress((i + 1) / len(resumes))
        time.sleep(1) # Petit d√©lai pour √©viter rate limits tier gratuit
    progress_bar.empty()
    return {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}

def get_gemini_profile_analysis(text: str, candidate_name: str | None = None) -> str:
    API_KEY = get_gemini_api_key()
    if not API_KEY: return "‚ùå Analyse impossible (cl√© API Gemini manquante)."
    
    # Logique Nom
    if candidate_name and is_valid_name_candidate(candidate_name):
        safe_name = candidate_name
    else:
        extracted = extract_name_from_cv_text(text)
        if extracted and extracted.get('name'):
            safe_name = extracted['name']
        else:
            safe_name = "Candidat"
    
    safe_name = safe_name.replace("##", "").replace("**", "").strip()

    genai.configure(api_key=API_KEY)
    # Utilisation de gemini-2.5-flash-lite
    model = genai.GenerativeModel('gemini-2.5-flash-lite')
    
    prompt = f"""Tu es un expert en recrutement. Analyse le CV suivant et g√©n√®re un r√©sum√© structur√© et concis EN FRAN√áAIS.

R√®gles NOM :
- Nom identifi√© : "{safe_name}".
- Si "{safe_name}" est inappropri√© (Candidat, Permis B...), Trouve le vrai nom dans le texte.
- Sinon garde "{safe_name}".

**Format de sortie OBLIGATOIRE** :

**üë§ [Nom du Candidat]**

**üìä Synth√®se**
[2-3 phrases]

**üéì Formation**
[Dipl√¥me le plus √©lev√©]

**üíº Exp√©rience**
[Dernier poste]

**üõ†Ô∏è Comp√©tences cl√©s**
[4-5 comp√©tences]

**üí° Points forts**
[2-3 points]

**‚ö†Ô∏è Points d'attention**
[1-2 points]

Texte du CV :
{text[:4000]}
"""
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
         # Fallback recursif silencieux si gemini-2.0-flash √©choue
        try:
             model = genai.GenerativeModel('gemini-flash-latest')
             response = model.generate_content(prompt)
             return response.text.strip()
        except:
            return f"‚ùå Erreur Gemini : {e}"

def get_gemini_auto_classification(text: str, full_name: str | None) -> dict:
    API_KEY = get_gemini_api_key()
    safe_name = (full_name or "Candidat").strip()
    if not API_KEY:
        return {
            "macro_category": "Non class√©",
            "sub_category": "Autre",
            "years_experience": 0,
            "profile_summary": f"Erreur config Gemini",
            "candidate_name": safe_name
        }
        
    genai.configure(api_key=API_KEY)
    # Update to gemini-2.5-flash-lite which is available
    model = genai.GenerativeModel('gemini-2.5-flash-lite', generation_config={"response_mime_type": "application/json"})
    
    # Use centralized classification prompt to ensure exactly 4 categories
    prompt = get_classification_prompt(text, safe_name, None)
    
    try:
        response = model.generate_content(prompt)
        try:
            data = json.loads(response.text)
        except:
             # Fallback JSON parsing simple
            clean_text = clean_json_string(response.text)
            data = json.loads(clean_text)
        
        # Fallback values handle
        macro = data.get("macro_category") or "Non class√©"
        if macro not in ["Fonctions supports", "Logistique", "Production/Technique", "Divers / Hors p√©rim√®tre"]: macro = "Non class√©"
        
        return {
            "macro_category": macro,
            "sub_category": data.get("sub_category", "Autre"),
            "years_experience": int(data.get("years_experience", 0)),
            "profile_summary": data.get("profile_summary", ""),
            "candidate_name": data.get("candidate_name", safe_name)
        }
    except Exception as e:
        # Fallback silent to gemini-flash-latest
        try:
            model = genai.GenerativeModel('gemini-flash-latest', generation_config={"response_mime_type": "application/json"})
            response = model.generate_content(prompt)
            try:
                data = json.loads(response.text)
            except:
                clean_text = clean_json_string(response.text)
                data = json.loads(clean_text)
            
            macro = data.get("macro_category") or "Non class√©"
            if macro not in ["Fonctions supports", "Logistique", "Production/Technique", "Divers / Hors p√©rim√®tre"]: macro = "Non class√©"
            
            return {
                "macro_category": macro,
                "sub_category": data.get("sub_category", "Autre"),
                "years_experience": int(data.get("years_experience", 0)),
                "profile_summary": data.get("profile_summary", ""),
                "candidate_name": data.get("candidate_name", safe_name)
            }
        except:
            return {
                "macro_category": "Non class√©",
                "sub_category": "Autre",
                "years_experience": 0,
                "profile_summary": f"Erreur Gemini: {e}",
                "candidate_name": safe_name
            }


# --- NOUVELLE VERSION "BLIND√âE" ---
CATEGORIES_PROMPT = """
Voici les 4 cat√©gories principales pour classer les CVs. Sois tr√®s strict et respecte les descriptions.

1.  **FONCTIONS SUPPORTS**
    *   **Description** : Regroupe les m√©tiers qui soutiennent l'activit√© principale de l'entreprise (BTP).
    *   **Sous-cat√©gories** :
        *   `FINANCE & COMPTABILIT√â` : (DAF, Contr√¥leur de gestion, Comptable...)
        *   `RH & PAIE` : (DRH, RRH, Charg√© de recrutement, Gestionnaire de paie...)
        *   `JURIDIQUE` : (Juriste, Avocat...)
        *   `ACHATS` : (Acheteur, Responsable Achats...)
        *   `MARKETING & COMMUNICATION`
        *   `DSI / IT` : (Directeur des syst√®mes d'information, Chef de projet IT, Technicien support...)
        *   `QUALIT√â / QSE` : (Responsable QSE, Animateur Qualit√©...)
        *   `SERVICES G√âN√âRAUX`

2.  **LOGISTIQUE**
    *   **Description** : M√©tiers li√©s √† la gestion des flux, du mat√©riel et des approvisionnements.
    *   **Sous-cat√©gories** :
        *   `MAT√âRIEL` : (Responsable mat√©riel, M√©canicien...)
        *   `CHA√éNE D'APPROVISIONNEMENT` : (Logisticien, Supply Chain Manager...)

3.  **PRODUCTION / TECHNIQUE**
    *   **Description** : C≈ìur de m√©tier du BTP. Concerne la r√©alisation des chantiers.
    *   **Sous-cat√©gories** :
        *   `√âTUDES & CONCEPTION` : (Ing√©nieur d'√©tudes, Projeteur, Dessinateur, M√©thodes...)
        *   `TRAVAUX` : (Directeur de travaux, Conducteur de travaux, Chef de chantier...)
        *   `MANAGEMENT DE PROJET` : (Chef de projet, OPC...)
        *   `BUREAU D'√âTUDES TECHNIQUES (BET)`
        *   `TOPOGRAPHIE`

4.  **DIVERS / HORS P√âRIM√àTRE**
    *   **Description** : Profils non pertinents, √©tudiants sans exp√©rience, ou inclassables.
    *   **Sous-cat√©gories** :
        *   `HORS SUJET`
        *   `√âTUDIANT / STAGIAIRE`
        *   `INCLASSIFIABLE`

--- R√àGLES STRICTES & INTERDICTIONS ---
- **INTERDICTION ABSOLUE** : Si la cat√©gorie principale est `PRODUCTION / TECHNIQUE`, les sous-cat√©gories `DSI / IT` ou `RH & PAIE` sont **INTERDITES**. Un profil BTP n'est **JAMAIS** un profil IT ou RH.
- **R√àGLE D'OR** : Un `Ing√©nieur G√©nie Civil`, `Conducteur de Travaux`, `Chef de Chantier` est **TOUJOURS** class√© dans `PRODUCTION / TECHNIQUE`. La sous-cat√©gorie sera `√âTUDES & CONCEPTION` ou `TRAVAUX`.
- **CLARIFICATION** : La pr√©sence de mots-cl√©s comme "gestion de projet", "management", "planning" dans un CV d'ing√©nieur BTP ne doit **PAS** le classer en "FONCTIONS SUPPORTS". Ces comp√©tences sont intrins√®ques au m√©tier de la `PRODUCTION / TECHNIQUE`.
- **EXEMPLE** : Si un CV mentionne "Ing√©nieur G√©nie Civil" et aussi "comp√©tences en gestion d'√©quipe", la classification doit √™tre `PRODUCTION / TECHNIQUE` et la sous-cat√©gorie `TRAVAUX` ou `MANAGEMENT DE PROJET`, mais **JAMAIS** `RH & PAIE`.
"""

def get_classification_prompt(cv_text, job_title, job_description):
    """G√©n√®re le prompt complet pour la classification avec les r√®gles et le contexte."""
    return f"""
    {CATEGORIES_PROMPT}

    --- MISSION ---
    Tu es un expert en recrutement pour le secteur du BTP. Ta mission est de classer le CV suivant de mani√®re extr√™mement rigoureuse en te basant **UNIQUEMENT** sur les cat√©gories, sous-cat√©gories et r√®gles d√©finies ci-dessus.

    --- CONTEXTE DU POSTE (si fourni) ---
    - **Intitul√© du poste recherch√©** : "{job_title}"
    - **Description du poste** : "{job_description}"

    --- TEXTE DU CV √Ä ANALYSER ---
    {cv_text}

    --- FORMAT DE SORTIE OBLIGATOIRE ---
    R√©ponds **UNIQUEMENT** avec un objet JSON valide contenant les cl√©s "categorie" et "sous_categorie". Ne fournis aucune explication ou texte suppl√©mentaire en dehors du JSON.

    **Exemple de sortie attendue** :
    ```json
    {{
      "categorie": "PRODUCTION / TECHNIQUE",
      "sous_categorie": "TRAVAUX"
    }}
    ```
    """

def get_deepseek_profile_analysis(text: str, candidate_name: str | None = None) -> str:
    """
    G√©n√®re une analyse de profil g√©n√©rique et concise en fran√ßais.
    Retourne un texte structur√© avec les points cl√©s du candidat.
    Format en 2 colonnes pour affichage, commence par synth√®se + nom.
    """
    API_KEY = get_api_key()
    if not API_KEY:
        return "‚ùå Analyse impossible (cl√© API manquante)."
    
    # --- LOGIQUE AM√âLIOR√âE POUR LE NOM ---
    safe_name = ""
    
    # 1. Priorit√© au nom pass√© en argument s'il est valide
    if candidate_name and is_valid_name_candidate(candidate_name):
        safe_name = candidate_name
    else:
        # 2. Sinon, tentative d'extraction locale robuste
        extracted = extract_name_from_cv_text(text)
        if extracted and extracted.get('name'):
            safe_name = extracted['name']
        else:
            safe_name = "Candidat"
    
    # Nettoyage final du nom (au cas o√π des ## resteraient)
    safe_name = safe_name.replace("##", "").replace("**", "").strip()
    # -------------------------------------
    
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    
    prompt = f"""Tu es un expert en recrutement. Analyse le CV suivant et g√©n√®re un r√©sum√© structur√© et concis EN FRAN√áAIS.

R√®gles NOM STRICTES (align√©es avec l'extraction locale) :
- Utilise STRICTEMENT le nom fourni ci-dessous s'il est pr√©sent.
- Ne modifie PAS le nom (pas d'ajout de points, parenth√®ses, intitul√©s).
- N'invente JAMAIS de nom. Si le nom ci-dessus est "Candidat (Nom non d√©tect√©)", REPRENDS-LE tel quel.
- Ignore toute ligne contenant des mots interdits fr√©quents (ex: AutoCAD, ORSYS, Secteur, BIM, Owner, PSPO, Client, Missions, Permis, Angleterre, Irlande, Luxembourg, Urbanisme, Agro-alimentaire, Lecture, Multi-disciplinary, Engineering, Studies, Parcours, Professionnel, Ivalua, PRM, AMF, Alerting, Blockchain, Projects, Purposes, Program).

**Format de sortie OBLIGATOIRE** - Respecte EXACTEMENT cet ordre et ces titres :

**üë§ {safe_name}**

**üìä Synth√®se**
[2-3 phrases max : ann√©es d'exp√©rience, type de profil (junior/confirm√©/senior), domaine d'expertise principal]

**üéì Formation**
[Dipl√¥me le plus √©lev√© - √©tablissement - ann√©e si disponible]

**üíº Exp√©rience**
[Dernier poste occup√© - entreprise - dur√©e]
[Secteur(s) d'activit√©]

**üõ†Ô∏è Comp√©tences cl√©s**
[4-5 comp√©tences techniques, s√©par√©es par des virgules]

**üí° Points forts**
[2-3 points forts, une ligne chacun]

**‚ö†Ô∏è Points d'attention**
[1-2 √©l√©ments √† v√©rifier en entretien]

Contraintes STRICTES :
- Commence TOUJOURS par le nom puis la synth√®se
- Sois factuel et concis (pas de formules de politesse)
- Si info absente du CV, √©cris "Non pr√©cis√©"
- Maximum 12 lignes au total

Texte du CV :
{text[:4000]}
"""
    
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.2,
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse : {e}"


def get_deepseek_analysis(text):
    API_KEY = get_api_key()
    if not API_KEY: return "Analyse impossible."
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    prompt = f"""
     Tu es un expert en recrutement. √Ä partir du texte du CV ci-dessous, classe le poste cible dans UNE seule des trois macro-cat√©gories suivantes :

     1. Fonctions supports
         ‚Ä¢ Direction RH : Recrutement, paie, formation, relations sociales.
         ‚Ä¢ Direction Finance : Comptabilit√©, tr√©sorerie, fiscalit√©, audit.
         ‚Ä¢ Contr√¥le de Gestion : Analyse de la performance, budgets.
         ‚Ä¢ Direction des Achats : Sourcing, n√©gociation, approvisionnements.
         ‚Ä¢ Direction Logistique : Gestion des flux, transport, entreposage.
         ‚Ä¢ Direction Informatique (DSI) : Infrastructure, support, cybers√©curit√©.
         ‚Ä¢ QHSE : Normes ISO, s√©curit√© au travail, environnement.
         ‚Ä¢ Direction Juridique : Conformit√©, contrats.
         ‚Ä¢ Communication / Marketing : Image de marque, digital.

     2. Logistique
         ‚Ä¢ Activit√©s centr√©es sur la gestion des flux physiques, transport, entrep√¥ts, distribution.

     3. Production/Technique
         ‚Ä¢ BTP / G√©nie Civil : √âtudes de prix, conduite de travaux.
         ‚Ä¢ Industrie : Production, ligne d'assemblage, usinage, √©lectrom√©canique, automatisme.
         ‚Ä¢ R&D / Bureau d'√©tudes : Conception, ing√©nierie.
         ‚Ä¢ Commercial / Vente : D√©veloppement du chiffre d'affaires li√© √† une offre technique ou industrielle.

      Consigne IMPORTANTE :
      - R√©ponds UNIQUEMENT par le nom exact d'UNE SEULE des quatre macro-cat√©gories ci-dessous :
          "Fonctions supports" OU "Logistique" OU "Production/Technique" OU "Non class√©".
      - Ne donne aucune explication suppl√©mentaire.

     Texte du CV :
     {text}
     """
    payload = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.2}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()
        # R√©cup√©rer uniquement la cat√©gorie (nettoyer la r√©ponse)
        result = response.json()["choices"][0]["message"]["content"].strip()
        res_low = result.lower()
        # Normaliser la r√©ponse pour s'assurer qu'elle correspond √† l'une des quatre cat√©gories
        if "support" in res_low:
            return "Fonctions supports"
        if "logist" in res_low:
            return "Logistique"
        if "production" in res_low or "technique" in res_low:
            return "Production/Technique"
        if "non class" in res_low or "non-class" in res_low or "non class√©" in res_low:
            return "Non class√©"
        # Garder la r√©ponse originale si elle ne correspond pas aux patterns pr√©vus
        return result
    except Exception as e:
        return f"Erreur IA : {e}"



def clean_json_string(json_str):
    """Nettoie la r√©ponse de l'IA pour extraire uniquement le bloc JSON valide."""
    import re
    # Enlever les balises Markdown ```json ... ```
    if "```" in json_str:
        json_str = re.sub(r'```json\s*', '', json_str)
        json_str = re.sub(r'```\s*', '', json_str)
    
    # Trouver le premier '{' et le dernier '}'
    start = json_str.find('{')
    end = json_str.rfind('}')
    
    if start != -1 and end != -1:
        return json_str[start : end + 1]
    return json_str

def get_deepseek_auto_classification(text: str, local_extracted_name: str | None) -> dict:
    API_KEY = get_api_key()
    hint_name = (local_extracted_name or "").strip()
    
    # Fallback imm√©diat si pas de cl√©
    default_response = {
        "macro_category": "Non class√©",
        "sub_category": "Autre",
        "years_experience": 0,
        "candidate_name": hint_name or "Candidat",
        "profile_summary": "Analyse impossible (cl√© manquante)."
    }
    
    if not API_KEY: return default_response

    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    
    # Use centralized classification prompt to ensure exactly 4 categories
    prompt = get_classification_prompt(text, hint_name, None)

    try:
        response = requests.post(url, headers=headers, data=json.dumps({
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1
        }))
        response.raise_for_status()
        
        # Nettoyage et Parsing
        raw_content = response.json()["choices"][0]["message"]["content"]
        # Utiliser l'outil de nettoyage JSON que nous avons ajout√©
        clean_content = clean_json_string(raw_content)
        
        try:
            data = json.loads(clean_content)
        except:
            # Si le JSON est cass√©, on essaie de sauver les meubles avec regex
            data = {}
            if "Production" in raw_content or "Technique" in raw_content: data["macro_category"] = "Production/Technique"
            elif "Logistique" in raw_content: data["macro_category"] = "Logistique"
            elif "support" in raw_content: data["macro_category"] = "Fonctions supports"

        # Validation post-traitement (Safety check)
        final_name = data.get("candidate_name", "Candidat")
        
        # Liste noire de s√©curit√©
        blacklist = ["curriculum", "vitae", "resume", "profil", "ing√©nieur", "manager", "d√©veloppeur", "page", "cv"]
        if any(bad in final_name.lower() for bad in blacklist):
            final_name = hint_name if hint_name else "Candidat (Nom non d√©tect√©)"

        # Normalisation cat√©gorie
        macro = data.get("macro_category")
        # Si le mod√®le renvoie une variante bizarre, on normalise
        if macro:
            if "support" in macro.lower(): macro = "Fonctions supports"
            elif "logisti" in macro.lower(): macro = "Logistique"
            elif "product" in macro.lower() or "technip" in macro.lower() or "btp" in macro.lower(): macro = "Production/Technique"
        
        if macro not in ["Fonctions supports", "Logistique", "Production/Technique"]:
            macro = "Non class√©"

        return {
            "macro_category": macro,
            "sub_category": data.get("sub_category", "Autre"),
            "years_experience": data.get("years_experience", 0),
            "candidate_name": final_name,
            "profile_summary": data.get("profile_summary", "")
        }

    except Exception as e:
        print(f"DeepSeek Error: {e}")
        default_response["candidate_name"] = hint_name or "Erreur Extraction"
        return default_response

def get_groq_auto_classification(text: str, local_extracted_name: str | None) -> dict:
    API_KEY = get_groq_api_key()
    hint_name = (local_extracted_name or "").strip()
    
    default_response = {
        "macro_category": "Non class√©",
        "sub_category": "Autre",
        "years_experience": 0,
        "candidate_name": hint_name or "Candidat",
        "profile_summary": "Analyse impossible (cl√© manquante)."
    }
    
    if not API_KEY: return default_response

    try:
        client = groq.Groq(api_key=API_KEY)
        
        # Use centralized classification prompt to ensure exactly 4 categories
        prompt = get_classification_prompt(text, hint_name, None)

        completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "Tu es un expert JSON. Tu ne r√©ponds que du JSON valide."},
                {"role": "user", "content": prompt}
            ],
            model="llama-3.1-8b-instant",
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        content = completion.choices[0].message.content
        data = json.loads(content)
        
        macro = data.get("macro_category")
        if macro not in ["Fonctions supports", "Logistique", "Production/Technique"]:
            if "support" in str(macro).lower(): macro = "Fonctions supports"
            elif "logisti" in str(macro).lower(): macro = "Logistique"
            elif "product" in str(macro).lower() or "techni" in str(macro).lower(): macro = "Production/Technique"
            else: macro = "Non class√©"

        return {
            "macro_category": macro,
            "sub_category": data.get("sub_category", "Autre"),
            "years_experience": data.get("years_experience", 0),
            "candidate_name": data.get("candidate_name", hint_name),
            "profile_summary": data.get("profile_summary", "")
        }
    except Exception as e:
        print(f"Groq Error: {e}")
        return default_response

def get_claude_auto_classification(text: str, local_extracted_name: str | None) -> dict:
    API_KEY = get_claude_api_key()
    hint_name = (local_extracted_name or "").strip()
    
    default_response = {
        "macro_category": "Non class√©",
        "sub_category": "Autre",
        "years_experience": 0,
        "candidate_name": hint_name or "Candidat",
        "profile_summary": "Analyse impossible (cl√© manquante)."
    }
    
    if not API_KEY: return default_response

    try:
        client = anthropic.Anthropic(api_key=API_KEY)
        
        # Use centralized classification prompt to ensure exactly 4 categories
        prompt = get_classification_prompt(text, hint_name, None)

        message = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        content = ""
        for block in message.content:
            if block.type == "text":
                content += block.text
        
        clean_content = clean_json_string(content)
        data = json.loads(clean_content)
        
        macro = data.get("macro_category")
        if macro not in ["Fonctions supports", "Logistique", "Production/Technique"]:
             macro = "Non class√©"

        return {
            "macro_category": macro,
            "sub_category": data.get("sub_category", "Autre"),
            "years_experience": data.get("years_experience", 0),
            "candidate_name": data.get("candidate_name", hint_name),
            "profile_summary": data.get("profile_summary", "")
        }
    except Exception as e:
        print(f"Claude Error: {e}")
        return default_response

def get_openrouter_auto_classification(text: str, local_extracted_name: str | None) -> dict:
    API_KEY = get_openrouter_api_key()
    hint_name = (local_extracted_name or "").strip()
    
    default_response = {
        "macro_category": "Non class√©",
        "sub_category": "Autre",
        "years_experience": 0,
        "candidate_name": hint_name or "Candidat",
        "profile_summary": "Analyse impossible (cl√© manquante)."
    }
    
    if not API_KEY: return default_response

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://tg-hire.streamlit.app/",
        "X-Title": "TG Hire"
    }
    
    prompt = f"""
    Act as a recruitment expert. Analyze this resume.
    
    1. Name: Find the candidate name. Hint: "{hint_name}".
    2. Category (STRICTLY ONE OF): "Fonctions supports", "Logistique", "Production/Technique".
    3. Sub-category (Do NOT use "Student" or "Intern". Use target job title).
    4. Years of experience (integer).
    5. Summary (2 sentences).

    Reply ONLY with valid JSON:
    {{
        "candidate_name": "...",
        "macro_category": "...",
        "sub_category": "...",
        "years_experience": 0,
        "profile_summary": "..."
    }}

    RESUME TEXT:
    {text[:4000]}
    """

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            data=json.dumps({
                "model": "openai/gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        response.raise_for_status()
        
        content = response.json()['choices'][0]['message']['content']
        clean_content = clean_json_string(content)
        data = json.loads(clean_content)
        
        macro = data.get("macro_category")
        if macro not in ["Fonctions supports", "Logistique", "Production/Technique"]:
             macro = "Non class√©"

        return {
            "macro_category": macro,
            "sub_category": data.get("sub_category", "Autre"),
            "years_experience": data.get("years_experience", 0),
            "candidate_name": data.get("candidate_name", hint_name),
            "profile_summary": data.get("profile_summary", "")
        }
    except Exception as e:
        print(f"OpenRouter Error: {e}")
        return default_response


def extract_name_smart_email(text):
    """
    Extrait le nom via l'email ET v√©rifie sa pr√©sence dans le texte pour confirmer.
    G√®re les formats : prenom.nom, prenom_nom, nom.prenom
    """
    import re
    if not text: return None
    
    # 1. Trouver les emails
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(email_pattern, text)
    
    # Liste d'emails g√©n√©riques √† ignorer
    ignore_emails = ['contact', 'info', 'recrutement', 'job', 'stages', 'rh', 'email', 'gmail', 'yahoo']
    
    for email in emails:
        user_part = email.split('@')[0]
        
        # Si l'email est g√©n√©rique, on saute
        if any(bad in user_part.lower() for bad in ignore_emails):
            continue
            
        # S√©parateurs possibles dans l'email (point, underscore, tiret)
        parts = re.split(r'[._-]', user_part)
        
        # On ne garde que les parties alphab√©tiques de plus de 2 lettres (√©vite les chiffres ou initiales)
        valid_parts = [p for p in parts if p.isalpha() and len(p) >= 3]
        
        if len(valid_parts) >= 2:
            # On a potentiellement Pr√©nom et Nom. On cherche ces mots dans les 1000 premiers caract√®res du CV
            header_text = text[:1000]
            found_parts = []
            
            for part in valid_parts:
                # On cherche le mot exact dans le texte (insensible √† la casse)
                match = re.search(r'\b' + re.escape(part) + r'\b', header_text, re.IGNORECASE)
                if match:
                    # On r√©cup√®re la version √©crite dans le CV (ex: "DUPONT" au lieu de "dupont")
                    found_parts.append(match.group(0))
            
            # Si on a retrouv√© au moins 2 parties du nom dans le texte, c'est un match solide !
            if len(found_parts) >= 2:
                # On retourne les parties trouv√©es, jointes par un espace
                return {"name": " ".join(found_parts), "confidence": 0.99, "method_used": "smart_email_cross_check"}
                
    return None

# -------------------- Extraction de noms des CV (AM√âLIOR√âE) --------------------

def is_valid_name_candidate(text: str) -> bool:
    """
    V√©rifie si un texte ressemble √† un vrai nom.
    Plus permissif pour accepter les noms compos√©s et formats internationaux.
    """
    if not text or len(text) < 2:
        return False
    
    # Nettoyage de base
    text = text.strip()
    
    # Rejets √©vidents
    if len(text) > 50 and ' ' not in text: return False  # Trop long sans espace
    if re.search(r'\d', text): return False  # Contient des chiffres
    if re.search(r'[@‚Ç¨$¬£%&:]', text): return False  # Caract√®res sp√©ciaux invalides (inclut : et &)
    if text.count('-') > 3: return False  # Trop de tirets
    
    # Doit contenir au moins une voyelle (sauf exceptions tr√®s rares)
    if not re.search(r'[aeiouy√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º]', text.lower()):
        return False
    
    # Ratio de lettres (doit √™tre principalement des lettres)
    # On enl√®ve espaces et tirets pour le calcul
    clean_chars = re.sub(r'[\s\-\.]', '', text)
    if not clean_chars: return False
    
    return True


def is_likely_name_line(line: str) -> bool:
    """
    D√©termine si une ligne a de fortes chances d'√™tre un nom (et pas un titre).
    """
    line_lower = line.lower().strip()
    words = line_lower.split()
    
    # 1. Mots INTERDITS : S'ils sont pr√©sents, ce n'est PAS un nom
    forbidden_words = [
        # Mots g√©n√©riques et titres de sections
        'cv', 'curriculum', 'vitae', 'resume', 'profil', 'profile',
        'exp√©rience', 'experience', 'formation', 'education', 
        'comp√©tences', 'skills', 'langues', 'languages',
        'projet', 'project', 'contact', 't√©l√©phone', 'email', 'adresse',
        'page', 'date', 'dipl√¥mes', 'formations', 'certifications', 'hobbies', 'loisirs',
        'permis', 'vehicule', 'v√©hicule', 'conduite', 'driver', 'driving', 'b', 'voiture',
        'centres', 'int√©r√™t', 'projets', 'r√©alis√©s', 'professionnelles',
        'coordonn√©es', 'sp√©cialisations', 'management', 'onboarding', 'performance',
        'sommaire', 'summary', 'objectif', 'objective', 'propos', 'about', 'me', 'moi',
        'bac', 'baccalaur√©at', 'baccalaureate', 'degree', 'niveau', 'level',
        'logiciels', 'ma√Ætris√©s', 'activit√©s', 'associatives',
        
        # √âcoles et Universit√©s (Faux positifs fr√©quents)
        '√©cole', 'ecole', 'school', 'business', 'university', 'universit√©',
        'hec', 'essec', 'esc', 'em', 'dauphine', 'polytechnique', 'centrale', 'mines',
        'master', 'bachelor', 'licence', 'mba', 'dipl√¥me', 'diplome', 'msc',
        'lyc√©e', 'lycee', 'college', 'coll√®ge', 'institut', 'academy',
        
        # Comp√©tences techniques & Outils
        'excel', 'vba', 'power', 'bi', 'crm', 'python', 'java', 'sql', 'office',
        'pack', 'adobe', 'suite', 'google', 'cloud', 'aws', 'azure', 'sap', 'erp',
        'photoshop', 'illustrator', 'indesign', 'canva', 'jira', 'trello',
        
        # Entreprises connues (pour √©viter "BNP Paribas" comme nom)
        'bnp', 'paribas', 'soci√©t√©', 'g√©n√©rale', 'cr√©dit', 'agricole', 'sncf',
        'groupe', 'group', 'bank', 'banque', 'service', 'civique', 'unilever',
        'orange', 'capgemini', 'atos', 'sopra', 'steria', 'accenture', 'deloitte',
        'kpmg', 'ey', 'pwc', 'mazars', 'nge', 'mire',
        
        # Pays et Villes (souvent en en-t√™te)
        'france', 'paris', 'maroc', 'casablanca', 'rabat', 'lyon', 'marseille',
        'toulouse', 'bordeaux', 'lille', 'nantes', 'strasbourg', 'rennes',
        
        # Blancs ou tr√®s courts
        'non', 'trouv√©',
        'analyste', 'financi√®re', 'contr√¥leuse', 'gestion', 'ing√©nieur',
        'directeur', 'directrice', 'manager', 'consultant', 'd√©veloppeur', 'responsable',
        'd√©veloppement', 'rh', 'sirh', 'assistant', 'assistante', 'stagiaire',
        'technicien', 'commercial', 'vente', 'marketing', 'comptable', 'auditeur',
        'senior', 'junior', 'expert', 'chef', 'actuaire', 'data', 'scientist',
        'charg√©', 'charg√©e', 'officer', 'executive', 'associate', 'partner',
        
        # Postes et m√©tiers suppl√©mentaires
        'job', '√©tudiant', 'etudiant', 'student', 'intern', 'internship', 'stage',
        'engineer', 'developer', 'designer', 'analyst', 'specialist', 'coordinator',
        'ia', 'ai', 'ml', 'machine', 'learning', 'deep',
        'm√©canique', 'mecanique', '√©lectrique', 'electrique', 'civil', 'industriel',
        
        # Termes de documents/r√©unions
        'weekly', 'meeting', 'decks', 'deck', 'presentation', 'rapport', 'report',
        'document', 'documents', 'fichier', 'fichiers', 'dossier', 'dossiers',
        
        # Verbes d'action (souvent en bullet points)
        'g√©rer', 'piloter', 'management', 'coordonner', 'd√©velopper', 'cr√©er',
        'r√©aliser', 'participer', 'contribuer', 'superviser', 'analyser',
        
        # Entreprises suppl√©mentaires (faux positifs fr√©quents)
        'procter', 'gamble', 'l\'or√©al', 'loreal', 'carrefour', 'hsbc', 'edf',
        
        # Langues et nationalit√©s
        'fran√ßais', 'francais', 'anglais', 'arabe', 'espagnol', 'courant', 'bilingue',
        'nationality', 'nationalit√©', 'franco-moroccan', 'franco-marocain',
        
        # Termes RH et certifications
        'gpec', 'gepp', 'hdi', 'certification', 'certifications', 'itil',
        
        # Logiciels et outils suppl√©mentaires
        'diapason', 'ktp', 'summit', 'anaplan', 'swiftnet', 'servicenow', 'remedy',
        'dynamics', 'confluence', 'slack', 'figma', 'tableau',
        
        # Loisirs et int√©r√™ts
        'int√©r√™ts', 'interets', 'football', 'natation', 'voyages', 'lecture',
        'sport', 'voyage', 'b√©n√©volat', 'benevolat', 'danse', 'musique',
        
        # Termes scientifiques/acad√©miques
        'physiologie', 'physiopathologie', 'physiopathologies', 'humaine', 'mod√©lisation',
        
        # Mots g√©n√©riques suppl√©mentaires
        'soft', 'hard', 'about', 'linkedin', 'tr√©sorier', 'tresorier', 'ing√©nieure', 'ingenieure',
        
        # ====== NOUVEAUX MOTS INTERDITS (Faux positifs observ√©s) ======
        # Termes techniques/m√©tiers
        'simulation', 'num√©rique', 'numerique', 'pens√©e', 'pensee', 'critique', 'lecture',
        'concept', 'partenaire', 'entreprise', 'entreprises',
        'charge', 'chargee', 'delivery', 'delivery', 'secteur', 'agro-alimentaire',
        'multi-disciplinary', 'multidisciplinary', 'engineering', 'studies', 'etudes', '√©tudes',
        'parcours', 'professionnel', 'profile',
        
        # Sections CV suppl√©mentaires  
        'experiences', 'exp√©riences', 'professionelles', 'professionnelle',
        'competences', 'realisations', 'r√©alisations',
        
        # Entreprises/Lieux suppl√©mentaires
        'saem', 'corum', 'montpellier', 'groupement', 'mousquetaires', 'intermarch√©',
        'leclerc', 'auchan', 'lidl', 'casino', 'monoprix',
        'puteaux', 'orsys', 'angleterre', 'irlande', 'luxembourg',
        'ivalua', 'prm',
        
        # Termes anglais courants
        'delivery', 'manager', 'coordinator', 'specialist', 'officer', 'owner', 'pspo',
        'technical', 'professional', 'summary', 'overview',
        'and', 'alerting', 'blockchain', 'projects', 'purposes', 'program',
        
        # Logiciels techniques / CAO / Outils scientifiques
        'logiciels', 'abaqus', 'catia', 'solidworks', 'autocad', 'ansys', 'matlab', 'bim', 'software',
        'xlstat', 'minitab', 'spss', 'stata', 'r', 'rstudio', 'hive', 'psql',
        'rtgs', 'target', 'swift', 'bpce',
        
        # Soft skills et termes RH
        'stress', '√©quipe', 'equipe', 'organisation', 'esprit', 'sens',
        'gestion', 'autonomie', 'rigueur', 'adaptabilit√©', 'adaptabilite',
        'dynamisme', 'motivation', 'travail', 'team', 'leadership',
        
        # Titres de postes
        'cash', 'flux', 'foncier', 'tr√©sorerie', 'tresorerie',
        # Termes g√©n√©riques r√©currents √† exclure
        'client', 'missions',
        # Certifications/Accr√©ditations sp√©cifiques
        'amf',
        # Mots √† bannir (Faux positifs signal√©s)
        'formateur', 'cuisine', 'agile', 'scrum', 'm√©thodologie', 'methodologie',
        'ocp', 'sa', 'sarl', 'sas', 'inc', 'ltd', 'group', 'groupe', 'holding',
        'r√©sidence', 'residence', 'immeuble', 'apt', 'app', '√©tage',
        'comp√©tence', 'competence', 'professionnelle', 'limit√©e',
        
        # Mots √† bannir (Faux positifs signal√©s)
        'formateur', 'cuisine', 'agile', 'scrum', 'm√©thodologie', 'methodologie',
        'ocp', 'sa', 'sarl', 'sas', 'inc', 'ltd', 'group', 'groupe', 'holding',
        'r√©sidence', 'residence', 'immeuble', 'apt', 'app', '√©tage',
        'comp√©tence', 'competence', 'professionnelle', 'limit√©e',
    ]

    # --- 1.1 FILTRAGE AGRESSIF (Substrings) ---
    # Certains mots invalident TOUTE la ligne m√™me s'ils sont coll√©s
    # Ex: "GestionDeProjet", "Comp√©tenceProfessionnelle"
    fatal_substrings = [
        'comp√©tence', 'competence', 'formation', 'education', 
        'projets', 'r√©alis√©s', 'experience', 'exp√©rience', 
        'sommaire', 'summary', 'profil', 'profile',
        'soft', 'hard', 'skills', 'outils', 'logiciels',
        'management', 'agile', 'scrum', 'methodologie', 'm√©thodologie'
    ]
    if any(fs in line_lower for fs in fatal_substrings):
        return False

    
    # Si un mot de la ligne est interdit -> Rejet
    if any(w in forbidden_words for w in words):
        return False
    
    # Rejet si la ligne contient des caract√®res sp√©ciaux typiques de labels
    if ':' in line or '&' in line:
        return False
    # Rejet si la ligne contient ponctuation indicative de titres/sections
    if any(p in line for p in ['.', '(', ')', '/', ',']) or any(c.isdigit() for c in line):
        return False

    # 2. V√©rifications de structure
    # Doit contenir entre 2 et 5 mots (ex: "Jean Dupont" ou "Jean-Pierre de la Tour")
    if len(words) < 2 or len(words) > 5:
        return False
    
    # Mots d'arr√™t (Articles) : accept√©s dans un nom compos, mais ne doivent pas constituer tout le nom
    stop_words = ['de', 'du', 'des', 'le', 'la', 'les', 'van', 'von', 'da', 'di']
    
    # Si tous les mots sont des stop words -> Rejet
    if all(w in stop_words for w in words):
        return False
    
    # Au moins un mot doit commencer par une majuscule (sauf si tout est en majuscule)
    # Note: line.isupper() g√®re les noms tout en majuscule
    if not line.isupper() and not any(w[0].isupper() for w in line.split() if w):
        return False
        
    return True


def score_name_candidate(text: str) -> float:
    """
    Attribue un score de probabilit√© (0-1) qu'un texte soit un nom.
    """
    score = 0.0
    words = text.split()
    
    # Longueur id√©ale (2-3 mots)
    if 2 <= len(words) <= 3: score += 0.3
    elif len(words) == 4: score += 0.2
    
    # Casse (Casing)
    if text.isupper():  # TOUT EN MAJUSCULES (fr√©quent pour les noms de famille)
        score += 0.2
    elif all(w[0].isupper() for w in words if w):  # Title Case
        score += 0.2
    elif len(words) >= 2 and words[-1].isupper() and words[0][0].isupper():  # Pr√©nom NOM
        score += 0.3
        
    # Validation basique
    if is_valid_name_candidate(text):
        score += 0.2
    else:
        return 0  # Si invalide, score 0 direct
        
    return min(score, 1.0)


def clean_merged_text_pdf(text: str) -> str:
    """
    Corrige les probl√®mes de parsing PDF o√π les mots sont coll√©s.
    Ex: 'Verneuil enABDALLAH' -> 'Verneuil en ABDALLAH'
    Ex: '0787860895HADDOUCHI' -> '0787860895 HADDOUCHI'
    Ex: 'Comp√©tenceProfessionnelle' -> 'Comp√©tence Professionnelle'
    """
    if not text: return ""
    
    # 1. S√©parer minuscule/Majuscule (CamelCase strict)
    # Ex: 'Comp√©tenceProfessionnelle' -> 'Comp√©tence Professionnelle'
    # Attention: 'McDonald' -> 'Mc Donald' (Acceptable pour l'analyse)
    text = re.sub(r'([a-z√†-√ø])([A-Z√Ä-≈∏])', r'\1 \2', text)
    
    # 2. S√©parer Chiffre/Lettre (ex: 95HADDOUCHI)
    text = re.sub(r'([0-9])([a-zA-Z]{2,})', r'\1 \2', text)
    
    return text

def extract_name_from_cv_text(text):
    """
    Extrait le nom complet d'un CV avec une approche heuristique avanc√©e.
    G√®re les cas comme "## Hiba BELFARJI" ou les mises en page OCR.
    """
    if not text or len(text.strip()) < 10:
        return {"name": None, "confidence": 0, "method_used": "text_too_short"}
    
    # NETTOYAGE CRITIQUE : S√©paration des mots coll√©s (OCR/PDF mal form√©s)
    text = clean_merged_text_pdf(text)
    
    lines = text.split('\n')
    
    # --- √âTAPE 1 : Nettoyage pr√©liminaire des lignes ---
    # MODIF : Augmentation de la port√©e d'analyse √† 200 lignes pour capturer les noms dans les sidebars (multi-colonnes)
    SCAN_LIMIT = 200
    cleaned_lines = []
    
    # On it√®re avec l'index pour p√©naliser la position si n√©cessaire
    for idx, line in enumerate(lines[:SCAN_LIMIT]):
        # Enlever les caract√®res de formatage Markdown ou OCR
        clean = line.strip()
        clean = re.sub(r'^##\s*', '', clean)  # Enlever "## " au d√©but
        clean = re.sub(r'^\*\*\s*', '', clean)  # Enlever "** " au d√©but
        clean = re.sub(r'\s*\*\*$', '', clean)  # Enlever " **" √† la fin
        clean = re.sub(r'^[-‚Ä¢‚û¢‚Äì]\s*', '', clean)  # Enlever les puces
        clean = re.sub(r'^[oÔÅ∂ÔÇß]\s*', '', clean) # Enlever autres puces OCR
        
        if not clean:
            continue
            
        # On garde l'info de ligne originelle si besoin
        cleaned_lines.append(clean)
        
        # Gestion des noms espac√©s (ex: "I c h r a k B A K I A" ou "M a r w a n  L A A N I G R I")
        # Si la ligne contient beaucoup d'espaces et des lettres isol√©es
        if len(clean) > 5 and ' ' in clean:
            # Compte le nombre de tokens de 1 lettre
            single_letter_tokens = [w for w in clean.split() if len(w) == 1 and w.isalpha()]
            if len(single_letter_tokens) > len(clean.split()) / 2:
                # C'est probablement un texte espac√©
                # AM√âLIORATION: Reconstituer en se basant sur les transitions de casse
                # "I c h r a k B A K I A" -> "Ichrak BAKIA"
                result_parts = []
                current_word = ""
                prev_was_lower = False
                
                for char in clean:
                    if char == ' ':
                        continue  # Ignorer les espaces
                    
                    is_upper = char.isupper()
                    
                    # Transition minuscule -> majuscule = nouveau mot (pr√©nom termin√©, nom commence)
                    if prev_was_lower and is_upper and current_word:
                        result_parts.append(current_word)
                        current_word = char
                    else:
                        current_word += char
                    
                    prev_was_lower = char.islower()
                
                if current_word:
                    result_parts.append(current_word)
                
                # Si on a au moins 2 parties, c'est probablement Pr√©nom NOM
                if len(result_parts) >= 2:
                    normalized = ' '.join(result_parts)
                    cleaned_lines.append(normalized)
                elif result_parts:
                    # Sinon fallback sur l'ancienne m√©thode
                    temp = re.sub(r'\s{2,}', '|', clean)
                    temp = temp.replace(' ', '')
                    normalized = temp.replace('|', ' ')
                    if normalized != clean:
                        cleaned_lines.append(normalized)

    # --- √âTAPE 1-BIS : Fusion de lignes (Pour les cas : L1=Pr√©nom, L2=Nom) ---
    # Ex: "Oussama" \n "GARMOUMI"
    merged_candidates = []
    if len(cleaned_lines) > 1:
        for i in range(len(cleaned_lines) - 1):
            l1 = cleaned_lines[i]
            l2 = cleaned_lines[i+1]
            # Si l1 ressemble √† un pr√©nom (Title) et l2 √† un nom (Upper) ou vice versa
            # Et qu'ils ne sont pas trop longs
            if len(l1.split()) == 1 and len(l2.split()) == 1:
                # Oussama \n GARMOUMI
                if l1.istitle() and l2.isupper():
                    merged_candidates.append(f"{l1} {l2}")
                # GARMOUMI \n Oussama
                elif l1.isupper() and l2.istitle():
                    merged_candidates.append(f"{l1} {l2}")

    # --- √âTAPE 2 : Recherche de patterns explicites (Regex forte) ---
    # Pattern : Pr√©nom (Title) NOM (Upper) ou NOM (Upper) Pr√©nom (Title)
    # Ex: "Hiba BELFARJI" ou "BELFARJI Hiba"
    regex_strong = r'^([A-Z√Ä-≈∏][a-z√†-√ø]+(?:-[A-Z√Ä-≈∏][a-z√†-√ø]+)?)\s+([A-Z√Ä-≈∏]{2,}(?:\s+[A-Z√Ä-≈∏]{2,})?)$'
    regex_reverse = r'^([A-Z√Ä-≈∏]{2,}(?:\s+[A-Z√Ä-≈∏]{2,})?)\s+([A-Z√Ä-≈∏][a-z√†-√ø]+(?:-[A-Z√Ä-≈∏][a-z√†-√ø]+)?)$'
    
    # Test d'abord sur les candidats merg√©s
    for cand in merged_candidates:
         if re.match(regex_strong, cand) or re.match(regex_reverse, cand):
             # V√©rif extra : pas de mot interdit
             if is_likely_name_line(cand):
                 return {"name": cand, "confidence": 0.90, "method_used": "merged_lines_regex"}

    for line in cleaned_lines:
        line_clean = line.strip()
        # Test Pr√©nom NOM
        match = re.match(regex_strong, line_clean)
        if match and is_likely_name_line(line_clean):
            return {"name": line_clean, "confidence": 0.95, "method_used": "regex_strong_firstname_lastname"}
        
        # Test NOM Pr√©nom
        match = re.match(regex_reverse, line_clean)
        if match and is_likely_name_line(line_clean):
            return {"name": line_clean, "confidence": 0.95, "method_used": "regex_strong_lastname_firstname"}

    # --- √âTAPE 3 : Syst√®me de Scoring (Heuristique) ---
    best_candidate = None
    best_score = 0.0
    
    for line in cleaned_lines:
        # Check rapide anti-spam (si ligne > 6 mots, peu probable que ce soit un nom sauf espac√©)
        if len(line.split()) > 6:
            continue

        if not is_likely_name_line(line):
            continue
            
        current_score = score_name_candidate(line)
        
        # Bonus si la ligne est isol√©e (pas de phrase avant/apr√®s dans le bloc original ?? Difficile √† dire ici)
        # Mais on peut p√©naliser les lignes tr√®s bas si elles n'ont pas un score excellent
        
        if current_score > best_score:
            best_score = current_score
            best_candidate = line
            
    # --- √âTAPE 4 : Fallback Proximit√© Email/Tel (Deep Scan) ---
    # Recherche √©tendue jusqu'√† SCAN_LIMIT au lieu de 50
    if best_score < 0.6:
        for i, line in enumerate(lines[:SCAN_LIMIT]):
            # Si on trouve un email ou un tel
            if re.search(r'@[\w\.-]+', line) or re.search(r'(?:(?:\+|00)33|0)\s*[1-9]', line):
                # Regarder 10 lignes AVANT (contexte imm√©diat)
                start_range = max(0, i - 10)
                # Mais aussi 3 lignes APR√àS (parfois le nom est sous l'email dans les sidebars)
                end_range = min(len(lines), i + 3)
                
                context_lines = lines[start_range:i] + lines[i+1:end_range]
                
                for ctx_line in context_lines:
                    ctx_line = ctx_line.strip()
                    # Nettoyage l√©ger
                    clean_ctx = re.sub(r'^##\s*', '', ctx_line)
                    clean_ctx = re.sub(r'^\*\*\s*', '', clean_ctx)
                    clean_ctx = re.sub(r'\s*\*\*$', '', clean_ctx)
                    clean_ctx = re.sub(r'^[-‚Ä¢‚û¢‚Äì]\s*', '', clean_ctx)
                    
                    if not clean_ctx: continue

                    if is_likely_name_line(clean_ctx):
                        cand_score = score_name_candidate(clean_ctx)
                        # On booste le score car proche des contacts
                        boosted_score = cand_score + 0.3
                        if boosted_score > best_score:
                            best_score = boosted_score
                            best_candidate = clean_ctx

    # --- √âTAPE 5 : Fallback Ultime (Recherche de patterns faibles) ---
    # Si toujours rien, on cherche n'importe quoi qui ressemble √† "Pr√©nom NOM" m√™me sans contexte
    if not best_candidate or best_score < 0.4:
        # Regex plus permissive (admet Title Title) pour les cas comme "Elkani Sadia"
        regex_permissive = r'^([A-Z√Ä-≈∏][a-z√†-√ø]+)\s+([A-Z√Ä-≈∏][a-z√†-√ø]+)$'
        
        for line in cleaned_lines:
             if re.match(regex_permissive, line) and is_likely_name_line(line):
                 # On v√©rifie quand m√™me que ce n'est pas un nom de ville ou d'√©cole connu (d√©j√† filtr√© par is_likely)
                 score = 0.5 # Score moyen
                 if score > best_score:
                     best_score = score
                     best_candidate = line
    
    if best_candidate and best_score > 0.4:
        return {"name": best_candidate, "confidence": best_score, "method_used": "scoring_best_match"}

    if best_candidate and best_score > 0.4:
        return {"name": best_candidate, "confidence": best_score, "method_used": "scoring_best_match"}

    return {"name": None, "confidence": 0, "method_used": "not_found"}


def extract_name_from_line(line):
    """Extrait un nom candidat d'une ligne en utilisant des heuristiques (fonction legacy)"""
    if not line or len(line.strip()) < 5:
        return None
    
    # Nettoyer la ligne
    line = line.strip()
    line = re.sub(r'^##\s*', '', line)  # Enlever "## " au d√©but
    line = re.sub(r'^\*\*\s*', '', line)  # Enlever "** " au d√©but
    line = re.sub(r'\s*\*\*$', '', line)  # Enlever " **" √† la fin
    
    # Utiliser les nouvelles fonctions
    if is_likely_name_line(line):
        score = score_name_candidate(line)
        if score > 0.4:
            return line
    
    return None

# -------------------- G√©n√©ration du ZIP organis√© --------------------
def merge_results_with_ai_analysis(original_results):
    """
    Int√®gre les r√©sultats des analyses IA dans les r√©sultats originaux.
    Met √† jour les cat√©gories des CV qui ont √©t√© analys√©s par l'IA.
    """
    # Cr√©er une copie pour ne pas modifier l'original
    updated_results = original_results.copy()
    
    # Si des analyses IA existent, int√©grer les r√©sultats
    if hasattr(st.session_state, 'deepseek_analyses') and st.session_state.deepseek_analyses:
        ai_results = {result['Fichier']: result['Cat√©gorie'] for result in st.session_state.deepseek_analyses}
        
        for i, result in enumerate(updated_results):
            filename = result['file']
            if filename in ai_results:
                ai_category = ai_results[filename]
                # Normaliser la cat√©gorie IA selon nos cat√©gories standard
                if "support" in ai_category.lower():
                    updated_results[i]['category'] = 'Fonctions supports'
                elif "logistique" in ai_category.lower():
                    updated_results[i]['category'] = 'Logistique'
                elif "production" in ai_category.lower() or "technique" in ai_category.lower():
                    updated_results[i]['category'] = 'Production/Technique'
                # Si la cat√©gorie IA n'est pas reconnue, on garde "Non class√©"
    
    return updated_results

def create_organized_zip(results, file_list):
    """
    Cr√©e un fichier ZIP avec les CV organis√©s par cat√©gorie et renomm√©s.
    Int√®gre automatiquement les r√©sultats des analyses IA.
    Retourne les bytes du ZIP et un DataFrame manifest.
    """
    import zipfile
    import io
    from io import BytesIO
    
    # Int√©grer les analyses IA dans les r√©sultats
    merged_results = merge_results_with_ai_analysis(results)
    
    zip_buffer = BytesIO()
    manifest_data = []
    
    # Cr√©er les dossiers par cat√©gorie
    folders = {
        'FONCTIONS SUPPORTS': '1_Fonctions_Supports/',
        'LOGISTIQUE': '2_Logistique/',
        'PRODUCTION / TECHNIQUE': '3_Production_Technique/',
        'DIVERS / HORS P√âRIM√àTRE': '4_Divers_Hors_Perimetre/',
        'Non class√©': '5_Non_Classe/'
    }
    
    # D√©terminer quelles cat√©gories sont r√©ellement pr√©sentes
    categories_present = set(result['category'] for result in merged_results)
    folders_to_create = set()
    for category in categories_present:
        if category in folders:
            folders_to_create.add(folders[category])
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        # Cr√©er seulement les dossiers n√©cessaires
        for folder in folders_to_create:
            zip_file.writestr(folder, '')
        
        # Traiter chaque CV avec les r√©sultats int√©grant l'IA
        for result in merged_results:
            original_name = result['file']
            category = result['category']
            
            # D√©terminer le nom final du fichier
            if 'extracted_name' in result and result['extracted_name'] and result['extracted_name']['name']:
                # Utiliser le nom extrait
                extracted_name = result['extracted_name']['name']
                # Normaliser les espaces multiples et nettoyer
                try:
                    import re as _re
                    cleaned_extracted = _re.sub(r"\s+", " ", extracted_name).strip()
                except Exception:
                    cleaned_extracted = extracted_name.strip()
                final_name = f"{cleaned_extracted}.pdf"
                confidence = result['extracted_name']['confidence']
                method = result['extracted_name']['method_used']
            else:
                # Garder le nom original
                final_name = original_name
                confidence = 0
                method = 'original_name'
            
            # D√©terminer le dossier de destination
            folder = folders.get(category, 'Non_classe/')
            file_path_in_zip = folder + final_name
            
            # Trouver le fichier original dans file_list
            original_file = None
            for item in file_list:
                if item['name'] == original_name:
                    original_file = item['file']
                    break
            
            if original_file:
                try:
                    # Lire le contenu du fichier original
                    original_file.seek(0)
                    file_content = original_file.read()
                    # Ajouter au ZIP
                    zip_file.writestr(file_path_in_zip, file_content)
                    
                    # Ajouter au manifest (une colonne par champ + r√©cap profil + ann√©es exp)
                    manifest_data.append({
                        'fichier_original': original_name,
                        'nouveau_nom': final_name,
                        'categorie': category,
                        'sous_categorie': result.get('sub_category', ''),
                        'annees_experience': result.get('years_experience', 0),
                        'confiance_extraction': confidence,
                        'methode_extraction': method,
                        'recap_profil': result.get('profile_summary', ''),
                        'dossier': folder.rstrip('/')
                    })
                except Exception as e:
                    st.warning(f"Erreur lors du traitement de {original_name}: {e}")
        
        # Cr√©er et ajouter le manifest CSV (avec point-virgule pour Excel FR) + Excel natif
        if manifest_data:
            manifest_df = pd.DataFrame(manifest_data)
            # CSV avec point-virgule pour Excel FR et encodage utf-8-sig (BOM)
            manifest_csv = manifest_df.to_csv(index=False, sep=';', encoding='utf-8-sig')
            zip_file.writestr('manifest.csv', manifest_csv.encode('utf-8-sig'))
            
            # Ajouter aussi un fichier Excel natif (.xlsx) pour compatibilit√© Excel 2010
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                manifest_df.to_excel(writer, index=False, sheet_name='Manifest')
            excel_buffer.seek(0)
            zip_file.writestr('manifest.xlsx', excel_buffer.getvalue())
    
    zip_buffer.seek(0)
    return zip_buffer.getvalue(), pd.DataFrame(manifest_data)

# -------------------- Interface Utilisateur --------------------
st.title("üìÑ Analyseur de CVs Intelligent")
display_commit_info()
tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìä Classement de CVs", "üéØ Analyse de Profil", "üìñ Guide des M√©thodes", "üìà Statistiques de Feedback", "üóÇÔ∏è Auto-classification"])

with tab1:
    st.markdown("### üìÑ Informations du Poste")
    col1, col2 = st.columns([2, 1])
    with col1:
        # Menu d√©roulant pour choisir entre annonce et fiche de poste
        job_source = st.selectbox(
            "Source des informations du poste",
            ["Annonce (saisie manuelle)", "Fiche de poste (PDF)"],
            index=0
        )
        
        job_title = ""
        job_description = ""
        fiche_poste_text = ""
        
        if job_source == "Annonce (saisie manuelle)":
            job_title = st.text_input("Intitul√© du poste", placeholder="Ex: Archiviste Junior")
            job_description = st.text_area("Description du poste", height=200, key="jd_ranking", placeholder="Collez la description...")
        else:  # Fiche de poste (PDF)
            fiche_poste_file = st.file_uploader("Importer une fiche de poste (PDF)", type=["pdf"], key="fiche_poste_uploader")
            if fiche_poste_file:
                fiche_poste_text = extract_text_from_pdf(fiche_poste_file)
                if fiche_poste_text and not fiche_poste_text.startswith("Erreur"):
                    # Use the fiche content silently (no success toast)
                    job_description = fiche_poste_text  # Utiliser le contenu de la fiche comme description
                else:
                    st.error("Erreur lors de la lecture de la fiche de poste.")
                    
    with col2:
        st.markdown("#### üì§ Importer des CVs")
        uploaded_files_ranking = st.file_uploader("Importer des CVs", type=["pdf"], accept_multiple_files=True, key="ranking_uploader")
    
    st.markdown("---")
    
    analysis_method = st.selectbox(
        "‚ú® Choisissez votre m√©thode de classement",
        ["M√©thode Cosinus (Mots-cl√©s)", "M√©thode S√©mantique (Embeddings)", "Scoring par R√®gles (Regex)", 
         "Analyse combin√©e (Ensemble)", "Analyse par IA (DeepSeek)", "Analyse par IA (Gemini)", 
         "Analyse par IA (Groq)", "Analyse par IA (Claude)", "Analyse par IA (OpenRouter)"],
        index=0, help="Consultez l'onglet 'Guide des M√©thodes'."
    )
    
    # Options suppl√©mentaires pour l'analyse combin√©e
    if analysis_method == "Analyse combin√©e (Ensemble)":
        st.markdown("### üî¢ Param√®tres de combinaison")
        col1, col2, col3 = st.columns(3)
        with col1:
            cosinus_weight = st.slider("Poids Cosinus", 0.0, 1.0, 0.2, 0.1, key="slider_cosinus")
        with col2:
            semantic_weight = st.slider("Poids S√©mantique", 0.0, 1.0, 0.4, 0.1, key="slider_semantic")
        with col3:
            rules_weight = st.slider("Poids R√®gles", 0.0, 1.0, 0.4, 0.1, key="slider_rules")
            
        # Normalisation des poids
        total_weight = cosinus_weight + semantic_weight + rules_weight
        if total_weight > 0:
            norm_cosinus = cosinus_weight / total_weight
            norm_semantic = semantic_weight / total_weight
            norm_rules = rules_weight / total_weight
            st.info(f"Poids normalis√©s : Cosinus {norm_cosinus:.2f}, S√©mantique {norm_semantic:.2f}, R√®gles {norm_rules:.2f}")
        else:
            st.warning("Veuillez attribuer un poids non nul √† au moins une m√©thode.")
    
    # Options pour le traitement par lots
    use_batch_processing = False
    if len(uploaded_files_ranking or []) > 20:
        use_batch_processing = st.checkbox("Activer le traitement par lots (recommand√© pour plus de 20 CVs)", 
                                         value=True, 
                                         help="Traite les CVs par petits groupes pour √©viter les probl√®mes de m√©moire")
        if use_batch_processing:
            batch_size = st.slider("Taille du lot", min_value=5, max_value=50, value=10, 
                                  help="Nombre de CVs trait√©s simultan√©ment")

    if st.button("üîç Analyser et Classer", type="primary", width="stretch", disabled=not (uploaded_files_ranking and job_description)):
        # Sauvegarder les informations pour le feedback
        st.session_state.last_analysis_method = analysis_method
        st.session_state.last_job_title = job_title
        st.session_state.last_job_description = job_description
        st.session_state.last_cv_count = len(uploaded_files_ranking)
        
        # Traitement standard ou par lots selon le nombre de CVs
        if use_batch_processing:
            # Cr√©er une barre de progression
            progress_placeholder = st.empty()
            progress_bar = st.progress(0)
            
            def update_progress(progress):
                progress_placeholder.text(f"Traitement en cours... {int(progress * 100)}%")
                progress_bar.progress(progress)
            
            # Traitement par lots
            results, file_names = batch_process_resumes(
                job_description=job_description,
                file_list=uploaded_files_ranking,
                analysis_method=analysis_method,
                batch_size=batch_size,
                progress_callback=update_progress,
                extract_text_from_pdf_func=extract_text_from_pdf,
                rank_resumes_funcs={
                    'cosine': rank_resumes_with_cosine,
                    'embeddings': rank_resumes_with_embeddings,
                    'rules': rank_resumes_with_rules,
                    'ai': rank_resumes_with_ai,
                    'ensemble': lambda jd, res, fnames, **kwargs: rank_resumes_with_ensemble(
                        jd, res, fnames,
                        cosine_func=rank_resumes_with_cosine,
                        semantic_func=rank_resumes_with_embeddings,
                        rules_func=rank_resumes_with_rules,
                        **kwargs
                    )
                }
            )
            
            explanations = results.get("explanations")
            logic = results.get("logic")
            
            # Nettoyer la barre de progression
            progress_placeholder.empty()
            progress_bar.empty()
            
        else:
            # Lecture des fichiers PDF
            resumes, file_names = [], []
            progress_placeholder = st.empty()
            progress_bar = st.progress(0)
            total_files = len(uploaded_files_ranking)
            
            for idx, file in enumerate(uploaded_files_ranking):
                progress_placeholder.info(f"üìÑ Lecture du fichier ({idx+1}/{total_files}) : {file.name}")
                progress_bar.progress((idx + 1) / total_files * 0.3)  # 30% pour lecture
                text = extract_text_from_pdf(file)
                if not "Erreur" in text:
                    resumes.append(text)
                    file_names.append(file.name)
            
            # Analyse selon la m√©thode choisie
            results, explanations, logic = {}, None, None
            
            
            if analysis_method == "Analyse par IA (Gemini)":
                progress_placeholder.info(f"ü§ñ Analyse Gemini en cours...")
                result = rank_resumes_with_gemini(job_description, resumes, file_names)
                results = {"scores": result["scores"], "explanations": result["explanations"]}
                explanations = result["explanations"]
                progress_bar.progress(1.0)

            elif analysis_method == "Analyse par IA (Groq)":
                progress_placeholder.info(f"ü§ñ Analyse Groq en cours...")
                result = rank_resumes_with_groq(job_description, resumes, file_names)
                results = {"scores": result["scores"], "explanations": result["explanations"]}
                explanations = result["explanations"]
                progress_bar.progress(1.0)

            elif analysis_method == "Analyse par IA (Claude)":
                progress_placeholder.info(f"ü§ñ Analyse Claude en cours...")
                # Manque la fonction batch pour Claude, on it√®re simplement
                scores_data = []
                for i, r_text in enumerate(resumes):
                    progress_placeholder.info(f"ü§ñ Analyse Claude ({i+1}/{len(resumes)})")
                    scores_data.append(get_detailed_score_with_claude(job_description, r_text))
                    progress_bar.progress((i + 1) / len(resumes))
                results = {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}
                explanations = results.get("explanations")

            elif analysis_method == "Analyse par IA (OpenRouter)":
                progress_placeholder.info(f"ü§ñ Analyse OpenRouter en cours...")
                result = rank_resumes_with_openrouter(job_description, resumes, file_names)
                results = {"scores": result["scores"], "explanations": result["explanations"]}
                explanations = result["explanations"]
                progress_bar.progress(1.0)

            elif analysis_method == "Analyse par IA (DeepSeek)":
                # Analyse IA avec progression individuelle
                progress_placeholder.info(f"ü§ñ Analyse par IA en cours (0/{len(resumes)})...")
                progress_bar.progress(0.3)
                
                scores_data = []
                for i, resume_text in enumerate(resumes):
                    progress_placeholder.info(f"ü§ñ Analyse par IA ({i+1}/{len(resumes)}) : {file_names[i]}")
                    progress_bar.progress(0.3 + (i + 1) / len(resumes) * 0.7)
                    scores_data.append(get_detailed_score_with_ai(job_description, resume_text))
                
                results = {"scores": [d["score"] for d in scores_data], "explanations": {file_names[i]: d["explanation"] for i, d in enumerate(scores_data)}}
                explanations = results.get("explanations")
   
            elif analysis_method == "Scoring par R√®gles (Regex)":
                progress_placeholder.info(f"üìè Analyse par r√®gles en cours...")
                rule_results = rank_resumes_with_rules(job_description, resumes, file_names)
                results = {"scores": [r["score"] for r in rule_results]}
                logic = {r["file_name"]: r["logic"] for r in rule_results}
                progress_bar.progress(1.0)
            
            elif analysis_method == "M√©thode S√©mantique (Embeddings)":
                progress_placeholder.info(f"üß† Analyse s√©mantique en cours...")
                results = rank_resumes_with_embeddings(job_description, resumes, file_names)
                logic = results.get("logic")
                progress_bar.progress(1.0)
            
            elif analysis_method == "Analyse combin√©e (Ensemble)":
                progress_placeholder.info(f"üîó Analyse combin√©e en cours...")
                results = rank_resumes_with_ensemble(
                    job_description, resumes, file_names,
                    cosinus_weight=cosinus_weight,
                    semantic_weight=semantic_weight,
                    rules_weight=rules_weight,
                    cosine_func=rank_resumes_with_cosine,
                    semantic_func=rank_resumes_with_embeddings,
                    rules_func=rank_resumes_with_rules
                )
                logic = results.get("logic")
                progress_bar.progress(1.0)
            
            else:  # M√©thode Cosinus par d√©faut
                progress_placeholder.info(f"üìê Analyse cosinus en cours...")
                results = rank_resumes_with_cosine(job_description, resumes, file_names)
                logic = results.get("logic")
                progress_bar.progress(1.0)

            # Nettoyer les indicateurs de progression
            progress_placeholder.empty()
            progress_bar.empty()

            scores = results.get("scores", [])
            if scores is not None and len(scores) > 0:
                ranked_resumes = sorted(zip(file_names, scores), key=lambda x: x[1], reverse=True)
                results_df = pd.DataFrame(ranked_resumes, columns=["Nom du CV", "Score brut"])
                results_df["Rang"] = range(1, len(results_df) + 1)
                results_df["Score"] = results_df["Score brut"].apply(lambda x: f"{x*100:.1f}%")
                
                # Sauvegarder les r√©sultats dans la session pour maintenir l'affichage
                st.session_state.last_analysis_result = results_df
                st.session_state.last_analysis_method = analysis_method
                st.session_state.ranked_resumes = ranked_resumes
                st.session_state.file_names = file_names
                st.session_state.scores = scores
                st.session_state.logic = logic
                st.session_state.job_title = job_title
                st.session_state.job_description = job_description
                st.session_state.last_job_title = job_title
                st.session_state.last_job_description = job_description
                st.session_state.last_file_names = file_names
                st.session_state.explanations = explanations
                
            else:
                st.error("L'analyse n'a retourn√© aucun score.")

    # Affichage des r√©sultats (toujours visible, m√™me apr√®s feedback)
    if hasattr(st.session_state, 'last_analysis_result') and st.session_state.last_analysis_result is not None:
        results_df = st.session_state.last_analysis_result
        ranked_resumes = st.session_state.ranked_resumes
        logic = getattr(st.session_state, 'logic', None)
        explanations = getattr(st.session_state, 'explanations', None)
        
        st.markdown("### üèÜ R√©sultats du Classement")
        st.dataframe(results_df[["Rang", "Nom du CV", "Score"]], width="stretch", hide_index=True)
        
        if logic:
            st.markdown("### üß† Logique de Scoring")
            for _, row in results_df.iterrows():
                file_name = row["Nom du CV"]
                with st.expander(f"D√©tail du score pour : **{file_name}**"):
                    st.json(logic.get(file_name, {}))

        if explanations:
            st.markdown("### üìù Analyse d√©taill√©e par l'IA")
            for _, row in results_df.iterrows():
                file_name = row["Nom du CV"]
                with st.expander(f"Analyse pour : **{file_name}**"):
                    explanation = explanations.get(file_name, "N/A")
                    import re
                    
                    # Extraction et affichage du score
                    score_match = re.search(r"score(?: de correspondance)?\s*:\s*(\d+)\s*%", explanation, re.IGNORECASE)
                    if score_match:
                        st.markdown(f"**Score : {score_match.group(1)}%**")
                    
                    # Nouvelle approche : affichage complet avec troncature intelligente
                    def smart_truncate(text, max_length=1000):
                        """Tronque intelligemment le texte en gardant le sens"""
                        if len(text) <= max_length:
                            return text
                        
                        # Cherche le dernier point, point d'exclamation ou d'interrogation avant la limite
                        truncate_pos = max_length
                        for i in range(max_length, max(0, max_length-200), -1):
                            if text[i] in '.!?':
                                truncate_pos = i + 1
                                break
                        
                        return text[:truncate_pos].strip() + "..."
                    
                    # Afficher l'explication compl√®te avec troncature intelligente
                    cleaned_explanation = explanation.replace("Score:", "").replace(f"{score_match.group(1)}%" if score_match else "", "").strip()
                    st.markdown(smart_truncate(cleaned_explanation))
        
        # Syst√®me de feedback par CV avec formulaires pour √©viter les rechargements
        st.markdown("---")
        st.markdown("### üí¨ Feedback sur les r√©sultats")
        
        for i, (file_name, score) in enumerate(ranked_resumes):
            with st.expander(f"üí¨ √âvaluer le classement de : {file_name}"):
                feedback_key = f"feedback_form_{i}"
                submitted_key = f"submitted_{i}"
                
                # V√©rifier si le feedback pour ce CV a d√©j√† √©t√© soumis
                if submitted_key not in st.session_state:
                    st.session_state[submitted_key] = False
                
                # Si d√©j√† soumis, afficher un message de confirmation
                if st.session_state[submitted_key]:
                    st.success(f"‚úÖ Merci pour votre feedback sur {file_name} !")
                else:
                    # Cr√©er un formulaire pour chaque CV pour √©viter les rechargements
                    with st.form(key=feedback_key):
                        st.markdown(f"#### üìä √âvaluation du CV : {file_name}")
                        st.caption(f"Score actuel : {score*100:.1f}%")

                        # Slider pour la notation (1-5)
                        cv_feedback_score = st.slider(
                            f"Note pour {file_name} (1 = Tr√®s insatisfaisant, 5 = Excellent)",
                            min_value=1,
                            max_value=5,
                            value=3,
                            step=1,
                            key=f"cv_rating_{i}",
                            help="Glissez pour donner votre note"
                        )

                        # Affichage visuel de la note
                        score_labels = {
                            1: "‚≠ê Tr√®s insatisfaisant",
                            2: "‚≠ê‚≠ê Insatisfaisant",
                            3: "‚≠ê‚≠ê‚≠ê Acceptable",
                            4: "‚≠ê‚≠ê‚≠ê‚≠ê Satisfaisant",
                            5: "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent"
                        }
                        cv_feedback_text = st.text_area(
                            "Commentaires sp√©cifiques (optionnel)",
                            placeholder=f"Points forts/faibles du classement de {file_name}...",
                            height=80,
                            key=f"cv_comment_{i}"
                        )

                        # Bouton de soumission avec style am√©lior√©
                        col1, col2 = st.columns([3, 1])
                        with col2:
                            cv_submit_button = st.form_submit_button(
                                label=f"üì§ √âvaluer",
                                type="secondary"
                            )
                        
                        if cv_submit_button:
                            job_title = getattr(st.session_state, 'job_title', '')
                            job_description = getattr(st.session_state, 'job_description', '')
                            analysis_method = getattr(st.session_state, 'last_analysis_method', '')
                            
                            result = save_feedback(
                                analysis_method=f"{analysis_method} (CV individuel)",
                                job_title=job_title,
                                job_description_snippet=job_description[:200],
                                cv_count=1,
                                feedback_score=cv_feedback_score,
                                feedback_text=f"Feedback pour {file_name}: {cv_feedback_text}"
                            )
                            st.session_state[submitted_key] = True
                            if result:
                                st.success(f"‚úÖ Merci pour votre feedback sur {file_name} !")
                                st.rerun()
                            else:
                                st.error("‚ùå √âchec de l'enregistrement du feedback.")
        
        # Feedback global sur l'analyse
        st.markdown("---")
        st.markdown("### üåü Feedback global sur l'analyse")

        # Formulaire de feedback global directement visible
        if not getattr(st.session_state, 'feedback_submitted', False):
            with st.form(key='feedback_form'):
                st.markdown("**Comment √©valuez-vous la qualit√© globale des r√©sultats de cette analyse ?**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Slider pour la notation (1-5)
                    global_feedback_score = st.slider(
                        "Note globale (1 = Tr√®s insatisfaisant, 5 = Excellent)",
                        min_value=1,
                        max_value=5,
                        value=3,
                        step=1,
                        help="Glissez pour donner votre note"
                    )

                    # Crit√®res d'√©valuation sp√©cifiques
                    st.markdown("**Crit√®res √©valu√©s :**")
                    user_criteria = st.multiselect(
                        "S√©lectionnez les crit√®res :",
                        options=[
                            "Pertinence du classement",
                            "Clart√© de la logique d'analyse",
                            "Rapidit√© d'ex√©cution",
                            "Facilit√© d'utilisation",
                            "Pr√©cision des scores",
                            "Qualit√© des explications",
                            "Autre"
                        ],
                        default=[],
                        help="Tous les crit√®res qui s'appliquent"
                    )
                    
                with col2:
                    # Champ pour les commentaires
                    global_feedback_text = st.text_area(
                        "Commentaires et suggestions d'am√©lioration (optionnel)",
                        placeholder="Qu'avez-vous appr√©ci√© ? Que pourrait-on am√©liorer ? Quelles fonctionnalit√©s ajouter ?",
                        height=200
                    )

                # Bouton de soumission avec style am√©lior√©
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    submit_button = st.form_submit_button(
                        label="üì§ Envoyer mon feedback",
                        type="primary",
                        width="stretch"
                    )

                if submit_button:
                    job_title = getattr(st.session_state, 'job_title', '')
                    job_description = getattr(st.session_state, 'job_description', '')
                    analysis_method = getattr(st.session_state, 'last_analysis_method', '')
                    file_names = getattr(st.session_state, 'file_names', [])

                    criteria_text = ", ".join(user_criteria) if user_criteria else ""

                    result = save_feedback(
                        analysis_method=analysis_method,
                        job_title=job_title,
                        job_description_snippet=job_description,
                        cv_count=len(file_names),
                        feedback_score=global_feedback_score,
                        feedback_text=global_feedback_text,
                        user_criteria=criteria_text,
                        improvement_suggestions=global_feedback_text
                    )
                    st.session_state.feedback_submitted = True
                    if result:
                        st.success("‚úÖ Merci pour votre feedback ! Il nous aidera √† am√©liorer notre syst√®me.")
                        st.balloons()  # Animation festive
                        st.rerun()
                    else:
                        st.error("‚ùå √âchec de l'enregistrement du feedback.")

        # Message si le feedback a d√©j√† √©t√© soumis
        elif getattr(st.session_state, 'feedback_submitted', False):
            st.success("‚úÖ Merci pour votre feedback ! Il nous aidera √† am√©liorer notre syst√®me.")

with tab2:
    st.markdown("### üìÇ Importer un ou plusieurs CVs")
    uploaded_files_analysis = st.file_uploader("Importer des CVs", type=["pdf"], key="analysis_uploader_single", accept_multiple_files=True)
    
    analysis_type_single = st.selectbox(
        "Type d'analyse souhait√©",
        ("Analyse par IA (DeepSeek)", "Analyse par IA (Gemini)", "Analyse par IA (Groq)", "Analyse par IA (Claude)", "Analyse par IA (OpenRouter)",
         "Analyse par Regex (Extraction d'entit√©s)", "Analyse par la M√©thode S√©mantique", 
         "Analyse par la M√©thode Cosinus", "Analyse Combin√©e (Ensemble)")
    )
    captions = {
        "Analyse par IA (DeepSeek)": "Analyse qualitative (points forts/faibles).",
        "Analyse par IA (Gemini)": "Analyse par Google Gemini (Rapide & Performant).",
        "Analyse par IA (Groq)": "Analyse ultra-rapide via Llama 3.",
        "Analyse par IA (Claude)": "Analyse nuanc√©e par Claude 3 Haiku.",
        "Analyse par IA (OpenRouter)": "Analyse flexible via OpenRouter.",
        "Analyse par Regex (Extraction d'entit√©s)": "Extrait des informations structur√©es (comp√©tences, dipl√¥mes, etc.).",
        "Analyse par la M√©thode S√©mantique": "Calcule un score de pertinence bas√© sur le sens (n√©cessite une description de poste).",
        "Analyse par la M√©thode Cosinus": "Calcule un score de pertinence bas√© sur les mots-cl√©s (n√©cessite une description de poste).",
        "Analyse Combin√©e (Ensemble)": "Combine plusieurs m√©thodes d'analyse pour un score plus robuste (n√©cessite une description de poste)."
    }
    st.caption(captions.get(analysis_type_single))

    job_desc_single = ""
    if "Analyse par la M√©thode" in analysis_type_single or "Analyse Combin√©e" in analysis_type_single:
        job_desc_single = st.text_area("Description de poste pour le calcul du score", height=150, key="jd_single")

    if uploaded_files_analysis and st.button("üöÄ Lancer l'analyse", type="primary", width="stretch", key="btn_single_analysis"):
        total_files = len(uploaded_files_analysis)
        progress_bar_tab2 = st.progress(0)
        progress_text_tab2 = st.empty()
        
        for file_idx, uploaded_file in enumerate(uploaded_files_analysis):
            progress_text_tab2.info(f"ü§ñ Analyse en cours ({file_idx+1}/{total_files}) : {uploaded_file.name}")
            progress_bar_tab2.progress((file_idx + 1) / total_files)
            
            with st.expander(f"R√©sultat pour : **{uploaded_file.name}**", expanded=True):
                text = extract_text_from_pdf(uploaded_file)
                if "Erreur" in text or (text and text.strip().startswith("Aucun texte lisible trouv√©")):
                    # Message clair pour les PDFs scann√©s ou prot√©g√©s
                    if text and text.strip().startswith("Aucun texte lisible trouv√©"):
                        st.error("‚ùå Aucun texte lisible trouv√© dans le PDF. Il s'agit probablement d'un PDF scann√© (images) ou prot√©g√©.\nüí° Collez manuellement le contenu ou utilisez un OCR externe (ex: tesseract) pour convertir le PDF en texte.")
                    else:
                        st.error(f"‚ùå {text}")
                else:
                    if analysis_type_single == "Analyse par Regex (Extraction d'entit√©s)":
                        entities = regex_analysis(text)
                        st.info("**Entit√©s extraites par la m√©thode Regex**")
                        st.json(entities)
                    elif "M√©thode S√©mantique" in analysis_type_single:
                        if not job_desc_single: st.warning("Veuillez fournir une description de poste.")
                        else:
                            result = rank_resumes_with_embeddings(job_desc_single, [text], [uploaded_file.name])
                            score = result["scores"][0]
                            st.metric("Score de Pertinence S√©mantique", f"{score*100:.1f}%")
                    elif "M√©thode Cosinus" in analysis_type_single:
                        if not job_desc_single: st.warning("Veuillez fournir une description de poste.")
                        else:
                            result = rank_resumes_with_cosine(job_desc_single, [text], [uploaded_file.name])
                            score = result["scores"][0]
                            st.metric("Score de Pertinence Cosinus", f"{score*100:.1f}%")
                    elif "Analyse Combin√©e" in analysis_type_single:
                        if not job_desc_single: st.warning("Veuillez fournir une description de poste.")
                        else:
                            result = rank_resumes_with_ensemble(
                                job_desc_single, [text], [uploaded_file.name],
                                cosinus_weight=0.2, semantic_weight=0.4, rules_weight=0.4,
                                cosine_func=rank_resumes_with_cosine,
                                semantic_func=rank_resumes_with_embeddings,
                                rules_func=rank_resumes_with_rules
                            )
                            score = result["scores"][0]
                            st.metric("Score de Pertinence Combin√©e", f"{score*100:.1f}%")
                            
                            # Affichage de la logique si disponible
                            if "logic" in result:
                                logic = result["logic"].get(uploaded_file.name, {})
                                if logic:
                                    st.markdown("**D√©tail de l'analyse combin√©e :**")
                                    st.json(logic)
                    elif analysis_type_single == "Analyse par IA (Gemini)":
                        # Extraire le nom du candidat
                        extracted = extract_name_from_cv_text(text)
                        candidate_name = extracted.get('name') if extracted else None
                        
                        analysis_result = get_gemini_profile_analysis(text, candidate_name)
                        st.markdown("### ü§ñ R√©sultat de l'analyse Gemini")
                        # Affichage en 2 colonnes
                        col1, col2 = st.columns(2)
                        sections = analysis_result.split('**')
                        left_sections = []
                        right_sections = []
                        current_section = ""
                        section_count = 0
                        for i, section in enumerate(sections):
                            if section.strip():
                                if i % 2 == 1:
                                    current_section = f"**{section}**"
                                else:
                                    full_section = current_section + section
                                    if section_count < 3:
                                        left_sections.append(full_section)
                                    else:
                                        right_sections.append(full_section)
                                    section_count += 1
                        with col1:
                            st.markdown("".join(left_sections))
                        with col2:
                            st.markdown("".join(right_sections))

                    elif analysis_type_single == "Analyse par IA (Groq)":
                        extracted = extract_name_from_cv_text(text)
                        candidate_name = extracted.get('name') if extracted else None
                        analysis_result = get_groq_profile_analysis(text, candidate_name)
                        st.markdown("### ü§ñ R√©sultat de l'analyse Groq")
                        # Affichage en 2 colonnes
                        col1, col2 = st.columns(2)
                        sections = analysis_result.split('**')
                        left_sections = []
                        right_sections = []
                        current_section = ""
                        section_count = 0
                        for i, section in enumerate(sections):
                            if section.strip():
                                if i % 2 == 1:
                                    current_section = f"**{section}**"
                                else:
                                    full_section = current_section + section
                                    if section_count < 3:
                                        left_sections.append(full_section)
                                    else:
                                        right_sections.append(full_section)
                                    section_count += 1
                        with col1:
                            st.markdown("".join(left_sections))
                        with col2:
                            st.markdown("".join(right_sections))

                    elif analysis_type_single == "Analyse par IA (Claude)":
                        extracted = extract_name_from_cv_text(text)
                        candidate_name = extracted.get('name') if extracted else None
                        analysis_result = get_claude_profile_analysis(text, candidate_name)
                        st.markdown("### ü§ñ R√©sultat de l'analyse Claude")
                        # Affichage en 2 colonnes
                        col1, col2 = st.columns(2)
                        sections = analysis_result.split('**')
                        left_sections = []
                        right_sections = []
                        current_section = ""
                        section_count = 0
                        for i, section in enumerate(sections):
                            if section.strip():
                                if i % 2 == 1:
                                    current_section = f"**{section}**"
                                else:
                                    full_section = current_section + section
                                    if section_count < 3:
                                        left_sections.append(full_section)
                                    else:
                                        right_sections.append(full_section)
                                    section_count += 1
                        with col1:
                            st.markdown("".join(left_sections))
                        with col2:
                            st.markdown("".join(right_sections))

                    elif analysis_type_single == "Analyse par IA (OpenRouter)":
                        extracted = extract_name_from_cv_text(text)
                        candidate_name = extracted.get('name') if extracted else None
                        analysis_result = get_openrouter_profile_analysis(text, candidate_name)
                        st.markdown("### ü§ñ R√©sultat de l'analyse OpenRouter")
                        # Affichage en 2 colonnes
                        col1, col2 = st.columns(2)
                        sections = analysis_result.split('**')
                        left_sections = []
                        right_sections = []
                        current_section = ""
                        section_count = 0
                        for i, section in enumerate(sections):
                            if section.strip():
                                if i % 2 == 1:
                                    current_section = f"**{section}**"
                                else:
                                    full_section = current_section + section
                                    if section_count < 3:
                                        left_sections.append(full_section)
                                    else:
                                        right_sections.append(full_section)
                                    section_count += 1
                        with col1:
                            st.markdown("".join(left_sections))
                        with col2:
                            st.markdown("".join(right_sections))

                    else: # Analyse IA DeepSeek
                        # Extraire le nom du candidat
                        extracted = extract_name_from_cv_text(text)
                        candidate_name = extracted.get('name') if extracted else None
                        analysis_result = get_deepseek_profile_analysis(text, candidate_name)
                        
                        # Affichage en 2 colonnes
                        col1, col2 = st.columns(2)
                        # D√©couper le r√©sultat en sections
                        sections = analysis_result.split('**')
                        left_sections = []
                        right_sections = []
                        current_section = ""
                        section_count = 0
                        
                        for i, section in enumerate(sections):
                            if section.strip():
                                if i % 2 == 1:  # C'est un titre
                                    current_section = f"**{section}**"
                                else:  # C'est le contenu
                                    full_section = current_section + section
                                    if section_count < 3:
                                        left_sections.append(full_section)
                                    else:
                                        right_sections.append(full_section)
                                    section_count += 1
                        
                        with col1:
                            st.markdown("".join(left_sections))
                        with col2:
                            st.markdown("".join(right_sections))
        
        # Nettoyer la progression
        progress_text_tab2.empty()
        progress_bar_tab2.empty()
        st.success(f"‚úÖ Analyse termin√©e pour {total_files} CV(s).")

with tab3:
    st.header("üìñ Comprendre les M√©thodes d'Analyse")
    st.markdown("Chaque m√©thode a ses propres forces et faiblesses. Voici un guide pour vous aider √† choisir la plus adapt√©e √† votre besoin.")
    
    st.subheader("1. M√©thode Cosinus (Bas√©e sur les Mots-cl√©s)")
    st.markdown("""
    - **Principe** : Compare la fr√©quence des mots exacts entre le CV et l'annonce.
    - **Comment √ßa marche ?** Elle utilise un mod√®le math√©matique (TF-IDF) pour donner plus de poids aux mots rares et importants. Le score repr√©sente la similarit√© de ces "sacs de mots-cl√©s".
    - **Id√©al pour** : Un premier tri tr√®s rapide et grossier.
    - **Avantages** : ‚úÖ Extr√™mement rapide, ne n√©cessite aucune IA externe.
    - **Limites** : ‚ùå Ne comprend absolument pas le contexte ou les synonymes.
    """)
    
    st.subheader("2. M√©thode S√©mantique (Bas√©e sur les Embeddings)")
    st.markdown("""
    - **Principe** : Utilise une IA pour convertir les phrases en vecteurs de sens, puis compare ces vecteurs.
    - **Comment √ßa marche ?** Au lieu de comparer des mots, on compare la "direction" de ces vecteurs. Deux vecteurs qui pointent dans la m√™me direction repr√©sentent des id√©es s√©mantiquement similaires.
    - **Id√©al pour** : Obtenir un score plus intelligent qui comprend les nuances du langage.
    - **Avantages** : ‚úÖ Comprend le contexte et les synonymes. Excellent √©quilibre entre vitesse et intelligence.
    - **Limites** : ‚ùå Un peu plus lente que la m√©thode cosinus.
    """)

    st.subheader("3. Scoring par R√®gles (Bas√© sur Regex)")
    st.markdown("""
    - **Principe** : Imite la fa√ßon dont un recruteur humain lit un CV. On d√©finit des r√®gles claires (comp√©tences, exp√©rience, dipl√¥me) et on attribue des points.
    - **Comment √ßa marche ?** Le code extrait dynamiquement les exigences de l'annonce, puis recherche ces √©l√©ments dans chaque CV pour calculer un score.
    - **Id√©al pour** : Des postes o√π les crit√®res sont tr√®s clairs et objectifs.
    - **Avantages** : ‚úÖ Totalement transparent (le d√©tail du score est affich√©), 100% personnalisable et sans d√©pendances complexes.
    - **Limites** : ‚ùå Tr√®s rigide. Si une comp√©tence est formul√©e diff√©remment, elle ne sera pas d√©tect√©e.
    """)
    
    st.subheader("4. Analyse par IA (Bas√©e sur un LLM)")
    st.markdown("""
    - **Principe** : On envoie le CV et l'annonce √† un grand mod√®le de langage (DeepSeek) en lui demandant d'agir comme un expert en recrutement.
    - **Comment √ßa marche ?** L'IA lit et comprend les deux textes, puis utilise sa vaste connaissance pour √©valuer la pertinence et formuler une explication.
    - **Id√©al pour** : Obtenir une analyse fine et contextuelle, similaire √† celle d'un premier entretien.
    - **Avantages** : ‚úÖ La plus pr√©cise et la plus "humaine". Comprend les nuances et fournit des explications de haute qualit√©.
    - **Limites** : ‚ùå La plus lente, et chaque analyse **consomme vos tokens !**
    """)
    
    st.subheader("5. Analyse combin√©e (Ensemble)")
    st.markdown("""
    - **Principe** : Combine plusieurs m√©thodes d'analyse (Cosinus, S√©mantique, R√®gles) en un seul score pond√©r√©.
    - **Comment √ßa marche ?** Chaque CV est analys√© selon les trois m√©thodes, puis les scores sont multipli√©s par les poids attribu√©s √† chaque m√©thode et additionn√©s.
    - **Id√©al pour** : Obtenir un classement plus √©quilibr√© qui tire parti des forces de chaque m√©thode. R√©duire les faux positifs et les faux n√©gatifs.
    - **Avantages** : ‚úÖ Plus robuste face aux biais de chaque m√©thode individuelle. Hautement personnalisable via les poids attribu√©s. Fournit des explications d√©taill√©es.
    - **Limites** : ‚ùå Plus lent que les m√©thodes individuelles (mais plus rapide que l'analyse par IA). Complexit√© accrue.
    
    ##### Comment ajuster les poids ?
    - **Augmentez le poids Cosinus** lorsque les mots-cl√©s exacts sont tr√®s importants (termes techniques sp√©cifiques).
    - **Augmentez le poids S√©mantique** pour les postes cr√©atifs ou les comp√©tences transversales, o√π la compr√©hension du contexte est cruciale.
    - **Augmentez le poids R√®gles** pour les postes avec des exigences formelles strictes en termes d'exp√©rience ou de dipl√¥mes.
    """)

with tab4:


    # R√©cup√©ration des statistiques (pr√©-chargement √† l'ouverture de l'onglet)
    feedback_stats = get_feedback_summary()

    if len(feedback_stats) > 0:
        # M√©triques principales
        st.subheader("üìà M√©triques Cl√©s")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_feedbacks = feedback_stats["Nombre d'√©valuations"].sum()
            st.metric("Total Feedbacks", total_feedbacks, help="Nombre total d'√©valuations re√ßues")

        with col2:
            avg_score = (feedback_stats["Score moyen"] * feedback_stats["Nombre d'√©valuations"]).sum() / total_feedbacks
            st.metric("Score Moyen Global", f"{avg_score:.2f}/5", help="Satisfaction moyenne globale")

        with col3:
            best_method = feedback_stats.loc[feedback_stats["Score moyen"].idxmax()]
            st.metric("Meilleure M√©thode", best_method["M√©thode"].split(" (")[0], help=f"Score: {best_method['Score moyen']:.2f}/5")

        with col4:
            most_used = feedback_stats.loc[feedback_stats["Nombre d'√©valuations"].idxmax()]
            evaluations_count = most_used["Nombre d'√©valuations"]
            st.metric("Top", most_used["M√©thode"].split(" (")[0], help=f"{evaluations_count} √©valuations")

        st.markdown("---")

        # Graphiques am√©lior√©s
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("üåü Satisfaction par M√©thode")
            # Filtrer uniquement les m√©thodes avec des √©valuations
            feedback_with_evals = feedback_stats[feedback_stats["Nombre d'√©valuations"] > 0]

            if not feedback_with_evals.empty:
                # Graphique en barres horizontales avec couleurs
                fig_scores = go.Figure()
                colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']

                for i, (_, row) in enumerate(feedback_with_evals.iterrows()):
                    fig_scores.add_trace(go.Bar(
                        x=[row["Score moyen"]],
                        y=[row["M√©thode"]],
                        orientation='h',
                        name=row["M√©thode"],
                        marker_color=colors[i % len(colors)],
                        showlegend=False
                    ))

                fig_scores.update_layout(
                    title="Score moyen par m√©thode (sur 5)",
                    height=max(300, len(feedback_with_evals) * 40),
                    margin={"l": 200, "r": 20, "t": 40, "b": 20},
                    xaxis={"range": [0, 5], "title": "Score moyen"},
                    yaxis={"title": ""},
                )

                st.plotly_chart(fig_scores, width="stretch")

        with col2:
            st.subheader("üìä Distribution des √âvaluations")
            if not feedback_with_evals.empty:
                # Camembert avec pourcentages
                fig_evals = go.Figure(data=[go.Pie(
                    labels=feedback_with_evals["M√©thode"],
                    values=feedback_with_evals["Nombre d'√©valuations"],
                    marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD'],
                    textinfo='label+percent',
                    hovertemplate="<b>%{label}</b><br>%{value} √©valuations (%{percent})<extra></extra>"
                )])

                fig_evals.update_layout(
                    title="R√©partition des feedbacks par m√©thode",
                    height=400,
                    margin={"l": 20, "r": 20, "t": 40, "b": 20},
                    font=dict(size=14),
                    legend=dict(font=dict(size=16))
                )

                st.plotly_chart(fig_evals, width="stretch")

        st.markdown("---")

        # Tableau d√©taill√© avec style am√©lior√©
        st.subheader("üìã D√©tails des Statistiques")

        # Pr√©parer les donn√©es pour l'affichage
        display_stats = feedback_stats.copy()
        display_stats["Score Format√©"] = display_stats.apply(lambda row: 
            f"{row['Score moyen']:.2f}/5 {'üü¢' if row['Score moyen'] >= 4.0 else 'üü°' if row['Score moyen'] >= 3.0 else 'üî¥'}", axis=1)
        display_stats["Fiabilit√©"] = display_stats["Nombre d'√©valuations"].apply(
            lambda x: "Tr√®s fiable üéØ" if x >= 10 else "√Ä confirmer ‚ö†Ô∏è" if x >= 5 else "Donn√©es limit√©es üìä")
        
        # Afficher le tableau avec colonnes format√©es
        st.dataframe(
            display_stats[["M√©thode", "Score Format√©", "Nombre d'√©valuations", "Fiabilit√©"]],
            column_config={
                "M√©thode": st.column_config.TextColumn("M√©thode d'Analyse", width="medium"),
                "Score Format√©": st.column_config.TextColumn("Score Moyen", width="small"),
                "Nombre d'√©valuations": st.column_config.NumberColumn("√âvaluations", width="small"),
                "Fiabilit√©": st.column_config.TextColumn("Fiabilit√©", width="medium")
            },
            hide_index=True,
            width="stretch"
        )

        # Insights et recommandations
        st.markdown("---")
        st.subheader("üí° Insights & Recommandations")

        if len(feedback_with_evals) > 1:
            best_method = feedback_with_evals.loc[feedback_with_evals["Score moyen"].idxmax()]
            worst_method = feedback_with_evals.loc[feedback_with_evals["Score moyen"].idxmin()]

            # Assurer un scalaire num√©rique pour l'√©cart de score (aide Pylance)
            best_score = cast(float, best_method["Score moyen"])
            worst_score = cast(float, worst_method["Score moyen"])

            col1, col2 = st.columns(2)

            with col1:
                st.success(f"üèÜ **Meilleure m√©thode** : {best_method['M√©thode']} avec un score de {best_score:.2f}/5")
                st.info("üí≠ **Recommandation** : Priorisez cette m√©thode pour vos analyses futures.")

            with col2:
                if best_score - worst_score > 0.5:
                    st.warning(f"‚ö†Ô∏è **M√©thode √† am√©liorer** : {worst_method['M√©thode']} (score: {worst_score:.2f}/5)")
                    st.info("üí≠ **Suggestion** : Collectez plus de feedbacks pour affiner cette m√©thode.")

        # √âvolution temporelle (si assez de donn√©es)
        if total_feedbacks >= 10:
            st.subheader("üìà √âvolution de la Satisfaction")
            st.info("üìä Avec plus de donn√©es, nous pourrons afficher des graphiques d'√©volution temporelle de la satisfaction utilisateur.")

    else:
        # Interface vide avec call-to-action
        st.info("Aucun feedback n'a encore √©t√© enregistr√©.")
        st.markdown("""
        <div style='margin-top:1em;'>
        <b>Comment √ßa marche :</b><br>
        1. Effectuez des analyses de CV<br>
        2. √âvaluez les r√©sultats obtenus<br>
        3. Les statistiques s'affichent automatiquement ici
        </div>
        """, unsafe_allow_html=True)

with st.sidebar:
    st.markdown("### üîß Configuration")
    
    # Indicateurs d'√©tat discret
    ds_status = "‚úÖ" if get_api_key() else "‚ö†Ô∏è"
    gem_status = "‚úÖ" if get_gemini_api_key() else "‚ö†Ô∏è"
    
    if ds_status == "‚ö†Ô∏è":
        st.caption("‚ö†Ô∏è DeepSeek API non configur√©e")
    if gem_status == "‚ö†Ô∏è":
        st.caption("‚ö†Ô∏è Gemini API non configur√©e")

    if st.button("Test connexion API"):
        # Test DeepSeek
        ds_key = get_api_key()
        if ds_key:
            try:
                response = requests.get("https://api.deepseek.com/v1/models", headers={"Authorization": f"Bearer {ds_key}"})
                if response.status_code == 200:
                    st.success("‚úÖ DeepSeek : Connect√©")
                else:
                    st.error(f"‚ùå DeepSeek : Erreur {response.status_code}")
            except Exception as e:
                st.error(f"‚ùå DeepSeek : {e}")
        else:
            st.warning("‚ö†Ô∏è DeepSeek : Cl√© manquante")
            
        # Test Gemini
        gem_key = get_gemini_api_key()
        if gem_key:
            try:
                genai.configure(api_key=gem_key)
                
                # Test prioritaires sur les mod√®les disponibles (2.5-flash-lite)
                try:
                    model = genai.GenerativeModel('gemini-2.5-flash-lite')
                    response = model.generate_content("Ping")
                    if response:
                        st.success("‚úÖ Gemini (2.5 Flash Lite) : Connect√©")
                except Exception as e_flash:
                     # Fallback sur flash-latest
                    try:
                        model = genai.GenerativeModel('gemini-flash-latest')
                        response = model.generate_content("Ping")
                        if response:
                             st.success("‚úÖ Gemini (Flash Latest) : Connect√©")
                    except Exception as e_latest:
                        st.error(f"‚ùå Gemini indisponible. Erreur : {e_flash} | {e_latest}")
            except Exception as e:
                st.error(f"‚ùå Gemini : {e}")
        else:
             st.warning("‚ö†Ô∏è Gemini : Cl√© manquante")

        # Test Claude
        claude_key = get_claude_api_key()
        if claude_key:
            try:
                client = anthropic.Anthropic(api_key=claude_key)
                message = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=10,
                    messages=[
                        {"role": "user", "content": "Ping"}
                    ]
                )
                if message and message.content:
                    st.success("‚úÖ Claude (Haiku) : Connect√©")
            except Exception as e:
                st.error(f"‚ùå Claude : {e}")
        else:
             st.warning("‚ö†Ô∏è Claude : Cl√© manquante")

        # Test Groq
        groq_key = get_groq_api_key()
        if groq_key:
            try:
                client = groq.Groq(api_key=groq_key)
                chat_completion = client.chat.completions.create(
                    messages=[{"role": "user", "content": "Ping"}],
                    model="llama-3.1-8b-instant",
                )
                if chat_completion.choices[0].message.content:
                    st.success("‚úÖ Groq (Llama 3) : Connect√©")
            except Exception as e:
                st.error(f"‚ùå Groq : {e}")
        else:
             st.warning("‚ö†Ô∏è Groq : Cl√© manquante")

        # Test OpenRouter
        openrouter_key = get_openrouter_api_key()
        if openrouter_key:
            try:
                resp = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={"Authorization": f"Bearer {openrouter_key}"},
                    json={
                        "model": "openai/gpt-3.5-turbo",
                        "messages": [{"role": "user", "content": "Ping"}]
                    },
                    timeout=10
                )
                if resp.status_code == 200:
                    # basic validation of response structure
                    try:
                        jr = resp.json()
                        if jr.get('choices') and jr['choices'][0].get('message'):
                            st.success("‚úÖ OpenRouter : Connect√©")
                        else:
                            st.error(f"‚ùå OpenRouter : r√©ponse inattendue")
                    except Exception:
                        st.error("‚ùå OpenRouter : r√©ponse non JSON")
                else:
                    st.error(f"‚ùå OpenRouter : Erreur {resp.status_code}")
            except Exception as e:
                st.error(f"‚ùå OpenRouter : {e}")
        else:
            st.warning("‚ö†Ô∏è OpenRouter : Cl√© manquante")

with tab5:
    st.header("üóÇÔ∏è Auto-classification de CVs (4 cat√©gories)")
    st.markdown("Chargez jusqu'√† 100 CVs (PDF). L'outil extrait le texte et classe automatiquement chaque CV dans l'une des 4 cat√©gories : Fonctions supports, Logistique, Production/Technique, Non class√©.")

    # Importer des CVs uniquement via upload
    uploaded_files_auto = st.file_uploader("Importer des CVs (PDF)", type=["pdf"], accept_multiple_files=True, key="auto_uploader")

    # Construire la liste de fichiers uniquement √† partir des uploads
    file_list = []
    if uploaded_files_auto:
        for uf in uploaded_files_auto:
            file_list.append({'name': uf.name, 'file': uf})

    # Afficher imm√©diatement combien de CVs ont √©t√© upload√©s
    if uploaded_files_auto:
        # Show upload status with a small progress indicator
        total_uploads = len(uploaded_files_auto)
        # Build file_list while updating a visible progress bar so users see upload progression
        upload_col, progress_col = st.columns([3, 1])
        upload_col.success(f"‚úÖ {total_uploads} CV(s) upload√©(s) et pr√™ts pour traitement.")
        upload_progress = progress_col.progress(0)

        # Limiter √† 200 pour s√©curit√©
        if total_uploads > 200:
            st.warning('Plus de 200 CVs trouv√©s. Seuls les 200 premiers seront trait√©s.')
            uploaded_files_auto = uploaded_files_auto[:200]
            total_uploads = len(uploaded_files_auto)

        file_list = []
        for i, uf in enumerate(uploaded_files_auto):
            file_list.append({'name': uf.name, 'file': uf})
            # update progress (nice UX next to page indicator)
            try:
                upload_progress.progress(int((i + 1) / total_uploads * 100))
            except Exception:
                # some streamlit versions accept float in [0,1]
                upload_progress.progress((i + 1) / total_uploads)

        # Initialiser les variables de session pour la classification et l'analyse DeepSeek
        if 'classification_results' not in st.session_state:
            st.session_state.classification_results = None
        if 'deepseek_analyses' not in st.session_state:
            st.session_state.deepseek_analyses = []
        if 'last_action' not in st.session_state:
            st.session_state.last_action = None
        
        if st.session_state.classification_results:
            # G√©n√©ration Excel Personnalis√©
            merged_results = merge_results_with_ai_analysis(st.session_state.classification_results)
            df = pd.DataFrame(merged_results)

            supports_list = []
            logistique_list = []
            production_list = []
            divers_list = []
            non_classe_list = []

            for res in merged_results:
                nom = res.get('extracted_name', {}).get('name', res['file'])
                cat = res['category']
                # Nettoyage de la sous-cat√©gorie
                sub = res.get('sub_category', 'Non identifi√©')
                if not sub or sub.lower() == 'autre': sub = "Poste non d√©tect√©"
                
                entry = f"{nom} ({sub})"

                if "SUPPORT" in cat: supports_list.append(entry)
                elif "LOGISTIQUE" in cat: logistique_list.append(entry)
                elif "PRODUCTION" in cat: 
                    # Pour la production, l'IA a mis le d√©tail dans sub_category ou on peut le d√©duire
                    production_list.append(entry)
                elif "DIVERS" in cat: divers_list.append(entry)
                else: non_classe_list.append(entry)

            # --- AFFICHAGE UI ---
            col1, col2 = st.columns(2)
            col3, col4 = st.columns(2)

            def display_list_in_expander(title, items, icon):
                count = len(items)
                with st.expander(f"{icon} {title} ({count})"):
                    if not items: st.caption("Vide")
                    for it in items: st.text(it)

            with col1: display_list_in_expander("SUPPORTS", supports_list, "üè¢")
            with col2: display_list_in_expander("LOGISTIQUE", logistique_list, "üöö")
            with col3: display_list_in_expander("PRODUCTION / TECHNIQUE", production_list, "üèóÔ∏è")
            with col4: display_list_in_expander("DIVERS / HORS P√âRIM√àTRE", divers_list, "üö´")

            if non_classe_list:
                st.error(f"‚ö†Ô∏è {len(non_classe_list)} CVs Non Class√©s")
                st.write(non_classe_list)

            # --- EXPORT EXCEL ---
            max_len = max(len(supports_list), len(logistique_list), len(production_list), len(divers_list), len(non_classe_list))
            supports_list += [''] * (max_len - len(supports_list))
            logistique_list += [''] * (max_len - len(logistique_list))
            production_list += [''] * (max_len - len(production_list))
            divers_list += [''] * (max_len - len(divers_list))
            non_classe_list += [''] * (max_len - len(non_classe_list))

            export_df = pd.DataFrame({
                'FONCTIONS SUPPORTS': supports_list,
                'LOGISTIQUE': logistique_list,
                'PRODUCTION / TECHNIQUE': production_list,
                'DIVERS / HORS P√âRIM√àTRE': divers_list,
                'Non class√©s': non_classe_list
            })

            from io import BytesIO
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                export_df.to_excel(writer, index=False)
            
            st.download_button("‚¨áÔ∏è T√©l√©charger Tableau de Bord Excel", buffer.getvalue(), "Recrutement_TGCC.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            
            if st.button('üì¶ T√©l√©charger le ZIP organis√©'):
                 zip_data, _ = create_organized_zip(st.session_state.classification_results, st.session_state.uploaded_files_list)
                 st.download_button('‚¨áÔ∏è T√©l√©charger ZIP', zip_data, 'CVs_TGCC_Organises.zip', 'application/zip')


# --- FONCTIONS GEMINI (NOUVEAU) ---


# --- FIN FONCTIONS GEMINI ---

