import streamlit as st
import importlib.util
import os
import requests
import json
import time
from datetime import datetime
import random

# --- IMPORTS POUR LES MOD√àLES IA ---
try:
    import groq
    import google.generativeai as genai
    from google.oauth2 import service_account 
except ImportError:
    st.error("‚ùå Biblioth√®ques manquantes. Ex√©cutez : pip install groq google-generativeai google-auth")
    st.stop()
    
# --- INITIALISATION DU SESSION STATE ---
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "Groq" 
if "response_length" not in st.session_state:
    st.session_state.response_length = "Courte"
if "last_token_usage" not in st.session_state:
    st.session_state.last_token_usage = 0
if "placeholder" not in st.session_state:
    # --- NOUVEAUT√â : "Ex: " ajout√© aux placeholders ---
    placeholders = [
        "Ex: Quelles sont les missions cl√©s d'un conducteur de travaux au Maroc ?",
        "Ex: R√©dige une offre d'emploi pour un chef de projet √† Casablanca.",
        "Ex: Propose 5 questions techniques pour un entretien avec un ing√©nieur."
    ]
    st.session_state.placeholder = random.choice(placeholders)

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="TG-Hire IA - Assistant Recrutement",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------- CONFIGURATION DES APIS --------------------
SYSTEM_PROMPT = """
Tu es 'TG-Hire Assistant', un expert IA sp√©cialis√© dans le recrutement pour le secteur du BTP (B√¢timent et Travaux Publics) au Maroc.
Ton r√¥le est d'aider un recruteur humain √† optimiser ses t√¢ches quotidiennes.
Tes r√©ponses doivent √™tre :
1.  **Contextualis√©es** : Toujours adapt√©es au march√© de l'emploi marocain et aux sp√©cificit√©s du secteur du BTP.
2.  **Professionnelles et Pr√©cises** : Fournis des informations concr√®tes et structur√©es.
3.  **Orient√©es Action** : Propose des listes, des questions, des mod√®les de texte, etc.
4.  **Adaptables** : Tu dois ajuster la longueur de ta r√©ponse (courte, normale, d√©taill√©e) selon la demande.
"""

def get_google_credentials():
    """Cr√©e les identifiants du compte de service √† partir des secrets Streamlit."""
    try:
        creds_json = {
            "type": st.secrets["GCP_TYPE"],
            "project_id": st.secrets["GCP_PROJECT_ID"],
            "private_key_id": st.secrets["GCP_PRIVATE_KEY_ID"],
            "private_key": st.secrets["GCP_PRIVATE_KEY"].replace('\\n', '\n'),
            "client_email": st.secrets["GCP_CLIENT_EMAIL"],
            "client_id": st.secrets["GCP_CLIENT_ID"],
            "auth_uri": st.secrets["GCP_AUTH_URI"],
            "token_uri": st.secrets["GCP_TOKEN_URI"],
            "auth_provider_x509_cert_url": st.secrets["GCP_AUTH_PROVIDER_CERT_URL"],
            "client_x509_cert_url": st.secrets["GCP_CLIENT_CERT_URL"]
        }
        return service_account.Credentials.from_service_account_info(creds_json)
    except Exception as e:
        st.error(f"‚ùå Erreur de chargement des identifiants Google: {e}")
        return None

def get_deepseek_response(prompt, history, length):
    api_key = st.secrets.get("DEEPSEEK_API_KEY")
    if not api_key: return {"content": "Erreur: Cl√© API DeepSeek manquante.", "usage": 0}
    
    final_prompt = f"{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": final_prompt}]
    
    try:
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers={"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
            json={"model": "deepseek-chat", "messages": messages, "max_tokens": 2048}
        )
        response.raise_for_status()
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        usage = data.get("usage", {}).get("total_tokens", 0)
        return {"content": content, "usage": usage}
    except Exception as e:
        return {"content": f"‚ùå Erreur API DeepSeek: {e}", "usage": 0}

def get_groq_response(prompt, history, length):
    api_key = st.secrets.get("GROQ_API_KEY")
    if not api_key: return {"content": "Erreur: Cl√© API Groq manquante.", "usage": 0}
    
    final_prompt = f"{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": final_prompt}]
    
    try:
        client = groq.Groq(api_key=api_key)
        chat_completion = client.chat.completions.create(
            messages=messages,
            model="llama-3.1-8b-instant",
        )
        content = chat_completion.choices[0].message.content
        usage = chat_completion.usage.total_tokens
        return {"content": content, "usage": usage}
    except Exception as e:
        return {"content": f"‚ùå Erreur API Groq: {e}", "usage":0}

def get_gemini_response(prompt, history, length):
    creds = get_google_credentials() 
    if not creds:
        return {"content": "Erreur: Impossible de charger les identifiants du compte de service Google.", "usage": 0}

    final_prompt = f"{SYSTEM_PROMPT}\n\nHistorique:\n{json.dumps(history)}\n\nQuestion:\n{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    
    try:
        genai.configure(credentials=creds) 
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        response = model.generate_content(final_prompt)
        content = response.text
        usage = model.count_tokens(final_prompt).total_tokens
        return {"content": content, "usage": usage}
    except Exception as e:
        return {"content": f"‚ùå Erreur API Gemini: {e}", "usage": 0}

# --- ROUTEUR DE MOD√àLE ---
def get_ai_response(prompt, history, model, length):
    if model == "Groq":
        return get_groq_response(prompt, history, length)
    elif model == "DeepSeek":
        return get_deepseek_response(prompt, history, length)
    elif model == "Gemini":
        return get_gemini_response(prompt, history, length)
    else:
        return {"content": "Erreur: Mod√®le non reconnu.", "usage": 0}

# -------------------- INTERFACE PRINCIPALE --------------------
# --- NOUVEAUT√â : Titre mis √† jour ---
st.title("ü§ñ Assistant IA pour le Recrutement")

# --- S√âLECTEURS DANS LA BARRE LAT√âRALE ---
with st.sidebar:
    st.subheader("‚öôÔ∏è Param√®tres")
    st.session_state.selected_model = st.selectbox(
        "üß† Choisir le mod√®le IA :",
        ("Groq", "DeepSeek", "Gemini") # CoGenAI retir√©
    )
    
    st.session_state.response_length = st.selectbox(
        "üìÑ Longueur de la r√©ponse :",
        ("Courte", "Normale", "D√©taill√©e"),
        index=0 # --- NOUVEAUT√â : "Courte" par d√©faut ---
    )

    st.divider()

    st.subheader("üìä Utilisation")
    st.metric("Tokens de la derni√®re r√©ponse", f"{st.session_state.last_token_usage}")
    st.caption("Le nombre de tokens mesure la 'quantit√© de travail' de l'IA.")

# --- ZONE DE SAISIE ET BOUTONS ---
user_input = st.text_area(
    "üí¨ Posez votre question ici :",
    key="assistant_input",
    height=120,
    placeholder=st.session_state.placeholder
)

col1, col2 = st.columns([3, 1])
with col1:
    send_button = st.button("üí° G√©n√©rer par l'IA", type="primary", use_container_width=True)
with col2:
    reset_button = st.button("üßπ Effacer", use_container_width=True)

if reset_button:
    st.session_state.conversation_history = []
    st.session_state.last_token_usage = 0
    st.success("üóëÔ∏è Historique effac√© !")
    time.sleep(1)
    st.rerun()

if send_button and user_input.strip():
    api_history = [{"role": msg["role"], "content": msg["content"]} for msg in st.session_state.conversation_history]
    
    st.session_state.conversation_history.append({"role": "user", "content": user_input})
    
    with st.spinner("‚è≥ G√©n√©ration d'une r√©ponse par l'IA en cours..."):
        response_dict = get_ai_response(
            user_input, 
            api_history, 
            st.session_state.selected_model,
            st.session_state.response_length
        )

    ai_response = response_dict["content"]
    token_usage = response_dict["usage"]

    st.session_state.conversation_history.append({"role": "assistant", "content": ai_response})
    st.session_state.last_token_usage = token_usage
    
    placeholders = [
        "Ex: Quelles sont les missions cl√©s d'un conducteur de travaux au Maroc ?",
        "Ex: R√©dige une offre d'emploi pour un chef de projet √† Casablanca.",
        "Ex: Propose 5 questions techniques pour un entretien avec un ing√©nieur."
    ]
    st.session_state.placeholder = random.choice(placeholders)
    
    st.rerun()

elif send_button and not user_input.strip():
    st.warning("‚ö†Ô∏è Veuillez √©crire une question avant de g√©n√©rer une r√©ponse.")

# --- AFFICHAGE DE L'HISTORIQUE ---
st.subheader("üìú Historique de la conversation")
if not st.session_state.conversation_history:
    st.info("La conversation n'a pas encore commenc√©.")
else:
    for conv in reversed(st.session_state.conversation_history):
        with st.chat_message(conv["role"]):
            st.markdown(conv["content"])