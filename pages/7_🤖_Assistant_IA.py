import streamlit as st
import importlib.util
import os
import requests
import json
import time
from datetime import datetime
import random

# --- NOUVEAUX IMPORTS POUR LES MOD√àLES IA ---
try:
    import groq
    import google.generativeai as genai
except ImportError:
    st.error("‚ùå Biblioth√®ques Groq ou Gemini manquantes. Ex√©cutez : pip install groq google-generativeai")
    st.stop()

# --- V√âRIFICATION DE CONNEXION (si n√©cessaire) ---
# if not st.session_state.get("logged_in", False):
#     st.error("üõë Veuillez vous connecter pour acc√©der √† cette page.")
#     st.stop()
    
# --- INITIALISATION DU SESSION STATE ---
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "Groq" # Mod√®le par d√©faut
if "response_length" not in st.session_state:
    st.session_state.response_length = "Normale" # Longueur par d√©faut
if "placeholder" not in st.session_state:
    # Liste de 10 placeholders al√©atoires
    placeholders = [
        "Quelles sont les missions cl√©s d'un conducteur de travaux dans le BTP au Maroc ?",
        "R√©dige une offre d'emploi pour un chef de projet BTP √† Casablanca.",
        "Propose 5 questions techniques pour un entretien avec un ing√©nieur en g√©nie civil.",
        "Comment √©valuer les soft skills d'un charg√© d'affaires BTP ?",
        "Quels sont les salaires moyens pour un dessinateur-projeteur √† Rabat ?",
        "Liste les comp√©tences indispensables pour un responsable QSE dans la construction.",
        "Comment attirer des profils p√©nuriques comme les grutiers au Maroc ?",
        "Analyse ce profil : 'Ing√©nieur d'√©tat, 5 ans d'exp√©rience en suivi de chantiers routiers'.",
        "Donne-moi des arguments pour convaincre un candidat de rejoindre notre entreprise de BTP.",
        "Quelles sont les r√©glementations marocaines importantes √† conna√Ætre pour un poste RH dans le BTP ?"
    ]
    st.session_state.placeholder = random.choice(placeholders)

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="TG-Hire IA - Assistant Recrutement",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------- CONFIGURATION DES APIS --------------------

# --- PROMPT SYST√àME COMMUN ---
# Contexte pr√©cis pour guider tous les mod√®les IA
SYSTEM_PROMPT = """
Tu es 'TG-Hire Assistant', un expert IA sp√©cialis√© dans le recrutement pour le secteur du BTP (B√¢timent et Travaux Publics) au Maroc.
Ton r√¥le est d'aider un recruteur humain √† optimiser ses t√¢ches quotidiennes.
Tes r√©ponses doivent √™tre :
1.  **Contextualis√©es** : Toujours adapt√©es au march√© de l'emploi marocain et aux sp√©cificit√©s du secteur du BTP (terminologie, types de postes, r√©glementations locales).
2.  **Professionnelles et Pr√©cises** : Fournis des informations concr√®tes, structur√©es et directement utilisables.
3.  **Orient√©es Action** : Propose des listes, des questions, des mod√®les de texte, etc.
4.  **Adaptables** : Tu dois ajuster la longueur et le niveau de d√©tail de ta r√©ponse (courte, normale, d√©taill√©e) selon la demande de l'utilisateur.
"""

def get_deepseek_response(prompt, history, length):
    api_key = st.secrets.get("DEEPSEEK_API_KEY")
    if not api_key: return "Erreur: Cl√© API DeepSeek manquante."
    
    final_prompt = f"{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": final_prompt}]
    
    try:
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers={"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
            json={"model": "deepseek-chat", "messages": messages, "max_tokens": 2048}
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"‚ùå Erreur API DeepSeek: {e}"

def get_groq_response(prompt, history, length):
    api_key = st.secrets.get("GROQ_API_KEY")
    if not api_key: return "Erreur: Cl√© API Groq manquante."
    
    final_prompt = f"{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    messages = [{"role": "system", "content": SYSTEM_PROMPT}] + history + [{"role": "user", "content": final_prompt}]
    
    try:
        client = groq.Groq(api_key=api_key)
        chat_completion = client.chat.completions.create(
            messages=messages,
            model="llama3-8b-8192",
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"‚ùå Erreur API Groq: {e}"

def get_gemini_response(prompt, history, length):
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key: return "Erreur: Cl√© API Gemini manquante."
    
    final_prompt = f"{SYSTEM_PROMPT}\n\nHistorique de la conversation:\n{json.dumps(history)}\n\nNouvelle question:\n{prompt}\n\n(Instruction: Fournir une r√©ponse de longueur '{length}')"
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(final_prompt)
        return response.text
    except Exception as e:
        return f"‚ùå Erreur API Gemini: {e}"

# --- ROUTEUR DE MOD√àLE ---
def get_ai_response(prompt, history, model, length):
    if model == "Groq":
        return get_groq_response(prompt, history, length)
    elif model == "DeepSeek":
        return get_deepseek_response(prompt, history, length)
    elif model == "Gemini":
        return get_gemini_response(prompt, history, length)
    else:
        return "Erreur: Mod√®le non reconnu."

# -------------------- INTERFACE PRINCIPALE --------------------
st.title("ü§ñ Assistant IA pour le Recrutement BTP")
st.info("Posez une question √† votre assistant sp√©cialis√© pour le march√© marocain du BTP.")

# --- S√âLECTEURS DANS LA BARRE LAT√âRALE ---
with st.sidebar:
    st.subheader("‚öôÔ∏è Param√®tres")
    st.session_state.selected_model = st.radio(
        "üß† Choisir le mod√®le IA :",
        ("Groq", "DeepSeek", "Gemini"),
        horizontal=True,
    )
    st.session_state.response_length = st.radio(
        "üìÑ Longueur de la r√©ponse :",
        ("Courte", "Normale", "D√©taill√©e"),
        horizontal=True,
    )

# --- ZONE DE SAISIE ET BOUTONS ---
user_input = st.text_area(
    "üí¨ Posez votre question ici :",
    key="assistant_input",
    height=120,
    placeholder=st.session_state.placeholder # Placeholder al√©atoire
)

col1, col2 = st.columns([3, 1]) # Donne plus de place au bouton principal
with col1:
    send_button = st.button("üí° G√©n√©rer par l'IA", type="primary", use_container_width=True)
with col2:
    reset_button = st.button("üßπ Effacer", use_container_width=True)

if reset_button:
    st.session_state.conversation_history = []
    st.success("üóëÔ∏è Historique de la conversation effac√© !")
    time.sleep(1) # Petit d√©lai pour voir le message
    st.rerun()

if send_button and user_input.strip():
    # Extrait uniquement le r√¥le et le contenu pour l'historique de l'API
    api_history = [{"role": msg["role"], "content": msg["content"]} for msg in st.session_state.conversation_history]
    
    # Ajoute le message de l'utilisateur √† l'historique d'affichage
    st.session_state.conversation_history.append({"role": "user", "content": user_input})
    
    # R√©cup√®re la r√©ponse de l'IA
    with st.spinner(f"‚è≥ L'assistant {st.session_state.selected_model} r√©fl√©chit..."):
        ai_response = get_ai_response(
            user_input, 
            api_history, 
            st.session_state.selected_model,
            st.session_state.response_length
        )

    # Ajoute la r√©ponse de l'IA √† l'historique d'affichage
    st.session_state.conversation_history.append({"role": "assistant", "content": ai_response})
    
    # Change le placeholder pour la prochaine question
    st.session_state.placeholder = random.choice([
        "Quelles sont les missions cl√©s d'un conducteur de travaux dans le BTP au Maroc ?",
        "R√©dige une offre d'emploi pour un chef de projet BTP √† Casablanca.",
        "Propose 5 questions techniques pour un entretien avec un ing√©nieur en g√©nie civil.",
        "Comment √©valuer les soft skills d'un charg√© d'affaires BTP ?",
        "Quels sont les salaires moyens pour un dessinateur-projeteur √† Rabat ?",
        "Liste les comp√©tences indispensables pour un responsable QSE dans la construction.",
        "Comment attirer des profils p√©nuriques comme les grutiers au Maroc ?",
        "Analyse ce profil : 'Ing√©nieur d'√©tat, 5 ans d'exp√©rience en suivi de chantiers routiers'.",
        "Donne-moi des arguments pour convaincre un candidat de rejoindre notre entreprise de BTP.",
        "Quelles sont les r√©glementations marocaines importantes √† conna√Ætre pour un poste RH dans le BTP ?"
    ])
    st.rerun()

elif send_button and not user_input.strip():
    st.warning("‚ö†Ô∏è Veuillez √©crire une question avant de g√©n√©rer une r√©ponse.")

st.divider()

# --- AFFICHAGE DE L'HISTORIQUE DE CONVERSATION (INVERS√â) ---
st.subheader("üìú Historique de la conversation")
if not st.session_state.conversation_history:
    st.info("La conversation n'a pas encore commenc√©. Posez une question pour d√©marrer !")
else:
    # It√®re sur la liste invers√©e pour afficher le plus r√©cent en premier
    for conv in reversed(st.session_state.conversation_history):
        # Utilise st.chat_message pour une interface de chat moderne
        with st.chat_message(conv["role"]):
            st.markdown(conv["content"])